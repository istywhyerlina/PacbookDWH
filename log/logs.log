2024-11-09 09:40:20,446 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 09:40:20,471 - ERROR - EXTRACT 'public.address' - FAILED.
2024-11-09 09:40:20,472 - INFO - Extract All Tables From Sources - FAILED
2024-11-09 09:40:20,473 - ERROR - [pid 82728] Worker Worker(salt=584669474, workers=1, host=Erlina, username=istywhyerlina, pid=82728) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 64, in run
    df.to_csv(f"{DIR_TEMP_DATA}/{table_name}.csv", index=False)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 3967, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/formats/format.py", line 1014, in to_csv
    csv_formatter.save()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py", line 251, in save
    with get_handle(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/common.py", line 749, in get_handle
    check_parent_directory(str(handle))
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/common.py", line 616, in check_parent_directory
    raise OSError(rf"Cannot save file into a non-existent directory: '{parent}'")
OSError: Cannot save file into a non-existent directory: '/home/istywhyerlina/fp_datastorage/PacbookDWH/pipeline/temp/data                      #  <project_dir>/pipeline/temp'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 70, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'public.address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 106, in run
    summary.to_csv(f"{DIR_TEMP_DATA}/extract-summary.csv", index = False)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 3967, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/formats/format.py", line 1014, in to_csv
    csv_formatter.save()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py", line 251, in save
    with get_handle(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/common.py", line 749, in get_handle
    check_parent_directory(str(handle))
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/common.py", line 616, in check_parent_directory
    raise OSError(rf"Cannot save file into a non-existent directory: '{parent}'")
OSError: Cannot save file into a non-existent directory: '/home/istywhyerlina/fp_datastorage/PacbookDWH/pipeline/temp/data                      #  <project_dir>/pipeline/temp'
2024-11-09 09:40:20,476 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 09:40:20,478 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-09 09:40:20,478 - DEBUG - Asking scheduler for work...
2024-11-09 09:40:20,478 - DEBUG - Done
2024-11-09 09:40:20,478 - DEBUG - There are no more tasks to run at this time
2024-11-09 09:40:20,479 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-09 09:40:20,479 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-09 09:40:20,479 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-09 09:40:20,480 - INFO - Worker Worker(salt=584669474, workers=1, host=Erlina, username=istywhyerlina, pid=82728) was stopped. Shutting down Keep-Alive thread
2024-11-09 09:40:20,480 - INFO - 
===== Luigi Execution Summary =====

Scheduled 1 tasks of which:
* 1 failed:
    - 1 Extract()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 09:41:55,015 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 09:41:55,031 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-09 09:41:55,033 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-09 09:41:55,045 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-09 09:41:55,080 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-09 09:41:55,095 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-09 09:41:55,097 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-09 09:41:55,099 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-09 09:41:55,135 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-09 09:41:55,140 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-09 09:41:55,145 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-09 09:41:55,202 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-09 09:41:55,236 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-09 09:41:55,238 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-09 09:41:55,243 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-09 09:41:55,245 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-09 09:41:55,245 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 09:41:55,245 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 09:41:55,245 - INFO - [pid 83996] Worker Worker(salt=4101116673, workers=1, host=Erlina, username=istywhyerlina, pid=83996) done      Extract()
2024-11-09 09:41:55,246 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 09:41:55,247 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 09:41:55,247 - DEBUG - Asking scheduler for work...
2024-11-09 09:41:55,247 - DEBUG - Done
2024-11-09 09:41:55,247 - DEBUG - There are no more tasks to run at this time
2024-11-09 09:41:55,247 - INFO - Worker Worker(salt=4101116673, workers=1, host=Erlina, username=istywhyerlina, pid=83996) was stopped. Shutting down Keep-Alive thread
2024-11-09 09:41:55,247 - INFO - 
===== Luigi Execution Summary =====

Scheduled 1 tasks of which:
* 1 ran successfully:
    - 1 Extract()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 09:44:13,124 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 09:44:13,139 - INFO - EXTRACT 'public.address' - SUCCESS.
2024-11-09 09:44:13,140 - INFO - EXTRACT 'public.address_status' - SUCCESS.
2024-11-09 09:44:13,152 - INFO - EXTRACT 'public.author' - SUCCESS.
2024-11-09 09:44:13,187 - INFO - EXTRACT 'public.book' - SUCCESS.
2024-11-09 09:44:13,204 - INFO - EXTRACT 'public.book_author' - SUCCESS.
2024-11-09 09:44:13,206 - INFO - EXTRACT 'public.book_language' - SUCCESS.
2024-11-09 09:44:13,208 - INFO - EXTRACT 'public.country' - SUCCESS.
2024-11-09 09:44:13,247 - INFO - EXTRACT 'public.cust_order' - SUCCESS.
2024-11-09 09:44:13,252 - INFO - EXTRACT 'public.customer' - SUCCESS.
2024-11-09 09:44:13,257 - INFO - EXTRACT 'public.customer_address' - SUCCESS.
2024-11-09 09:44:13,312 - INFO - EXTRACT 'public.order_history' - SUCCESS.
2024-11-09 09:44:13,344 - INFO - EXTRACT 'public.order_line' - SUCCESS.
2024-11-09 09:44:13,346 - INFO - EXTRACT 'public.order_status' - SUCCESS.
2024-11-09 09:44:13,350 - INFO - EXTRACT 'public.publisher' - SUCCESS.
2024-11-09 09:44:13,352 - INFO - EXTRACT 'public.shipping_method' - SUCCESS.
2024-11-09 09:44:13,352 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 09:44:13,353 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 09:44:13,353 - INFO - [pid 85809] Worker Worker(salt=7347986822, workers=1, host=Erlina, username=istywhyerlina, pid=85809) done      Extract()
2024-11-09 09:44:13,354 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 09:44:13,354 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 09:44:13,354 - DEBUG - Asking scheduler for work...
2024-11-09 09:44:13,354 - DEBUG - Done
2024-11-09 09:44:13,354 - DEBUG - There are no more tasks to run at this time
2024-11-09 09:44:13,354 - INFO - Worker Worker(salt=7347986822, workers=1, host=Erlina, username=istywhyerlina, pid=85809) was stopped. Shutting down Keep-Alive thread
2024-11-09 09:44:13,355 - INFO - 
===== Luigi Execution Summary =====

Scheduled 1 tasks of which:
* 1 ran successfully:
    - 1 Extract()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 09:48:50,824 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 09:48:50,841 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 09:48:50,842 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 09:48:50,853 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 09:48:50,889 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 09:48:50,906 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 09:48:50,908 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 09:48:50,910 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 09:48:50,946 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 09:48:50,950 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 09:48:50,955 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 09:48:51,012 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 09:48:51,043 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 09:48:51,045 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 09:48:51,049 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 09:48:51,050 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 09:48:51,050 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 09:48:51,051 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 09:48:51,051 - INFO - [pid 89502] Worker Worker(salt=5191948936, workers=1, host=Erlina, username=istywhyerlina, pid=89502) done      Extract()
2024-11-09 09:48:51,052 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 09:48:51,052 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 09:48:51,052 - DEBUG - Asking scheduler for work...
2024-11-09 09:48:51,052 - DEBUG - Done
2024-11-09 09:48:51,052 - DEBUG - There are no more tasks to run at this time
2024-11-09 09:48:51,052 - INFO - Worker Worker(salt=5191948936, workers=1, host=Erlina, username=istywhyerlina, pid=89502) was stopped. Shutting down Keep-Alive thread
2024-11-09 09:48:51,053 - INFO - 
===== Luigi Execution Summary =====

Scheduled 1 tasks of which:
* 1 ran successfully:
    - 1 Extract()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 09:59:35,929 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 09:59:35,946 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 09:59:35,948 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 09:59:35,961 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 09:59:35,998 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 09:59:36,037 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 09:59:36,040 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 09:59:36,042 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 09:59:36,064 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 09:59:36,069 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 09:59:36,075 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 09:59:36,132 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 09:59:36,192 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 09:59:36,195 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 09:59:36,202 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 09:59:36,204 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 09:59:36,204 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 09:59:36,205 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 09:59:36,205 - INFO - [pid 98120] Worker Worker(salt=6516965155, workers=1, host=Erlina, username=istywhyerlina, pid=98120) done      Extract()
2024-11-09 09:59:36,206 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 09:59:36,206 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 09:59:36,206 - DEBUG - Asking scheduler for work...
2024-11-09 09:59:36,207 - DEBUG - Pending tasks: 1
2024-11-09 09:59:36,207 - INFO - [pid 98120] Worker Worker(salt=6516965155, workers=1, host=Erlina, username=istywhyerlina, pid=98120) running   Load()
2024-11-09 09:59:36,207 - INFO - Read Load Query - SUCCESS
2024-11-09 09:59:36,265 - INFO - Read Extracted Data - SUCCESS
2024-11-09 09:59:36,266 - INFO - Connect to DWH - SUCCESS
2024-11-09 09:59:36,275 - ERROR - Truncate pacbook Schema in DWH - FAILED
2024-11-09 09:59:36,276 - ERROR - [pid 98120] Worker Worker(salt=6516965155, workers=1, host=Erlina, username=istywhyerlina, pid=98120) failed    Load()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InvalidSchemaName: schema "dvdrental" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 103, in run
    session.execute(query)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
    return self._execute_internal(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2256, in _execute_internal
    result = conn.execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.InvalidSchemaName) schema "dvdrental" does not exist

[SQL: TRUNCATE TABLE dvdrental.actor CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 115, in run
    raise Exception("Failed to Truncate pacbook Schema in DWH")
Exception: Failed to Truncate pacbook Schema in DWH
2024-11-09 09:59:36,278 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 09:59:36,279 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-09 09:59:36,279 - DEBUG - Asking scheduler for work...
2024-11-09 09:59:36,279 - DEBUG - Done
2024-11-09 09:59:36,279 - DEBUG - There are no more tasks to run at this time
2024-11-09 09:59:36,279 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-09 09:59:36,279 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-09 09:59:36,279 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-09 09:59:36,279 - INFO - Worker Worker(salt=6516965155, workers=1, host=Erlina, username=istywhyerlina, pid=98120) was stopped. Shutting down Keep-Alive thread
2024-11-09 09:59:36,280 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:03:32,742 - INFO - Read Load Query - SUCCESS
2024-11-09 10:03:32,783 - INFO - Read Extracted Data - SUCCESS
2024-11-09 10:03:32,801 - INFO - Connect to DWH - SUCCESS
2024-11-09 10:03:32,812 - ERROR - Truncate pacbook Schema in DWH - FAILED
2024-11-09 10:03:32,812 - ERROR - [pid 101264] Worker Worker(salt=9249821697, workers=1, host=Erlina, username=istywhyerlina, pid=101264) failed    Load()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InvalidSchemaName: schema "dvdrental" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 103, in run
    session.execute(query)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
    return self._execute_internal(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2256, in _execute_internal
    result = conn.execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.InvalidSchemaName) schema "dvdrental" does not exist

[SQL: TRUNCATE TABLE dvdrental.actor CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 115, in run
    raise Exception("Failed to Truncate pacbook Schema in DWH")
Exception: Failed to Truncate pacbook Schema in DWH
2024-11-09 10:03:32,814 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:03:32,816 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-09 10:03:32,816 - DEBUG - Asking scheduler for work...
2024-11-09 10:03:32,816 - DEBUG - Done
2024-11-09 10:03:32,816 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:03:32,816 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-09 10:03:32,816 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-09 10:03:32,816 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-09 10:03:32,817 - INFO - Worker Worker(salt=9249821697, workers=1, host=Erlina, username=istywhyerlina, pid=101264) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:03:32,817 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 complete ones were encountered:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:04:15,556 - INFO - Read Load Query - SUCCESS
2024-11-09 10:04:15,599 - INFO - Read Extracted Data - SUCCESS
2024-11-09 10:04:15,618 - INFO - Connect to DWH - SUCCESS
2024-11-09 10:04:15,627 - ERROR - Truncate pacbook Schema in DWH - FAILED
2024-11-09 10:04:15,628 - ERROR - [pid 101925] Worker Worker(salt=1346824336, workers=1, host=Erlina, username=istywhyerlina, pid=101925) failed    Load()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.InvalidSchemaName: schema "dvdrental" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 103, in run
    session.execute(query)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2362, in execute
    return self._execute_internal(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 2256, in _execute_internal
    result = conn.execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1846, in _execute_context
    return self._exec_single_context(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1986, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1967, in _exec_single_context
    self.dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.InvalidSchemaName) schema "dvdrental" does not exist

[SQL: TRUNCATE TABLE dvdrental.actor CASCADE]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 115, in run
    raise Exception("Failed to Truncate pacbook Schema in DWH")
Exception: Failed to Truncate pacbook Schema in DWH
2024-11-09 10:04:15,630 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:04:15,631 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-09 10:04:15,631 - DEBUG - Asking scheduler for work...
2024-11-09 10:04:15,631 - DEBUG - Done
2024-11-09 10:04:15,631 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:04:15,631 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-09 10:04:15,631 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-09 10:04:15,631 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-09 10:04:15,631 - INFO - Worker Worker(salt=1346824336, workers=1, host=Erlina, username=istywhyerlina, pid=101925) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:04:15,632 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 complete ones were encountered:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:06:36,933 - INFO - Read Load Query - SUCCESS
2024-11-09 10:06:36,977 - INFO - Read Extracted Data - SUCCESS
2024-11-09 10:06:36,995 - INFO - Connect to DWH - SUCCESS
2024-11-09 10:06:37,080 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 10:06:37,080 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 10:06:37,099 - ERROR - LOAD All Tables To DWH-pacbook - FAILED
2024-11-09 10:06:37,101 - ERROR - LOAD All Tables To DWH - FAILED
2024-11-09 10:06:37,101 - ERROR - [pid 103807] Worker Worker(salt=8870260865, workers=1, host=Erlina, username=istywhyerlina, pid=103807) failed    Load()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.ForeignKeyViolation: insert or update on table "address" violates foreign key constraint "fk_addr_ctry"
DETAIL:  Key (country_id)=(95) is not present in table "country".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 128, in run
    address.to_sql('address',
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 3087, in to_sql
    return sql.to_sql(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 842, in to_sql
    return pandas_sql.to_sql(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in to_sql
    total_inserted = sql_engine.insert_records(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1567, in insert_records
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1558, in insert_records
    return table.insert(chunksize=chunksize, method=method)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1119, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1010, in _execute_insert
    result = conn.execute(self.table.insert(), data)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1844, in _execute_context
    return self._exec_insertmany_context(dialect, context)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2126, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.ForeignKeyViolation) insert or update on table "address" violates foreign key constraint "fk_addr_ctry"
DETAIL:  Key (country_id)=(95) is not present in table "country".

[SQL: INSERT INTO pacbook.address (address_id, street_number, street_name, city, country_id) VALUES (%(address_id__0)s, %(street_number__0)s, %(street_name__0)s, %(city__0)s, %(country_id__0)s), (%(address_id__1)s, %(street_number__1)s, %(street_name__1)s, ... 104192 characters truncated ... address_id__999)s, %(street_number__999)s, %(street_name__999)s, %(city__999)s, %(country_id__999)s)]
[parameters: {'country_id__0': 95, 'street_name__0': 'Glacier Hill Avenue', 'city__0': 'Torbat-e Jām', 'address_id__0': 1, 'street_number__0': 57, 'country_id__1': 37, 'street_name__1': 'Dottie Junction', 'city__1': 'Beaumont', 'address_id__1': 2, 'street_number__1': 86, 'country_id__2': 60, 'street_name__2': 'Ramsey Avenue', 'city__2': 'Cayambe', 'address_id__2': 3, 'street_number__2': 292, 'country_id__3': 47, 'street_name__3': 'Thackeray Junction', 'city__3': 'Caldas', 'address_id__3': 4, 'street_number__3': 5618, 'country_id__4': 153, 'street_name__4': '2nd Park', 'city__4': 'Ngunguru', 'address_id__4': 5, 'street_number__4': 4, 'country_id__5': 159, 'street_name__5': 'Nancy Junction', 'city__5': 'Burirao', 'address_id__5': 6, 'street_number__5': 387, 'country_id__6': 42, 'street_name__6': 'Atwood Point', 'city__6': 'Nirji', 'address_id__6': 7, 'street_number__6': 501, 'country_id__7': 164, 'street_name__7': 'North Pass', 'city__7': 'Tijão', 'address_id__7': 8, 'street_number__7': 42, 'country_id__8': 164, 'street_name__8': 'Graceland Pass', 'city__8': 'Castelo de Vide', 'address_id__8': 9, 'street_number__8': 83, 'country_id__9': 42, 'street_name__9': 'Clyde Gallagher Road', 'city__9': 'Shangde', 'address_id__9': 10, 'street_number__9': 93 ... 4900 parameters truncated ... 'country_id__990': 69, 'street_name__990': 'Heath Street', 'city__990': 'Parikkala', 'address_id__990': 991, 'street_number__990': 510, 'country_id__991': 200, 'street_name__991': 'Sheridan Park', 'city__991': 'Ongkharak', 'address_id__991': 992, 'street_number__991': 71, 'country_id__992': 70, 'street_name__992': 'Carpenter Street', 'city__992': 'Paris 08', 'address_id__992': 993, 'street_number__992': 5329, 'country_id__993': 194, 'street_name__993': 'Arkansas Hill', 'city__993': 'Vellinge', 'address_id__993': 994, 'street_number__993': 61170, 'country_id__994': 158, 'street_name__994': 'Lindbergh Drive', 'city__994': 'Santa Rosa', 'address_id__994': 995, 'street_number__994': 70837, 'country_id__995': 92, 'street_name__995': 'Leroy Alley', 'city__995': 'Mmaaf', 'address_id__995': 996, 'street_number__995': 5, 'country_id__996': 53, 'street_name__996': 'Morningstar Junction', 'city__996': 'Jobabo', 'address_id__996': 997, 'street_number__996': 24, 'country_id__997': 42, 'street_name__997': 'Autumn Leaf Parkway', 'city__997': 'Changxingbao', 'address_id__997': 998, 'street_number__997': 429, 'country_id__998': 92, 'street_name__998': 'Moose Crossing', 'city__998': 'Pasararba', 'address_id__998': 999, 'street_number__998': 2, 'country_id__999': 42, 'street_name__999': 'Canary Crossing', 'city__999': 'Jiangfeng', 'address_id__999': 1000, 'street_number__999': 503}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 254, in run
    raise Exception('Failed Load Tables To DWH-pacbook')
Exception: Failed Load Tables To DWH-pacbook

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 292, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-11-09 10:06:37,105 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:06:37,107 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-09 10:06:37,107 - DEBUG - Asking scheduler for work...
2024-11-09 10:06:37,107 - DEBUG - Done
2024-11-09 10:06:37,107 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:06:37,107 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-09 10:06:37,107 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-09 10:06:37,107 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-09 10:06:37,107 - INFO - Worker Worker(salt=8870260865, workers=1, host=Erlina, username=istywhyerlina, pid=103807) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:06:37,108 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 complete ones were encountered:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:14:00,305 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:14:00,332 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 10:14:00,336 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 10:14:00,356 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 10:14:00,424 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 10:14:00,491 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 10:14:00,494 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 10:14:00,497 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 10:14:00,545 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 10:14:00,556 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 10:14:00,568 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 10:14:00,711 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 10:14:00,810 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 10:14:00,813 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 10:14:00,820 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 10:14:00,823 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 10:14:00,823 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 10:14:00,825 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 10:14:00,825 - INFO - [pid 109557] Worker Worker(salt=2665433399, workers=1, host=Erlina, username=istywhyerlina, pid=109557) done      Extract()
2024-11-09 10:14:00,827 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:14:00,828 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 10:14:00,828 - DEBUG - Asking scheduler for work...
2024-11-09 10:14:00,828 - DEBUG - Pending tasks: 1
2024-11-09 10:14:00,828 - INFO - [pid 109557] Worker Worker(salt=2665433399, workers=1, host=Erlina, username=istywhyerlina, pid=109557) running   Load()
2024-11-09 10:14:00,829 - INFO - Read Load Query - SUCCESS
2024-11-09 10:14:00,914 - INFO - Read Extracted Data - SUCCESS
2024-11-09 10:14:00,915 - INFO - Connect to DWH - SUCCESS
2024-11-09 10:14:01,109 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 10:14:01,109 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 10:14:01,146 - ERROR - LOAD All Tables To DWH-pacbook - FAILED
2024-11-09 10:14:01,147 - ERROR - LOAD All Tables To DWH - FAILED
2024-11-09 10:14:01,147 - ERROR - [pid 109557] Worker Worker(salt=2665433399, workers=1, host=Erlina, username=istywhyerlina, pid=109557) failed    Load()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.ForeignKeyViolation: insert or update on table "address" violates foreign key constraint "fk_addr_ctry"
DETAIL:  Key (country_id)=(95) is not present in table "country".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 128, in run
    address.to_sql('address',
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 3087, in to_sql
    return sql.to_sql(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 842, in to_sql
    return pandas_sql.to_sql(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in to_sql
    total_inserted = sql_engine.insert_records(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1567, in insert_records
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1558, in insert_records
    return table.insert(chunksize=chunksize, method=method)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1119, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1010, in _execute_insert
    result = conn.execute(self.table.insert(), data)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1844, in _execute_context
    return self._exec_insertmany_context(dialect, context)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2126, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.ForeignKeyViolation) insert or update on table "address" violates foreign key constraint "fk_addr_ctry"
DETAIL:  Key (country_id)=(95) is not present in table "country".

[SQL: INSERT INTO pacbook.address (address_id, street_number, street_name, city, country_id) VALUES (%(address_id__0)s, %(street_number__0)s, %(street_name__0)s, %(city__0)s, %(country_id__0)s), (%(address_id__1)s, %(street_number__1)s, %(street_name__1)s, ... 104192 characters truncated ... address_id__999)s, %(street_number__999)s, %(street_name__999)s, %(city__999)s, %(country_id__999)s)]
[parameters: {'city__0': 'Torbat-e Jām', 'address_id__0': 1, 'street_number__0': 57, 'street_name__0': 'Glacier Hill Avenue', 'country_id__0': 95, 'city__1': 'Beaumont', 'address_id__1': 2, 'street_number__1': 86, 'street_name__1': 'Dottie Junction', 'country_id__1': 37, 'city__2': 'Cayambe', 'address_id__2': 3, 'street_number__2': 292, 'street_name__2': 'Ramsey Avenue', 'country_id__2': 60, 'city__3': 'Caldas', 'address_id__3': 4, 'street_number__3': 5618, 'street_name__3': 'Thackeray Junction', 'country_id__3': 47, 'city__4': 'Ngunguru', 'address_id__4': 5, 'street_number__4': 4, 'street_name__4': '2nd Park', 'country_id__4': 153, 'city__5': 'Burirao', 'address_id__5': 6, 'street_number__5': 387, 'street_name__5': 'Nancy Junction', 'country_id__5': 159, 'city__6': 'Nirji', 'address_id__6': 7, 'street_number__6': 501, 'street_name__6': 'Atwood Point', 'country_id__6': 42, 'city__7': 'Tijão', 'address_id__7': 8, 'street_number__7': 42, 'street_name__7': 'North Pass', 'country_id__7': 164, 'city__8': 'Castelo de Vide', 'address_id__8': 9, 'street_number__8': 83, 'street_name__8': 'Graceland Pass', 'country_id__8': 164, 'city__9': 'Shangde', 'address_id__9': 10, 'street_number__9': 93, 'street_name__9': 'Clyde Gallagher Road', 'country_id__9': 42 ... 4900 parameters truncated ... 'city__990': 'Parikkala', 'address_id__990': 991, 'street_number__990': 510, 'street_name__990': 'Heath Street', 'country_id__990': 69, 'city__991': 'Ongkharak', 'address_id__991': 992, 'street_number__991': 71, 'street_name__991': 'Sheridan Park', 'country_id__991': 200, 'city__992': 'Paris 08', 'address_id__992': 993, 'street_number__992': 5329, 'street_name__992': 'Carpenter Street', 'country_id__992': 70, 'city__993': 'Vellinge', 'address_id__993': 994, 'street_number__993': 61170, 'street_name__993': 'Arkansas Hill', 'country_id__993': 194, 'city__994': 'Santa Rosa', 'address_id__994': 995, 'street_number__994': 70837, 'street_name__994': 'Lindbergh Drive', 'country_id__994': 158, 'city__995': 'Mmaaf', 'address_id__995': 996, 'street_number__995': 5, 'street_name__995': 'Leroy Alley', 'country_id__995': 92, 'city__996': 'Jobabo', 'address_id__996': 997, 'street_number__996': 24, 'street_name__996': 'Morningstar Junction', 'country_id__996': 53, 'city__997': 'Changxingbao', 'address_id__997': 998, 'street_number__997': 429, 'street_name__997': 'Autumn Leaf Parkway', 'country_id__997': 42, 'city__998': 'Pasararba', 'address_id__998': 999, 'street_number__998': 2, 'street_name__998': 'Moose Crossing', 'country_id__998': 92, 'city__999': 'Jiangfeng', 'address_id__999': 1000, 'street_number__999': 503, 'street_name__999': 'Canary Crossing', 'country_id__999': 42}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 254, in run
    raise Exception('Failed Load Tables To DWH-pacbook')
Exception: Failed Load Tables To DWH-pacbook

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 292, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-11-09 10:14:01,153 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:14:01,156 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-09 10:14:01,156 - DEBUG - Asking scheduler for work...
2024-11-09 10:14:01,156 - DEBUG - Done
2024-11-09 10:14:01,156 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:14:01,157 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-09 10:14:01,157 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-09 10:14:01,157 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-09 10:14:01,157 - INFO - Worker Worker(salt=2665433399, workers=1, host=Erlina, username=istywhyerlina, pid=109557) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:14:01,158 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:18:08,223 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:18:08,256 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 10:18:08,259 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 10:18:08,283 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 10:18:08,367 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 10:18:08,426 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 10:18:08,430 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 10:18:08,433 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 10:18:08,475 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 10:18:08,484 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 10:18:08,495 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 10:18:08,613 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 10:18:08,713 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 10:18:08,717 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 10:18:08,723 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 10:18:08,726 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 10:18:08,726 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 10:18:08,727 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 10:18:08,727 - INFO - [pid 112668] Worker Worker(salt=5017980203, workers=1, host=Erlina, username=istywhyerlina, pid=112668) done      Extract()
2024-11-09 10:18:08,728 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:18:08,729 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 10:18:08,729 - DEBUG - Asking scheduler for work...
2024-11-09 10:18:08,729 - DEBUG - Pending tasks: 1
2024-11-09 10:18:08,729 - INFO - [pid 112668] Worker Worker(salt=5017980203, workers=1, host=Erlina, username=istywhyerlina, pid=112668) running   Load()
2024-11-09 10:18:08,730 - INFO - Read Load Query - SUCCESS
2024-11-09 10:18:08,805 - INFO - Read Extracted Data - SUCCESS
2024-11-09 10:18:08,806 - INFO - Connect to DWH - SUCCESS
2024-11-09 10:18:09,016 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 10:18:09,016 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 10:18:09,031 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 10:18:09,072 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 10:18:09,078 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 10:18:09,202 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 10:18:09,328 - ERROR - LOAD All Tables To DWH-pacbook - FAILED
2024-11-09 10:18:09,330 - ERROR - LOAD All Tables To DWH - FAILED
2024-11-09 10:18:09,330 - ERROR - [pid 112668] Worker Worker(salt=5017980203, workers=1, host=Erlina, username=istywhyerlina, pid=112668) failed    Load()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "publication_date" of relation "book" does not exist
LINE 1: ... (book_id, title, isbn13, language_id, num_pages, publicatio...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 162, in run
    book.to_sql('book',
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 3087, in to_sql
    return sql.to_sql(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 842, in to_sql
    return pandas_sql.to_sql(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in to_sql
    total_inserted = sql_engine.insert_records(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1567, in insert_records
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1558, in insert_records
    return table.insert(chunksize=chunksize, method=method)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1119, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1010, in _execute_insert
    result = conn.execute(self.table.insert(), data)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1844, in _execute_context
    return self._exec_insertmany_context(dialect, context)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2126, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "publication_date" of relation "book" does not exist
LINE 1: ... (book_id, title, isbn13, language_id, num_pages, publicatio...
                                                             ^

[SQL: INSERT INTO pacbook.book (book_id, title, isbn13, language_id, num_pages, publication_date, publisher_id) VALUES (%(book_id__0)s, %(title__0)s, %(isbn13__0)s, %(language_id__0)s, %(num_pages__0)s, %(publication_date__0)s, %(publisher_id__0)s), (%(boo ... 143991 characters truncated ... __999)s, %(language_id__999)s, %(num_pages__999)s, %(publication_date__999)s, %(publisher_id__999)s)]
[parameters: {'publication_date__0': '1996-09-01', 'isbn13__0': 8987059752, 'num_pages__0': 276, 'publisher_id__0': 1010, 'book_id__0': 1, 'language_id__0': 2, 'title__0': "The World's First Love: Mary  Mother of God", 'publication_date__1': '2004-10-04', 'isbn13__1': 20049130001, 'num_pages__1': 352, 'publisher_id__1': 1967, 'book_id__1': 2, 'language_id__1': 1, 'title__1': 'The Illuminati', 'publication_date__2': '2003-03-11', 'isbn13__2': 23755004321, 'num_pages__2': 128, 'publisher_id__2': 1967, 'book_id__2': 3, 'language_id__2': 1, 'title__2': 'The Servant Leader', 'publication_date__3': '1999-09-01', 'isbn13__3': 34406054602, 'num_pages__3': 168, 'publisher_id__3': 1978, 'book_id__3': 4, 'language_id__3': 1, 'title__3': 'What Life Was Like in the Jewel in the Crown: British India  AD 1600-1905', 'publication_date__4': '1983-12-29', 'isbn13__4': 49086007763, 'num_pages__4': 80, 'publisher_id__4': 416, 'book_id__4': 5, 'language_id__4': 1, 'title__4': "Cliffs Notes on Aristophanes' Lysistrata  The Birds  The Clouds  The Frogs", 'publication_date__5': '2000-04-01', 'isbn13__5': 73999140774, 'num_pages__5': 298, 'publisher_id__5': 96, 'book_id__5': 6, 'language_id__5': 1, 'title__5': "Life Is a Dream and Other Spanish Classics (Eric Bentley's Dramatic Repertoire) - Volume II", 'publication_date__6': '2000-05-01', 'isbn13__6': 73999254907, 'num_pages__6': 504, 'publisher_id__6': 95, 'book_id__6': 7, 'language_id__6': 2, 'title__6': 'William Goldman: Four Screenplays', 'publication_date__7': '2004-07-01' ... 6900 parameters truncated ... 'title__992': 'Americana', 'publication_date__993': '1990-05-01', 'isbn13__993': 9780140119503, 'num_pages__993': 240, 'publisher_id__993': 1476, 'book_id__993': 991, 'language_id__993': 1, 'title__993': 'If the River Was Whiskey', 'publication_date__994': '1992-01-01', 'isbn13__994': 9780140127225, 'num_pages__994': 107, 'publisher_id__994': 1476, 'book_id__994': 992, 'language_id__994': 1, 'title__994': 'On Directing Film', 'publication_date__995': '1995-01-31', 'isbn13__995': 9780140128468, 'num_pages__995': 270, 'publisher_id__995': 1476, 'book_id__995': 993, 'language_id__995': 1, 'title__995': "Love's Executioner  And Other Tales Of Psychotherapy", 'publication_date__996': '1991-08-01', 'isbn13__996': 9780140131673, 'num_pages__996': 384, 'publisher_id__996': 1476, 'book_id__996': 994, 'language_id__996': 1, 'title__996': 'East Is East', 'publication_date__997': '1993-08-01', 'isbn13__997': 9780140131963, 'num_pages__997': 415, 'publisher_id__997': 1476, 'book_id__997': 995, 'language_id__997': 1, 'title__997': 'The Ice-Shirt (Seven Dreams #1)', 'publication_date__998': '2002-12-05', 'isbn13__998': 9780140137002, 'num_pages__998': 400, 'publisher_id__998': 1470, 'book_id__998': 996, 'language_id__998': 1, 'title__998': 'Montaillou: Cathars and Catholics in a French Village 1294-1324', 'publication_date__999': '1998-07-30', 'isbn13__999': 9780140137347, 'num_pages__999': 304, 'publisher_id__999': 1470, 'book_id__999': 997, 'language_id__999': 1, 'title__999': 'The History of Sexuality  Volume 2: The Use of Pleasure'}]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 257, in run
    raise Exception('Failed Load Tables To DWH-pacbook')
Exception: Failed Load Tables To DWH-pacbook

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 295, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-11-09 10:18:09,341 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:18:09,348 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-09 10:18:09,348 - DEBUG - Asking scheduler for work...
2024-11-09 10:18:09,349 - DEBUG - Done
2024-11-09 10:18:09,349 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:18:09,349 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-09 10:18:09,350 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-09 10:18:09,350 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-09 10:18:09,350 - INFO - Worker Worker(salt=5017980203, workers=1, host=Erlina, username=istywhyerlina, pid=112668) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:18:09,353 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 ran successfully:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:21:06,237 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:21:06,240 - ERROR - EXTRACT 'address' - FAILED.
2024-11-09 10:21:06,240 - INFO - Extract All Tables From Sources - FAILED
2024-11-09 10:21:06,245 - ERROR - [pid 115652] Worker Worker(salt=2687075884, workers=1, host=Erlina, username=istywhyerlina, pid=115652) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 62, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3278, in connect
    return self._connection_cls(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2442, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 71, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 110, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-11-09 10:21:06,252 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:21:06,255 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-09 10:21:06,255 - DEBUG - Asking scheduler for work...
2024-11-09 10:21:06,256 - DEBUG - Done
2024-11-09 10:21:06,256 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:21:06,256 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-11-09 10:21:06,256 - DEBUG - There are 2 pending tasks unique to this worker
2024-11-09 10:21:06,256 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-11-09 10:21:06,256 - INFO - Worker Worker(salt=2687075884, workers=1, host=Erlina, username=istywhyerlina, pid=115652) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:21:06,258 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 failed:
    - 1 Extract()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:21:38,992 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:21:38,994 - ERROR - EXTRACT 'address' - FAILED.
2024-11-09 10:21:38,995 - INFO - Extract All Tables From Sources - FAILED
2024-11-09 10:21:38,999 - ERROR - [pid 116175] Worker Worker(salt=2315607102, workers=1, host=Erlina, username=istywhyerlina, pid=116175) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 62, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3278, in connect
    return self._connection_cls(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2442, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 71, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 110, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-11-09 10:21:39,003 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:21:39,006 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-09 10:21:39,006 - DEBUG - Asking scheduler for work...
2024-11-09 10:21:39,007 - DEBUG - Done
2024-11-09 10:21:39,007 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:21:39,007 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-11-09 10:21:39,007 - DEBUG - There are 2 pending tasks unique to this worker
2024-11-09 10:21:39,007 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-11-09 10:21:39,007 - INFO - Worker Worker(salt=2315607102, workers=1, host=Erlina, username=istywhyerlina, pid=116175) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:21:39,009 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 failed:
    - 1 Extract()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:23:44,104 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:23:44,107 - ERROR - EXTRACT 'address' - FAILED.
2024-11-09 10:23:44,107 - INFO - Extract All Tables From Sources - FAILED
2024-11-09 10:23:44,110 - ERROR - [pid 118464] Worker Worker(salt=3495418311, workers=1, host=Erlina, username=istywhyerlina, pid=118464) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 62, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3278, in connect
    return self._connection_cls(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2442, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 71, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 110, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-11-09 10:23:44,116 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:23:44,126 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-09 10:23:44,127 - DEBUG - Asking scheduler for work...
2024-11-09 10:23:44,128 - DEBUG - Done
2024-11-09 10:23:44,128 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:23:44,129 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-11-09 10:23:44,129 - DEBUG - There are 2 pending tasks unique to this worker
2024-11-09 10:23:44,129 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-11-09 10:23:44,129 - INFO - Worker Worker(salt=3495418311, workers=1, host=Erlina, username=istywhyerlina, pid=118464) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:23:44,131 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 failed:
    - 1 Extract()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:25:04,206 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:25:04,208 - ERROR - EXTRACT 'address' - FAILED.
2024-11-09 10:25:04,208 - INFO - Extract All Tables From Sources - FAILED
2024-11-09 10:25:04,212 - ERROR - [pid 119713] Worker Worker(salt=4870036274, workers=1, host=Erlina, username=istywhyerlina, pid=119713) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 62, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3278, in connect
    return self._connection_cls(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2442, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 71, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 110, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-11-09 10:25:04,216 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:25:04,219 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-09 10:25:04,219 - DEBUG - Asking scheduler for work...
2024-11-09 10:25:04,220 - DEBUG - Done
2024-11-09 10:25:04,220 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:25:04,220 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-11-09 10:25:04,220 - DEBUG - There are 2 pending tasks unique to this worker
2024-11-09 10:25:04,220 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-11-09 10:25:04,221 - INFO - Worker Worker(salt=4870036274, workers=1, host=Erlina, username=istywhyerlina, pid=119713) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:25:04,223 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 failed:
    - 1 Extract()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:25:28,281 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:25:28,284 - ERROR - EXTRACT 'address' - FAILED.
2024-11-09 10:25:28,284 - INFO - Extract All Tables From Sources - FAILED
2024-11-09 10:25:28,288 - ERROR - [pid 120538] Worker Worker(salt=2851538638, workers=1, host=Erlina, username=istywhyerlina, pid=120538) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 62, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3278, in connect
    return self._connection_cls(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2442, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 71, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 110, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-11-09 10:25:28,294 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:25:28,299 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-09 10:25:28,300 - DEBUG - Asking scheduler for work...
2024-11-09 10:25:28,300 - DEBUG - Done
2024-11-09 10:25:28,300 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:25:28,300 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-11-09 10:25:28,300 - DEBUG - There are 2 pending tasks unique to this worker
2024-11-09 10:25:28,300 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-11-09 10:25:28,301 - INFO - Worker Worker(salt=2851538638, workers=1, host=Erlina, username=istywhyerlina, pid=120538) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:25:28,303 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 failed:
    - 1 Extract()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:32:10,143 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:32:10,160 - ERROR - EXTRACT 'address' - FAILED.
2024-11-09 10:32:10,161 - INFO - Extract All Tables From Sources - FAILED
2024-11-09 10:32:10,171 - ERROR - [pid 3831] Worker Worker(salt=1997708674, workers=1, host=Erlina, username=istywhyerlina, pid=3831) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 62, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3278, in connect
    return self._connection_cls(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2442, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 71, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 110, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-11-09 10:32:10,191 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:32:10,195 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-09 10:32:10,195 - DEBUG - Asking scheduler for work...
2024-11-09 10:32:10,195 - DEBUG - Done
2024-11-09 10:32:10,196 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:32:10,196 - DEBUG - There are 2 pending tasks possibly being run by other workers
2024-11-09 10:32:10,196 - DEBUG - There are 2 pending tasks unique to this worker
2024-11-09 10:32:10,196 - DEBUG - There are 2 pending tasks last scheduled by this worker
2024-11-09 10:32:10,196 - INFO - Worker Worker(salt=1997708674, workers=1, host=Erlina, username=istywhyerlina, pid=3831) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:32:10,201 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 failed:
    - 1 Extract()
* 1 were left pending, among these:
    * 1 had failed dependencies:
        - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:35:29,296 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:35:29,321 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 10:35:29,325 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 10:35:29,345 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 10:35:29,421 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 10:35:29,457 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 10:35:29,462 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 10:35:29,466 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 10:35:29,584 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 10:35:29,598 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 10:35:29,617 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 10:35:29,733 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 10:35:29,803 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 10:35:29,807 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 10:35:29,814 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 10:35:29,817 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 10:35:29,817 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 10:35:29,819 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 10:35:29,819 - INFO - [pid 5786] Worker Worker(salt=6375044631, workers=1, host=Erlina, username=istywhyerlina, pid=5786) done      Extract()
2024-11-09 10:35:29,821 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:35:29,822 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 10:35:29,822 - DEBUG - Asking scheduler for work...
2024-11-09 10:35:29,822 - DEBUG - Done
2024-11-09 10:35:29,822 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:35:29,822 - INFO - Worker Worker(salt=6375044631, workers=1, host=Erlina, username=istywhyerlina, pid=5786) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:35:29,823 - INFO - 
===== Luigi Execution Summary =====

Scheduled 1 tasks of which:
* 1 ran successfully:
    - 1 Extract()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 10:35:42,082 - INFO - Read Load Query - SUCCESS
2024-11-09 10:35:42,163 - INFO - Read Extracted Data - SUCCESS
2024-11-09 10:35:42,204 - INFO - Connect to DWH - SUCCESS
2024-11-09 10:35:42,259 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 10:35:42,259 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 10:35:42,277 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 10:35:42,313 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 10:35:42,320 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 10:35:42,423 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 10:35:42,492 - ERROR - LOAD All Tables To DWH-pacbook - FAILED
2024-11-09 10:35:42,494 - ERROR - LOAD All Tables To DWH - FAILED
2024-11-09 10:35:42,494 - ERROR - [pid 6086] Worker Worker(salt=9969452670, workers=1, host=Erlina, username=istywhyerlina, pid=6086) failed    Load()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "publication_date" of relation "book" does not exist
LINE 1: ... (book_id, title, isbn13, language_id, num_pages, publicatio...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 162, in run
    book.to_sql('book',
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/core/generic.py", line 3087, in to_sql
    return sql.to_sql(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 842, in to_sql
    return pandas_sql.to_sql(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in to_sql
    total_inserted = sql_engine.insert_records(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1567, in insert_records
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1558, in insert_records
    return table.insert(chunksize=chunksize, method=method)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1119, in insert
    num_inserted = exec_insert(conn, keys, chunk_iter)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1010, in _execute_insert
    result = conn.execute(self.table.insert(), data)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1418, in execute
    return meth(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 515, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1640, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1844, in _execute_context
    return self._exec_insertmany_context(dialect, context)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2126, in _exec_insertmany_context
    self._handle_dbapi_exception(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2355, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2118, in _exec_insertmany_context
    dialect.do_execute(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 941, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "publication_date" of relation "book" does not exist
LINE 1: ... (book_id, title, isbn13, language_id, num_pages, publicatio...
                                                             ^

[SQL: INSERT INTO pacbook.book (book_id, title, isbn13, language_id, num_pages, publication_date, publisher_id) VALUES (%(book_id__0)s, %(title__0)s, %(isbn13__0)s, %(language_id__0)s, %(num_pages__0)s, %(publication_date__0)s, %(publisher_id__0)s), (%(boo ... 143991 characters truncated ... __999)s, %(language_id__999)s, %(num_pages__999)s, %(publication_date__999)s, %(publisher_id__999)s)]
[parameters: {'publication_date__0': '1996-09-01', 'num_pages__0': 276, 'book_id__0': 1, 'publisher_id__0': 1010, 'language_id__0': 2, 'title__0': "The World's First Love: Mary  Mother of God", 'isbn13__0': 8987059752, 'publication_date__1': '2004-10-04', 'num_pages__1': 352, 'book_id__1': 2, 'publisher_id__1': 1967, 'language_id__1': 1, 'title__1': 'The Illuminati', 'isbn13__1': 20049130001, 'publication_date__2': '2003-03-11', 'num_pages__2': 128, 'book_id__2': 3, 'publisher_id__2': 1967, 'language_id__2': 1, 'title__2': 'The Servant Leader', 'isbn13__2': 23755004321, 'publication_date__3': '1999-09-01', 'num_pages__3': 168, 'book_id__3': 4, 'publisher_id__3': 1978, 'language_id__3': 1, 'title__3': 'What Life Was Like in the Jewel in the Crown: British India  AD 1600-1905', 'isbn13__3': 34406054602, 'publication_date__4': '1983-12-29', 'num_pages__4': 80, 'book_id__4': 5, 'publisher_id__4': 416, 'language_id__4': 1, 'title__4': "Cliffs Notes on Aristophanes' Lysistrata  The Birds  The Clouds  The Frogs", 'isbn13__4': 49086007763, 'publication_date__5': '2000-04-01', 'num_pages__5': 298, 'book_id__5': 6, 'publisher_id__5': 96, 'language_id__5': 1, 'title__5': "Life Is a Dream and Other Spanish Classics (Eric Bentley's Dramatic Repertoire) - Volume II", 'isbn13__5': 73999140774, 'publication_date__6': '2000-05-01', 'num_pages__6': 504, 'book_id__6': 7, 'publisher_id__6': 95, 'language_id__6': 2, 'title__6': 'William Goldman: Four Screenplays', 'isbn13__6': 73999254907, 'publication_date__7': '2004-07-01' ... 6900 parameters truncated ... 'isbn13__992': 9780140119480, 'publication_date__993': '1990-05-01', 'num_pages__993': 240, 'book_id__993': 991, 'publisher_id__993': 1476, 'language_id__993': 1, 'title__993': 'If the River Was Whiskey', 'isbn13__993': 9780140119503, 'publication_date__994': '1992-01-01', 'num_pages__994': 107, 'book_id__994': 992, 'publisher_id__994': 1476, 'language_id__994': 1, 'title__994': 'On Directing Film', 'isbn13__994': 9780140127225, 'publication_date__995': '1995-01-31', 'num_pages__995': 270, 'book_id__995': 993, 'publisher_id__995': 1476, 'language_id__995': 1, 'title__995': "Love's Executioner  And Other Tales Of Psychotherapy", 'isbn13__995': 9780140128468, 'publication_date__996': '1991-08-01', 'num_pages__996': 384, 'book_id__996': 994, 'publisher_id__996': 1476, 'language_id__996': 1, 'title__996': 'East Is East', 'isbn13__996': 9780140131673, 'publication_date__997': '1993-08-01', 'num_pages__997': 415, 'book_id__997': 995, 'publisher_id__997': 1476, 'language_id__997': 1, 'title__997': 'The Ice-Shirt (Seven Dreams #1)', 'isbn13__997': 9780140131963, 'publication_date__998': '2002-12-05', 'num_pages__998': 400, 'book_id__998': 996, 'publisher_id__998': 1470, 'language_id__998': 1, 'title__998': 'Montaillou: Cathars and Catholics in a French Village 1294-1324', 'isbn13__998': 9780140137002, 'publication_date__999': '1998-07-30', 'num_pages__999': 304, 'book_id__999': 997, 'publisher_id__999': 1470, 'language_id__999': 1, 'title__999': 'The History of Sexuality  Volume 2: The Use of Pleasure', 'isbn13__999': 9780140137347}]
(Background on this error at: https://sqlalche.me/e/20/f405)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 257, in run
    raise Exception('Failed Load Tables To DWH-pacbook')
Exception: Failed Load Tables To DWH-pacbook

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/load.py", line 295, in run
    raise Exception('Failed Load Tables To DWH')
Exception: Failed Load Tables To DWH
2024-11-09 10:35:42,537 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:35:42,542 - INFO - Informed scheduler that task   Load__99914b932b   has status   FAILED
2024-11-09 10:35:42,542 - DEBUG - Asking scheduler for work...
2024-11-09 10:35:42,543 - DEBUG - Done
2024-11-09 10:35:42,543 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:35:42,543 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-09 10:35:42,543 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-09 10:35:42,544 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-09 10:35:42,544 - INFO - Worker Worker(salt=9969452670, workers=1, host=Erlina, username=istywhyerlina, pid=6086) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:35:42,546 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 complete ones were encountered:
    - 1 Extract()
* 1 failed:
    - 1 Load()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 10:39:22,100 - INFO - Read Load Query - SUCCESS
2024-11-09 10:39:22,193 - INFO - Read Extracted Data - SUCCESS
2024-11-09 10:39:22,234 - INFO - Connect to DWH - SUCCESS
2024-11-09 10:39:22,272 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 10:39:22,272 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 10:39:22,288 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 10:39:22,325 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 10:39:22,331 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 10:39:22,433 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 10:39:22,802 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 10:39:23,039 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 10:39:23,046 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 10:39:23,195 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 10:39:23,241 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 10:39:23,294 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 10:39:23,709 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 10:39:24,008 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 10:39:24,015 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 10:39:24,047 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 10:39:24,054 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 10:39:24,054 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 10:39:24,057 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 10:39:24,058 - INFO - [pid 7947] Worker Worker(salt=9578486452, workers=1, host=Erlina, username=istywhyerlina, pid=7947) done      Load()
2024-11-09 10:39:24,058 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:39:24,059 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 10:39:24,059 - DEBUG - Asking scheduler for work...
2024-11-09 10:39:24,059 - DEBUG - Done
2024-11-09 10:39:24,059 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:39:24,060 - INFO - Worker Worker(salt=9578486452, workers=1, host=Erlina, username=istywhyerlina, pid=7947) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:39:24,061 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 complete ones were encountered:
    - 1 Extract()
* 1 ran successfully:
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 10:40:03,994 - INFO - Read Load Query - SUCCESS
2024-11-09 10:40:04,070 - INFO - Read Extracted Data - SUCCESS
2024-11-09 10:40:04,107 - INFO - Connect to DWH - SUCCESS
2024-11-09 10:40:04,162 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 10:40:04,162 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 10:40:04,177 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 10:40:04,208 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 10:40:04,215 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 10:40:04,330 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 10:40:04,658 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 10:40:04,842 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 10:40:04,848 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 10:40:04,977 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 10:40:05,017 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 10:40:05,054 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 10:40:05,389 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 10:40:05,649 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 10:40:05,655 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 10:40:05,683 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 10:40:05,689 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 10:40:05,689 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 10:40:05,691 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 10:40:05,692 - INFO - [pid 8356] Worker Worker(salt=8777591886, workers=1, host=Erlina, username=istywhyerlina, pid=8356) done      Load()
2024-11-09 10:40:05,693 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:40:05,694 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 10:40:05,694 - DEBUG - Asking scheduler for work...
2024-11-09 10:40:05,694 - DEBUG - Done
2024-11-09 10:40:05,694 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:40:05,694 - INFO - Worker Worker(salt=8777591886, workers=1, host=Erlina, username=istywhyerlina, pid=8356) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:40:05,696 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 1 complete ones were encountered:
    - 1 Extract()
* 1 ran successfully:
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 10:41:18,659 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:41:18,688 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 10:41:18,693 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 10:41:18,712 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 10:41:18,777 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 10:41:18,841 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 10:41:18,845 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 10:41:18,848 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 10:41:18,891 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 10:41:18,899 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 10:41:18,911 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 10:41:19,025 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 10:41:19,127 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 10:41:19,132 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 10:41:19,140 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 10:41:19,143 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 10:41:19,144 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 10:41:19,145 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 10:41:19,145 - INFO - [pid 9139] Worker Worker(salt=6610327431, workers=1, host=Erlina, username=istywhyerlina, pid=9139) done      Extract()
2024-11-09 10:41:19,147 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:41:19,147 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 10:41:19,148 - DEBUG - Asking scheduler for work...
2024-11-09 10:41:19,148 - DEBUG - Pending tasks: 1
2024-11-09 10:41:19,148 - INFO - [pid 9139] Worker Worker(salt=6610327431, workers=1, host=Erlina, username=istywhyerlina, pid=9139) running   Load()
2024-11-09 10:41:19,148 - INFO - Read Load Query - SUCCESS
2024-11-09 10:41:19,226 - INFO - Read Extracted Data - SUCCESS
2024-11-09 10:41:19,227 - INFO - Connect to DWH - SUCCESS
2024-11-09 10:41:19,270 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 10:41:19,270 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 10:41:19,286 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 10:41:19,324 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 10:41:19,333 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 10:41:19,468 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 10:41:19,788 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 10:41:20,009 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 10:41:20,015 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 10:41:20,143 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 10:41:20,183 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 10:41:20,226 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 10:41:20,578 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 10:41:20,805 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 10:41:20,810 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 10:41:20,863 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 10:41:20,868 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 10:41:20,868 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 10:41:20,870 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 10:41:20,871 - INFO - [pid 9139] Worker Worker(salt=6610327431, workers=1, host=Erlina, username=istywhyerlina, pid=9139) done      Load()
2024-11-09 10:41:20,872 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:41:20,872 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 10:41:20,872 - DEBUG - Asking scheduler for work...
2024-11-09 10:41:20,872 - DEBUG - Done
2024-11-09 10:41:20,873 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:41:20,873 - INFO - Worker Worker(salt=6610327431, workers=1, host=Erlina, username=istywhyerlina, pid=9139) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:41:20,874 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 10:44:31,448 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 10:44:31,470 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 10:44:31,473 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 10:44:31,493 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 10:44:31,559 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 10:44:31,621 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 10:44:31,625 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 10:44:31,629 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 10:44:31,676 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 10:44:31,685 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 10:44:31,695 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 10:44:31,824 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 10:44:31,919 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 10:44:31,922 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 10:44:31,928 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 10:44:31,931 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 10:44:31,931 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 10:44:31,932 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 10:44:31,932 - INFO - [pid 10933] Worker Worker(salt=7838192957, workers=1, host=Erlina, username=istywhyerlina, pid=10933) done      Extract()
2024-11-09 10:44:31,934 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:44:31,934 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 10:44:31,934 - DEBUG - Asking scheduler for work...
2024-11-09 10:44:31,935 - DEBUG - Pending tasks: 1
2024-11-09 10:44:31,935 - INFO - [pid 10933] Worker Worker(salt=7838192957, workers=1, host=Erlina, username=istywhyerlina, pid=10933) running   Load()
2024-11-09 10:44:31,936 - INFO - Read Load Query - SUCCESS
2024-11-09 10:44:32,018 - INFO - Read Extracted Data - SUCCESS
2024-11-09 10:44:32,019 - INFO - Connect to DWH - SUCCESS
2024-11-09 10:44:32,065 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 10:44:32,065 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 10:44:32,078 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 10:44:32,108 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 10:44:32,115 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 10:44:32,224 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 10:44:32,544 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 10:44:32,754 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 10:44:32,762 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 10:44:32,909 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 10:44:32,952 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 10:44:32,996 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 10:44:33,392 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 10:44:33,624 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 10:44:33,629 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 10:44:33,686 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 10:44:33,691 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 10:44:33,692 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 10:44:33,693 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 10:44:33,694 - INFO - [pid 10933] Worker Worker(salt=7838192957, workers=1, host=Erlina, username=istywhyerlina, pid=10933) done      Load()
2024-11-09 10:44:33,694 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 10:44:33,695 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 10:44:33,695 - DEBUG - Asking scheduler for work...
2024-11-09 10:44:33,695 - DEBUG - Done
2024-11-09 10:44:33,695 - DEBUG - There are no more tasks to run at this time
2024-11-09 10:44:33,695 - INFO - Worker Worker(salt=7838192957, workers=1, host=Erlina, username=istywhyerlina, pid=10933) was stopped. Shutting down Keep-Alive thread
2024-11-09 10:44:33,696 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 18:46:35,852 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 18:46:35,898 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 18:46:35,903 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 18:46:35,932 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 18:46:36,004 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 18:46:36,069 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 18:46:36,073 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 18:46:36,076 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 18:46:36,140 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 18:46:36,153 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 18:46:36,166 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 18:46:36,287 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 18:46:36,406 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 18:46:36,412 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 18:46:36,424 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 18:46:36,430 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 18:46:36,431 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 18:46:36,432 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 18:46:36,432 - INFO - [pid 235528] Worker Worker(salt=8567457149, workers=1, host=Erlina, username=istywhyerlina, pid=235528) done      Extract()
2024-11-09 18:46:36,434 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 18:46:36,434 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 18:46:36,435 - DEBUG - Asking scheduler for work...
2024-11-09 18:46:36,435 - DEBUG - Pending tasks: 2
2024-11-09 18:46:36,435 - INFO - [pid 235528] Worker Worker(salt=8567457149, workers=1, host=Erlina, username=istywhyerlina, pid=235528) running   Load()
2024-11-09 18:46:36,446 - INFO - Read Load Query - SUCCESS
2024-11-09 18:46:36,527 - INFO - Read Extracted Data - SUCCESS
2024-11-09 18:46:36,528 - INFO - Connect to DWH - SUCCESS
2024-11-09 18:46:36,579 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 18:46:36,579 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 18:46:36,596 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 18:46:36,636 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 18:46:36,645 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 18:46:36,765 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 18:46:37,140 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 18:46:37,354 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 18:46:37,360 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 18:46:37,509 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 18:46:37,550 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 18:46:37,597 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 18:46:37,963 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 18:46:38,202 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 18:46:38,208 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 18:46:38,267 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 18:46:38,273 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 18:46:38,274 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 18:46:38,275 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 18:46:38,276 - INFO - [pid 235528] Worker Worker(salt=8567457149, workers=1, host=Erlina, username=istywhyerlina, pid=235528) done      Load()
2024-11-09 18:46:38,277 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 18:46:38,277 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 18:46:38,278 - DEBUG - Asking scheduler for work...
2024-11-09 18:46:38,278 - DEBUG - Pending tasks: 1
2024-11-09 18:46:38,278 - INFO - [pid 235528] Worker Worker(salt=8567457149, workers=1, host=Erlina, username=istywhyerlina, pid=235528) running   Transform()
2024-11-09 18:46:38,279 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-11-09 18:46:38,280 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-11-09 18:46:38,281 - ERROR - Transform Tables - FAILED
2024-11-09 18:46:38,281 - ERROR - [pid 235528] Worker Worker(salt=8567457149, workers=1, host=Erlina, username=istywhyerlina, pid=235528) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 32, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd DIR_DBT_TRANSFORM=/home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 2.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 79, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-11-09 18:46:38,284 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 18:46:38,287 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-09 18:46:38,287 - DEBUG - Asking scheduler for work...
2024-11-09 18:46:38,287 - DEBUG - Done
2024-11-09 18:46:38,287 - DEBUG - There are no more tasks to run at this time
2024-11-09 18:46:38,287 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-09 18:46:38,287 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-09 18:46:38,288 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-09 18:46:38,288 - INFO - Worker Worker(salt=8567457149, workers=1, host=Erlina, username=istywhyerlina, pid=235528) was stopped. Shutting down Keep-Alive thread
2024-11-09 18:46:38,289 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

[0m11:49:21  Running with dbt=1.9.0-b2
[0m11:49:22  Installing dbt-labs/dbt_utils
[0m11:49:23  Installed from version 1.1.1
[0m11:49:23  Updated version available: 1.3.0
[0m11:49:23  Installing calogica/dbt_date
[0m11:49:23  Installed from version 0.10.0
[0m11:49:23  Updated version available: 0.10.1
[0m11:49:23  
[0m11:49:23  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m11:49:32  Running with dbt=1.9.0-b2
[0m11:49:33  Registered adapter: postgres=1.8.2
[0m11:49:33  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m11:49:33  
[0m11:49:33  Concurrency: 1 threads (target='dev')
[0m11:49:33  
[0m11:49:33  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m11:52:01  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 147.92s]
[0m11:52:01  
[0m11:52:01  Finished running 1 seed in 0 hours 2 minutes and 28.06 seconds (148.06s).
[0m11:52:01  
[0m11:52:01  [32mCompleted successfully[0m
[0m11:52:01  
[0m11:52:01  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:52:06  Running with dbt=1.9.0-b2
[0m11:52:06  Registered adapter: postgres=1.8.2
[0m11:52:07  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m11:52:07  
[0m11:52:07  Concurrency: 1 threads (target='dev')
[0m11:52:07  
[0m11:52:07  1 of 15 START sql view model final.stg_dwh__address ............................ [RUN]
[0m11:52:07  1 of 15 OK created sql view model final.stg_dwh__address ....................... [[32mCREATE VIEW[0m in 0.20s]
[0m11:52:07  2 of 15 START sql view model final.stg_dwh__address_status ..................... [RUN]
[0m11:52:07  2 of 15 OK created sql view model final.stg_dwh__address_status ................ [[32mCREATE VIEW[0m in 0.06s]
[0m11:52:07  3 of 15 START sql view model final.stg_dwh__author ............................. [RUN]
[0m11:52:07  3 of 15 OK created sql view model final.stg_dwh__author ........................ [[32mCREATE VIEW[0m in 0.05s]
[0m11:52:07  4 of 15 START sql view model final.stg_dwh__book ............................... [RUN]
[0m11:52:07  4 of 15 OK created sql view model final.stg_dwh__book .......................... [[32mCREATE VIEW[0m in 0.06s]
[0m11:52:07  5 of 15 START sql view model final.stg_dwh__book_author ........................ [RUN]
[0m11:52:07  5 of 15 OK created sql view model final.stg_dwh__book_author ................... [[32mCREATE VIEW[0m in 0.06s]
[0m11:52:07  6 of 15 START sql view model final.stg_dwh__book_language ...................... [RUN]
[0m11:52:07  6 of 15 OK created sql view model final.stg_dwh__book_language ................. [[32mCREATE VIEW[0m in 0.05s]
[0m11:52:07  7 of 15 START sql view model final.stg_dwh__country ............................ [RUN]
[0m11:52:08  7 of 15 OK created sql view model final.stg_dwh__country ....................... [[32mCREATE VIEW[0m in 0.06s]
[0m11:52:08  8 of 15 START sql view model final.stg_dwh__cust_order ......................... [RUN]
[0m11:52:08  8 of 15 OK created sql view model final.stg_dwh__cust_order .................... [[32mCREATE VIEW[0m in 0.06s]
[0m11:52:08  9 of 15 START sql view model final.stg_dwh__customer ........................... [RUN]
[0m11:52:08  9 of 15 OK created sql view model final.stg_dwh__customer ...................... [[32mCREATE VIEW[0m in 0.07s]
[0m11:52:08  10 of 15 START sql view model final.stg_dwh__customer_adress ................... [RUN]
[0m11:52:08  10 of 15 OK created sql view model final.stg_dwh__customer_adress .............. [[32mCREATE VIEW[0m in 0.06s]
[0m11:52:08  11 of 15 START sql view model final.stg_dwh__order_history ..................... [RUN]
[0m11:52:08  11 of 15 OK created sql view model final.stg_dwh__order_history ................ [[32mCREATE VIEW[0m in 0.14s]
[0m11:52:08  12 of 15 START sql view model final.stg_dwh__order_line ........................ [RUN]
[0m11:52:08  12 of 15 OK created sql view model final.stg_dwh__order_line ................... [[32mCREATE VIEW[0m in 0.07s]
[0m11:52:08  13 of 15 START sql view model final.stg_dwh__order_status ...................... [RUN]
[0m11:52:08  13 of 15 OK created sql view model final.stg_dwh__order_status ................. [[32mCREATE VIEW[0m in 0.06s]
[0m11:52:08  14 of 15 START sql view model final.stg_dwh__publisher ......................... [RUN]
[0m11:52:08  14 of 15 OK created sql view model final.stg_dwh__publisher .................... [[32mCREATE VIEW[0m in 0.06s]
[0m11:52:08  15 of 15 START sql view model final.stg_dwh__shipping_method ................... [RUN]
[0m11:52:08  15 of 15 OK created sql view model final.stg_dwh__shipping_method .............. [[32mCREATE VIEW[0m in 0.06s]
[0m11:52:08  
[0m11:52:08  Finished running 15 view models in 0 hours 0 minutes and 1.37 seconds (1.37s).
[0m11:52:08  
[0m11:52:08  [32mCompleted successfully[0m
[0m11:52:08  
[0m11:52:08  Done. PASS=15 WARN=0 ERROR=0 SKIP=0 TOTAL=15
[0m11:52:11  Running with dbt=1.9.0-b2
[0m11:52:12  Registered adapter: postgres=1.8.2
[0m11:52:12  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m11:52:12  
[0m11:52:12  Concurrency: 1 threads (target='dev')
[0m11:52:12  
[0m11:52:12  1 of 8 START snapshot final.dim_author ......................................... [RUN]
[0m11:52:13  1 of 8 OK snapshotted final.dim_author ......................................... [[32mSELECT 9235[0m in 0.30s]
[0m11:52:13  2 of 8 START snapshot final.dim_book ........................................... [RUN]
[0m11:52:13  2 of 8 OK snapshotted final.dim_book ........................................... [[32mSELECT 11127[0m in 0.11s]
[0m11:52:13  3 of 8 START snapshot final.dim_customer_address ............................... [RUN]
[0m11:52:13  3 of 8 OK snapshotted final.dim_customer_address ............................... [[32mSELECT 2950[0m in 0.07s]
[0m11:52:13  4 of 8 START snapshot final.dim_order_status ................................... [RUN]
[0m11:52:13  4 of 8 OK snapshotted final.dim_order_status ................................... [[32mSELECT 6[0m in 0.06s]
[0m11:52:13  5 of 8 START snapshot final.dim_shipping_method ................................ [RUN]
[0m11:52:13  5 of 8 OK snapshotted final.dim_shipping_method ................................ [[32mSELECT 4[0m in 0.05s]
[0m11:52:13  6 of 8 START snapshot final.fct_book_author_sales .............................. [RUN]
[0m11:52:13  6 of 8 OK snapshotted final.fct_book_author_sales .............................. [[32mSELECT 23838[0m in 0.26s]
[0m11:52:13  7 of 8 START snapshot final.fct_sales .......................................... [RUN]
[0m11:52:13  7 of 8 OK snapshotted final.fct_sales .......................................... [[32mSELECT 15400[0m in 0.15s]
[0m11:52:13  8 of 8 START snapshot final.fct_order .......................................... [RUN]
[0m11:52:14  8 of 8 OK snapshotted final.fct_order .......................................... [[32mSELECT 22345[0m in 0.88s]
[0m11:52:14  
[0m11:52:14  Finished running 8 snapshots in 0 hours 0 minutes and 2.06 seconds (2.06s).
[0m11:52:14  
[0m11:52:14  [32mCompleted successfully[0m
[0m11:52:14  
[0m11:52:14  Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m11:55:15  Running with dbt=1.9.0-b2
[0m11:55:15  Installing dbt-labs/dbt_utils
[0m11:55:16  Installed from version 1.1.1
[0m11:55:16  Updated version available: 1.3.0
[0m11:55:16  Installing calogica/dbt_date
[0m11:55:16  Installed from version 0.10.0
[0m11:55:16  Updated version available: 0.10.1
[0m11:55:16  
[0m11:55:16  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m11:55:20  Running with dbt=1.9.0-b2
[0m11:55:20  Registered adapter: postgres=1.8.2
[0m11:55:21  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m11:55:21  
[0m11:55:21  Concurrency: 1 threads (target='dev')
[0m11:55:21  
[0m11:55:21  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m11:57:55  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 153.90s]
[0m11:57:55  
[0m11:57:55  Finished running 1 seed in 0 hours 2 minutes and 34.06 seconds (154.06s).
[0m11:57:55  
[0m11:57:55  [32mCompleted successfully[0m
[0m11:57:55  
[0m11:57:55  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:57:58  Running with dbt=1.9.0-b2
[0m11:57:58  Registered adapter: postgres=1.8.2
[0m11:57:59  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m11:57:59  
[0m11:57:59  Concurrency: 1 threads (target='dev')
[0m11:57:59  
[0m11:57:59  1 of 15 START sql view model final.stg_dwh__address ............................ [RUN]
[0m11:57:59  1 of 15 OK created sql view model final.stg_dwh__address ....................... [[32mCREATE VIEW[0m in 0.24s]
[0m11:57:59  2 of 15 START sql view model final.stg_dwh__address_status ..................... [RUN]
[0m11:58:00  2 of 15 OK created sql view model final.stg_dwh__address_status ................ [[32mCREATE VIEW[0m in 0.06s]
[0m11:58:00  3 of 15 START sql view model final.stg_dwh__author ............................. [RUN]
[0m11:58:00  3 of 15 OK created sql view model final.stg_dwh__author ........................ [[32mCREATE VIEW[0m in 0.06s]
[0m11:58:00  4 of 15 START sql view model final.stg_dwh__book ............................... [RUN]
[0m11:58:00  4 of 15 OK created sql view model final.stg_dwh__book .......................... [[32mCREATE VIEW[0m in 0.06s]
[0m11:58:00  5 of 15 START sql view model final.stg_dwh__book_author ........................ [RUN]
[0m11:58:00  5 of 15 OK created sql view model final.stg_dwh__book_author ................... [[32mCREATE VIEW[0m in 0.06s]
[0m11:58:00  6 of 15 START sql view model final.stg_dwh__book_language ...................... [RUN]
[0m11:58:00  6 of 15 OK created sql view model final.stg_dwh__book_language ................. [[32mCREATE VIEW[0m in 0.05s]
[0m11:58:00  7 of 15 START sql view model final.stg_dwh__country ............................ [RUN]
[0m11:58:00  7 of 15 OK created sql view model final.stg_dwh__country ....................... [[32mCREATE VIEW[0m in 0.05s]
[0m11:58:00  8 of 15 START sql view model final.stg_dwh__cust_order ......................... [RUN]
[0m11:58:00  8 of 15 OK created sql view model final.stg_dwh__cust_order .................... [[32mCREATE VIEW[0m in 0.05s]
[0m11:58:00  9 of 15 START sql view model final.stg_dwh__customer ........................... [RUN]
[0m11:58:00  9 of 15 OK created sql view model final.stg_dwh__customer ...................... [[32mCREATE VIEW[0m in 0.06s]
[0m11:58:00  10 of 15 START sql view model final.stg_dwh__customer_adress ................... [RUN]
[0m11:58:00  10 of 15 OK created sql view model final.stg_dwh__customer_adress .............. [[32mCREATE VIEW[0m in 0.06s]
[0m11:58:00  11 of 15 START sql view model final.stg_dwh__order_history ..................... [RUN]
[0m11:58:00  11 of 15 OK created sql view model final.stg_dwh__order_history ................ [[32mCREATE VIEW[0m in 0.12s]
[0m11:58:00  12 of 15 START sql view model final.stg_dwh__order_line ........................ [RUN]
[0m11:58:00  12 of 15 OK created sql view model final.stg_dwh__order_line ................... [[32mCREATE VIEW[0m in 0.06s]
[0m11:58:00  13 of 15 START sql view model final.stg_dwh__order_status ...................... [RUN]
[0m11:58:00  13 of 15 OK created sql view model final.stg_dwh__order_status ................. [[32mCREATE VIEW[0m in 0.05s]
[0m11:58:00  14 of 15 START sql view model final.stg_dwh__publisher ......................... [RUN]
[0m11:58:00  14 of 15 OK created sql view model final.stg_dwh__publisher .................... [[32mCREATE VIEW[0m in 0.06s]
[0m11:58:00  15 of 15 START sql view model final.stg_dwh__shipping_method ................... [RUN]
[0m11:58:00  15 of 15 OK created sql view model final.stg_dwh__shipping_method .............. [[32mCREATE VIEW[0m in 0.06s]
[0m11:58:00  
[0m11:58:00  Finished running 15 view models in 0 hours 0 minutes and 1.35 seconds (1.35s).
[0m11:58:00  
[0m11:58:00  [32mCompleted successfully[0m
[0m11:58:00  
[0m11:58:00  Done. PASS=15 WARN=0 ERROR=0 SKIP=0 TOTAL=15
[0m11:58:04  Running with dbt=1.9.0-b2
[0m11:58:04  Registered adapter: postgres=1.8.2
[0m11:58:05  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m11:58:05  
[0m11:58:05  Concurrency: 1 threads (target='dev')
[0m11:58:05  
[0m11:58:05  1 of 8 START snapshot final.dim_author ......................................... [RUN]
[0m11:58:05  1 of 8 OK snapshotted final.dim_author ......................................... [[32mSELECT 9235[0m in 0.38s]
[0m11:58:05  2 of 8 START snapshot final.dim_book ........................................... [RUN]
[0m11:58:05  2 of 8 OK snapshotted final.dim_book ........................................... [[32mSELECT 11127[0m in 0.12s]
[0m11:58:05  3 of 8 START snapshot final.dim_customer_address ............................... [RUN]
[0m11:58:06  3 of 8 OK snapshotted final.dim_customer_address ............................... [[32mSELECT 2950[0m in 0.08s]
[0m11:58:06  4 of 8 START snapshot final.dim_order_status ................................... [RUN]
[0m11:58:06  4 of 8 OK snapshotted final.dim_order_status ................................... [[32mSELECT 6[0m in 0.05s]
[0m11:58:06  5 of 8 START snapshot final.dim_shipping_method ................................ [RUN]
[0m11:58:06  5 of 8 OK snapshotted final.dim_shipping_method ................................ [[32mSELECT 4[0m in 0.05s]
[0m11:58:06  6 of 8 START snapshot final.fct_book_author_sales .............................. [RUN]
[0m11:58:06  6 of 8 OK snapshotted final.fct_book_author_sales .............................. [[32mSELECT 23838[0m in 0.26s]
[0m11:58:06  7 of 8 START snapshot final.fct_sales .......................................... [RUN]
[0m11:58:06  7 of 8 OK snapshotted final.fct_sales .......................................... [[32mSELECT 15400[0m in 0.15s]
[0m11:58:06  8 of 8 START snapshot final.fct_order .......................................... [RUN]
[0m11:58:07  8 of 8 OK snapshotted final.fct_order .......................................... [[32mSELECT 22345[0m in 0.95s]
[0m11:58:07  
[0m11:58:07  Finished running 8 snapshots in 0 hours 0 minutes and 2.27 seconds (2.27s).
[0m11:58:07  
[0m11:58:07  [32mCompleted successfully[0m
[0m11:58:07  
[0m11:58:07  Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2024-11-09 19:00:05,248 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 19:00:05,250 - ERROR - EXTRACT 'address' - FAILED.
2024-11-09 19:00:05,250 - INFO - Extract All Tables From Sources - FAILED
2024-11-09 19:00:05,253 - ERROR - [pid 244889] Worker Worker(salt=4100403174, workers=1, host=Erlina, username=istywhyerlina, pid=244889) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 62, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3278, in connect
    return self._connection_cls(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2442, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 71, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 110, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-11-09 19:00:05,263 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:00:05,267 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-09 19:00:05,267 - DEBUG - Asking scheduler for work...
2024-11-09 19:00:05,267 - DEBUG - Done
2024-11-09 19:00:05,268 - DEBUG - There are no more tasks to run at this time
2024-11-09 19:00:05,268 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-11-09 19:00:05,268 - DEBUG - There are 3 pending tasks unique to this worker
2024-11-09 19:00:05,268 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-11-09 19:00:05,268 - INFO - Worker Worker(salt=4100403174, workers=1, host=Erlina, username=istywhyerlina, pid=244889) was stopped. Shutting down Keep-Alive thread
2024-11-09 19:00:05,269 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 19:00:32,828 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 19:00:32,830 - ERROR - EXTRACT 'address' - FAILED.
2024-11-09 19:00:32,830 - INFO - Extract All Tables From Sources - FAILED
2024-11-09 19:00:32,834 - ERROR - [pid 245221] Worker Worker(salt=6433333992, workers=1, host=Erlina, username=istywhyerlina, pid=245221) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 62, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3278, in connect
    return self._connection_cls(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2442, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 71, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 110, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-11-09 19:00:32,838 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:00:32,842 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-09 19:00:32,843 - DEBUG - Asking scheduler for work...
2024-11-09 19:00:32,843 - DEBUG - Done
2024-11-09 19:00:32,843 - DEBUG - There are no more tasks to run at this time
2024-11-09 19:00:32,843 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-11-09 19:00:32,843 - DEBUG - There are 3 pending tasks unique to this worker
2024-11-09 19:00:32,843 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-11-09 19:00:32,844 - INFO - Worker Worker(salt=6433333992, workers=1, host=Erlina, username=istywhyerlina, pid=245221) was stopped. Shutting down Keep-Alive thread
2024-11-09 19:00:32,846 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 19:16:38,047 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 19:16:38,086 - ERROR - EXTRACT 'address' - FAILED.
2024-11-09 19:16:38,086 - INFO - Extract All Tables From Sources - FAILED
2024-11-09 19:16:38,100 - ERROR - [pid 6933] Worker Worker(salt=5645340869, workers=1, host=Erlina, username=istywhyerlina, pid=6933) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 62, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3278, in connect
    return self._connection_cls(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2442, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 71, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 110, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-11-09 19:16:38,118 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:16:38,122 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-09 19:16:38,122 - DEBUG - Asking scheduler for work...
2024-11-09 19:16:38,123 - DEBUG - Done
2024-11-09 19:16:38,123 - DEBUG - There are no more tasks to run at this time
2024-11-09 19:16:38,123 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-11-09 19:16:38,123 - DEBUG - There are 3 pending tasks unique to this worker
2024-11-09 19:16:38,123 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-11-09 19:16:38,123 - INFO - Worker Worker(salt=5645340869, workers=1, host=Erlina, username=istywhyerlina, pid=6933) was stopped. Shutting down Keep-Alive thread
2024-11-09 19:16:38,126 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 19:19:35,146 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 19:19:35,216 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 19:19:35,219 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 19:19:35,251 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 19:19:35,316 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 19:19:35,349 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 19:19:35,353 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 19:19:35,357 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 19:19:35,435 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 19:19:35,445 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 19:19:35,456 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 19:19:35,575 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 19:19:35,642 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 19:19:35,646 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 19:19:35,653 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 19:19:35,656 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 19:19:35,657 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 19:19:35,658 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 19:19:35,658 - INFO - [pid 8891] Worker Worker(salt=5199079876, workers=1, host=Erlina, username=istywhyerlina, pid=8891) done      Extract()
2024-11-09 19:19:35,659 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:19:35,660 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 19:19:35,660 - DEBUG - Asking scheduler for work...
2024-11-09 19:19:35,661 - DEBUG - Done
2024-11-09 19:19:35,661 - DEBUG - There are no more tasks to run at this time
2024-11-09 19:19:35,661 - INFO - Worker Worker(salt=5199079876, workers=1, host=Erlina, username=istywhyerlina, pid=8891) was stopped. Shutting down Keep-Alive thread
2024-11-09 19:19:35,662 - INFO - 
===== Luigi Execution Summary =====

Scheduled 1 tasks of which:
* 1 ran successfully:
    - 1 Extract()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 19:20:01,684 - INFO - Read Load Query - SUCCESS
2024-11-09 19:20:01,768 - INFO - Read Extracted Data - SUCCESS
2024-11-09 19:20:01,805 - INFO - Connect to DWH - SUCCESS
2024-11-09 19:20:01,852 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 19:20:01,852 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 19:20:01,868 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 19:20:01,909 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 19:20:01,916 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 19:20:02,008 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 19:20:02,316 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 19:20:02,487 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 19:20:02,493 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 19:20:02,628 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 19:20:02,671 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 19:20:02,719 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 19:20:03,088 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 19:20:03,341 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 19:20:03,345 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 19:20:03,370 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 19:20:03,375 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 19:20:03,375 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 19:20:03,377 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 19:20:03,378 - INFO - [pid 9141] Worker Worker(salt=2287251795, workers=1, host=Erlina, username=istywhyerlina, pid=9141) done      Load()
2024-11-09 19:20:03,379 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:20:03,379 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 19:20:03,379 - DEBUG - Asking scheduler for work...
2024-11-09 19:20:03,380 - DEBUG - Pending tasks: 1
2024-11-09 19:20:03,380 - INFO - [pid 9141] Worker Worker(salt=2287251795, workers=1, host=Erlina, username=istywhyerlina, pid=9141) running   Transform()
2024-11-09 19:20:03,380 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m12:20:05  Running with dbt=1.9.0-b2
[0m12:20:06  Installing dbt-labs/dbt_utils
[0m12:20:06  Installed from version 1.1.1
[0m12:20:06  Updated version available: 1.3.0
[0m12:20:06  Installing calogica/dbt_date
[0m12:20:07  Installed from version 0.10.0
[0m12:20:07  Updated version available: 0.10.1
[0m12:20:07  
[0m12:20:07  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m12:20:10  Running with dbt=1.9.0-b2
[0m12:20:11  Registered adapter: postgres=1.8.2
[0m12:20:11  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m12:20:11  
[0m12:20:11  Concurrency: 1 threads (target='dev')
[0m12:20:11  
[0m12:20:12  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m12:22:35  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 143.20s]
[0m12:22:35  
[0m12:22:35  Finished running 1 seed in 0 hours 2 minutes and 23.39 seconds (143.39s).
[0m12:22:35  
[0m12:22:35  [32mCompleted successfully[0m
[0m12:22:35  
[0m12:22:35  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m12:22:38  Running with dbt=1.9.0-b2
[0m12:22:38  Registered adapter: postgres=1.8.2
[0m12:22:38  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m12:22:38  
[0m12:22:38  Concurrency: 1 threads (target='dev')
[0m12:22:38  
[0m12:22:39  1 of 15 START sql view model final.stg_dwh__address ............................ [RUN]
[0m12:22:39  1 of 15 OK created sql view model final.stg_dwh__address ....................... [[32mCREATE VIEW[0m in 0.17s]
[0m12:22:39  2 of 15 START sql view model final.stg_dwh__address_status ..................... [RUN]
[0m12:22:39  2 of 15 OK created sql view model final.stg_dwh__address_status ................ [[32mCREATE VIEW[0m in 0.04s]
[0m12:22:39  3 of 15 START sql view model final.stg_dwh__author ............................. [RUN]
[0m12:22:39  3 of 15 OK created sql view model final.stg_dwh__author ........................ [[32mCREATE VIEW[0m in 0.05s]
[0m12:22:39  4 of 15 START sql view model final.stg_dwh__book ............................... [RUN]
[0m12:22:39  4 of 15 OK created sql view model final.stg_dwh__book .......................... [[32mCREATE VIEW[0m in 0.05s]
[0m12:22:39  5 of 15 START sql view model final.stg_dwh__book_author ........................ [RUN]
[0m12:22:39  5 of 15 OK created sql view model final.stg_dwh__book_author ................... [[32mCREATE VIEW[0m in 0.04s]
[0m12:22:39  6 of 15 START sql view model final.stg_dwh__book_language ...................... [RUN]
[0m12:22:39  6 of 15 OK created sql view model final.stg_dwh__book_language ................. [[32mCREATE VIEW[0m in 0.05s]
[0m12:22:39  7 of 15 START sql view model final.stg_dwh__country ............................ [RUN]
[0m12:22:39  7 of 15 OK created sql view model final.stg_dwh__country ....................... [[32mCREATE VIEW[0m in 0.05s]
[0m12:22:39  8 of 15 START sql view model final.stg_dwh__cust_order ......................... [RUN]
[0m12:22:39  8 of 15 OK created sql view model final.stg_dwh__cust_order .................... [[32mCREATE VIEW[0m in 0.05s]
[0m12:22:39  9 of 15 START sql view model final.stg_dwh__customer ........................... [RUN]
[0m12:22:39  9 of 15 OK created sql view model final.stg_dwh__customer ...................... [[32mCREATE VIEW[0m in 0.04s]
[0m12:22:39  10 of 15 START sql view model final.stg_dwh__customer_adress ................... [RUN]
[0m12:22:39  10 of 15 OK created sql view model final.stg_dwh__customer_adress .............. [[32mCREATE VIEW[0m in 0.04s]
[0m12:22:39  11 of 15 START sql view model final.stg_dwh__order_history ..................... [RUN]
[0m12:22:39  11 of 15 OK created sql view model final.stg_dwh__order_history ................ [[32mCREATE VIEW[0m in 0.05s]
[0m12:22:39  12 of 15 START sql view model final.stg_dwh__order_line ........................ [RUN]
[0m12:22:39  12 of 15 OK created sql view model final.stg_dwh__order_line ................... [[32mCREATE VIEW[0m in 0.04s]
[0m12:22:39  13 of 15 START sql view model final.stg_dwh__order_status ...................... [RUN]
[0m12:22:39  13 of 15 OK created sql view model final.stg_dwh__order_status ................. [[32mCREATE VIEW[0m in 0.04s]
[0m12:22:39  14 of 15 START sql view model final.stg_dwh__publisher ......................... [RUN]
[0m12:22:39  14 of 15 OK created sql view model final.stg_dwh__publisher .................... [[32mCREATE VIEW[0m in 0.04s]
[0m12:22:39  15 of 15 START sql view model final.stg_dwh__shipping_method ................... [RUN]
[0m12:22:39  15 of 15 OK created sql view model final.stg_dwh__shipping_method .............. [[32mCREATE VIEW[0m in 0.05s]
[0m12:22:39  
[0m12:22:40  Finished running 15 view models in 0 hours 0 minutes and 1.01 seconds (1.01s).
[0m12:22:40  
[0m12:22:40  [32mCompleted successfully[0m
[0m12:22:40  
[0m12:22:40  Done. PASS=15 WARN=0 ERROR=0 SKIP=0 TOTAL=15
[0m12:22:43  Running with dbt=1.9.0-b2
[0m12:22:43  Registered adapter: postgres=1.8.2
[0m12:22:44  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m12:22:44  
[0m12:22:44  Concurrency: 1 threads (target='dev')
[0m12:22:44  
[0m12:22:44  1 of 8 START snapshot final.dim_author ......................................... [RUN]
[0m12:22:44  1 of 8 OK snapshotted final.dim_author ......................................... [[32mSELECT 9235[0m in 0.26s]
[0m12:22:44  2 of 8 START snapshot final.dim_book ........................................... [RUN]
[0m12:22:44  2 of 8 OK snapshotted final.dim_book ........................................... [[32mSELECT 11127[0m in 0.10s]
[0m12:22:44  3 of 8 START snapshot final.dim_customer_address ............................... [RUN]
[0m12:22:45  3 of 8 OK snapshotted final.dim_customer_address ............................... [[32mSELECT 2950[0m in 0.07s]
[0m12:22:45  4 of 8 START snapshot final.dim_order_status ................................... [RUN]
[0m12:22:45  4 of 8 OK snapshotted final.dim_order_status ................................... [[32mSELECT 6[0m in 0.05s]
[0m12:22:45  5 of 8 START snapshot final.dim_shipping_method ................................ [RUN]
[0m12:22:45  5 of 8 OK snapshotted final.dim_shipping_method ................................ [[32mSELECT 4[0m in 0.05s]
[0m12:22:45  6 of 8 START snapshot final.fct_book_author_sales .............................. [RUN]
[0m12:22:45  6 of 8 OK snapshotted final.fct_book_author_sales .............................. [[32mSELECT 23838[0m in 0.26s]
[0m12:22:45  7 of 8 START snapshot final.fct_sales .......................................... [RUN]
[0m12:22:45  7 of 8 OK snapshotted final.fct_sales .......................................... [[32mSELECT 15400[0m in 0.16s]
[0m12:22:45  8 of 8 START snapshot final.fct_order .......................................... [RUN]
[0m12:22:46  8 of 8 OK snapshotted final.fct_order .......................................... [[32mSELECT 22345[0m in 1.38s]
[0m12:22:46  
[0m12:22:46  Finished running 8 snapshots in 0 hours 0 minutes and 2.51 seconds (2.51s).
[0m12:22:47  
[0m12:22:47  [32mCompleted successfully[0m
[0m12:22:47  
[0m12:22:47  Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2024-11-09 19:22:48,671 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-09 19:22:48,671 - INFO - [pid 9141] Worker Worker(salt=2287251795, workers=1, host=Erlina, username=istywhyerlina, pid=9141) done      Transform()
2024-11-09 19:22:48,672 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:22:48,672 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-09 19:22:48,673 - DEBUG - Asking scheduler for work...
2024-11-09 19:22:48,673 - DEBUG - Done
2024-11-09 19:22:48,673 - DEBUG - There are no more tasks to run at this time
2024-11-09 19:22:48,673 - INFO - Worker Worker(salt=2287251795, workers=1, host=Erlina, username=istywhyerlina, pid=9141) was stopped. Shutting down Keep-Alive thread
2024-11-09 19:22:48,674 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 complete ones were encountered:
    - 1 Extract()
* 2 ran successfully:
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 19:25:58,130 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 19:25:58,158 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 19:25:58,161 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 19:25:58,184 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 19:25:58,265 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 19:25:58,303 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 19:25:58,306 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 19:25:58,310 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 19:25:58,392 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 19:25:58,402 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 19:25:58,413 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 19:25:58,530 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 19:25:58,589 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 19:25:58,592 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 19:25:58,599 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 19:25:58,602 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 19:25:58,603 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 19:25:58,604 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 19:25:58,604 - INFO - [pid 13029] Worker Worker(salt=9945828745, workers=1, host=Erlina, username=istywhyerlina, pid=13029) done      Extract()
2024-11-09 19:25:58,605 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:25:58,606 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 19:25:58,606 - DEBUG - Asking scheduler for work...
2024-11-09 19:25:58,606 - DEBUG - Done
2024-11-09 19:25:58,606 - DEBUG - There are no more tasks to run at this time
2024-11-09 19:25:58,606 - INFO - Worker Worker(salt=9945828745, workers=1, host=Erlina, username=istywhyerlina, pid=13029) was stopped. Shutting down Keep-Alive thread
2024-11-09 19:25:58,607 - INFO - 
===== Luigi Execution Summary =====

Scheduled 1 tasks of which:
* 1 ran successfully:
    - 1 Extract()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 19:26:57,874 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 19:26:57,896 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 19:26:57,899 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 19:26:57,919 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 19:26:57,996 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 19:26:58,059 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 19:26:58,062 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 19:26:58,066 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 19:26:58,118 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 19:26:58,127 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 19:26:58,141 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 19:26:58,257 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 19:26:58,359 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 19:26:58,362 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 19:26:58,370 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 19:26:58,374 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 19:26:58,374 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 19:26:58,376 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 19:26:58,376 - INFO - [pid 13679] Worker Worker(salt=8328114741, workers=1, host=Erlina, username=istywhyerlina, pid=13679) done      Extract()
2024-11-09 19:26:58,378 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:26:58,378 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 19:26:58,379 - DEBUG - Asking scheduler for work...
2024-11-09 19:26:58,379 - DEBUG - Pending tasks: 1
2024-11-09 19:26:58,379 - INFO - [pid 13679] Worker Worker(salt=8328114741, workers=1, host=Erlina, username=istywhyerlina, pid=13679) running   Load()
2024-11-09 19:26:58,380 - INFO - Read Load Query - SUCCESS
2024-11-09 19:26:58,469 - INFO - Read Extracted Data - SUCCESS
2024-11-09 19:26:58,471 - INFO - Connect to DWH - SUCCESS
2024-11-09 19:26:58,516 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 19:26:58,516 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 19:26:58,534 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 19:26:58,568 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 19:26:58,574 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 19:26:58,676 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 19:26:59,085 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 19:26:59,303 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 19:26:59,311 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 19:26:59,465 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 19:26:59,508 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 19:26:59,559 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 19:26:59,966 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 19:27:00,212 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 19:27:00,218 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 19:27:00,274 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 19:27:00,280 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 19:27:00,280 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 19:27:00,282 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 19:27:00,283 - INFO - [pid 13679] Worker Worker(salt=8328114741, workers=1, host=Erlina, username=istywhyerlina, pid=13679) done      Load()
2024-11-09 19:27:00,283 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:27:00,284 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 19:27:00,284 - DEBUG - Asking scheduler for work...
2024-11-09 19:27:00,284 - DEBUG - Done
2024-11-09 19:27:00,284 - DEBUG - There are no more tasks to run at this time
2024-11-09 19:27:00,285 - INFO - Worker Worker(salt=8328114741, workers=1, host=Erlina, username=istywhyerlina, pid=13679) was stopped. Shutting down Keep-Alive thread
2024-11-09 19:27:00,285 - INFO - 
===== Luigi Execution Summary =====

Scheduled 2 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-09 19:29:07,768 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 19:29:07,792 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 19:29:07,796 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 19:29:07,822 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 19:29:07,897 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 19:29:07,960 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 19:29:07,964 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 19:29:07,969 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 19:29:08,021 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 19:29:08,034 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 19:29:08,044 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 19:29:08,153 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 19:29:08,244 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 19:29:08,247 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 19:29:08,254 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 19:29:08,257 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 19:29:08,257 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 19:29:08,258 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 19:29:08,258 - INFO - [pid 14882] Worker Worker(salt=9347914090, workers=1, host=Erlina, username=istywhyerlina, pid=14882) done      Extract()
2024-11-09 19:29:08,259 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:29:08,260 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 19:29:08,260 - DEBUG - Asking scheduler for work...
2024-11-09 19:29:08,260 - DEBUG - Pending tasks: 2
2024-11-09 19:29:08,260 - INFO - [pid 14882] Worker Worker(salt=9347914090, workers=1, host=Erlina, username=istywhyerlina, pid=14882) running   Load()
2024-11-09 19:29:08,261 - INFO - Read Load Query - SUCCESS
2024-11-09 19:29:08,332 - INFO - Read Extracted Data - SUCCESS
2024-11-09 19:29:08,333 - INFO - Connect to DWH - SUCCESS
2024-11-09 19:29:08,385 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 19:29:08,385 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 19:29:08,401 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 19:29:08,437 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 19:29:08,443 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 19:29:08,549 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 19:29:08,869 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 19:29:09,061 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 19:29:09,068 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 19:29:09,211 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 19:29:09,258 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 19:29:09,305 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 19:29:09,679 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 19:29:09,912 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 19:29:09,917 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 19:29:09,968 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 19:29:09,973 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 19:29:09,974 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 19:29:09,975 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 19:29:09,976 - INFO - [pid 14882] Worker Worker(salt=9347914090, workers=1, host=Erlina, username=istywhyerlina, pid=14882) done      Load()
2024-11-09 19:29:09,976 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:29:09,977 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 19:29:09,977 - DEBUG - Asking scheduler for work...
2024-11-09 19:29:09,977 - DEBUG - Pending tasks: 1
2024-11-09 19:29:09,977 - INFO - [pid 14882] Worker Worker(salt=9347914090, workers=1, host=Erlina, username=istywhyerlina, pid=14882) running   Transform()
2024-11-09 19:29:09,978 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m12:29:11  Running with dbt=1.9.0-b2
[0m12:29:11  Installing dbt-labs/dbt_utils
[0m12:29:12  Installed from version 1.1.1
[0m12:29:12  Updated version available: 1.3.0
[0m12:29:12  Installing calogica/dbt_date
[0m12:29:12  Installed from version 0.10.0
[0m12:29:12  Updated version available: 0.10.1
[0m12:29:12  
[0m12:29:12  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m12:29:17  Running with dbt=1.9.0-b2
[0m12:29:17  Registered adapter: postgres=1.8.2
[0m12:29:18  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m12:29:18  
[0m12:29:18  Concurrency: 1 threads (target='dev')
[0m12:29:18  
[0m12:29:18  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m12:31:45  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 147.38s]
[0m12:31:45  
[0m12:31:45  Finished running 1 seed in 0 hours 2 minutes and 27.56 seconds (147.56s).
[0m12:31:45  
[0m12:31:45  [32mCompleted successfully[0m
[0m12:31:45  
[0m12:31:45  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m12:31:49  Running with dbt=1.9.0-b2
[0m12:31:50  Registered adapter: postgres=1.8.2
[0m12:31:50  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m12:31:50  
[0m12:31:50  Concurrency: 1 threads (target='dev')
[0m12:31:50  
[0m12:31:50  1 of 15 START sql view model final.stg_dwh__address ............................ [RUN]
[0m12:31:50  1 of 15 OK created sql view model final.stg_dwh__address ....................... [[32mCREATE VIEW[0m in 0.20s]
[0m12:31:50  2 of 15 START sql view model final.stg_dwh__address_status ..................... [RUN]
[0m12:31:51  2 of 15 OK created sql view model final.stg_dwh__address_status ................ [[32mCREATE VIEW[0m in 0.06s]
[0m12:31:51  3 of 15 START sql view model final.stg_dwh__author ............................. [RUN]
[0m12:31:51  3 of 15 OK created sql view model final.stg_dwh__author ........................ [[32mCREATE VIEW[0m in 0.06s]
[0m12:31:51  4 of 15 START sql view model final.stg_dwh__book ............................... [RUN]
[0m12:31:51  4 of 15 OK created sql view model final.stg_dwh__book .......................... [[32mCREATE VIEW[0m in 0.05s]
[0m12:31:51  5 of 15 START sql view model final.stg_dwh__book_author ........................ [RUN]
[0m12:31:51  5 of 15 OK created sql view model final.stg_dwh__book_author ................... [[32mCREATE VIEW[0m in 0.05s]
[0m12:31:51  6 of 15 START sql view model final.stg_dwh__book_language ...................... [RUN]
[0m12:31:51  6 of 15 OK created sql view model final.stg_dwh__book_language ................. [[32mCREATE VIEW[0m in 0.05s]
[0m12:31:51  7 of 15 START sql view model final.stg_dwh__country ............................ [RUN]
[0m12:31:51  7 of 15 OK created sql view model final.stg_dwh__country ....................... [[32mCREATE VIEW[0m in 0.05s]
[0m12:31:51  8 of 15 START sql view model final.stg_dwh__cust_order ......................... [RUN]
[0m12:31:51  8 of 15 OK created sql view model final.stg_dwh__cust_order .................... [[32mCREATE VIEW[0m in 0.06s]
[0m12:31:51  9 of 15 START sql view model final.stg_dwh__customer ........................... [RUN]
[0m12:31:51  9 of 15 OK created sql view model final.stg_dwh__customer ...................... [[32mCREATE VIEW[0m in 0.07s]
[0m12:31:51  10 of 15 START sql view model final.stg_dwh__customer_adress ................... [RUN]
[0m12:31:51  10 of 15 OK created sql view model final.stg_dwh__customer_adress .............. [[32mCREATE VIEW[0m in 0.06s]
[0m12:31:51  11 of 15 START sql view model final.stg_dwh__order_history ..................... [RUN]
[0m12:31:51  11 of 15 OK created sql view model final.stg_dwh__order_history ................ [[32mCREATE VIEW[0m in 0.06s]
[0m12:31:51  12 of 15 START sql view model final.stg_dwh__order_line ........................ [RUN]
[0m12:31:51  12 of 15 OK created sql view model final.stg_dwh__order_line ................... [[32mCREATE VIEW[0m in 0.11s]
[0m12:31:51  13 of 15 START sql view model final.stg_dwh__order_status ...................... [RUN]
[0m12:31:51  13 of 15 OK created sql view model final.stg_dwh__order_status ................. [[32mCREATE VIEW[0m in 0.07s]
[0m12:31:51  14 of 15 START sql view model final.stg_dwh__publisher ......................... [RUN]
[0m12:31:51  14 of 15 OK created sql view model final.stg_dwh__publisher .................... [[32mCREATE VIEW[0m in 0.06s]
[0m12:31:51  15 of 15 START sql view model final.stg_dwh__shipping_method ................... [RUN]
[0m12:31:51  15 of 15 OK created sql view model final.stg_dwh__shipping_method .............. [[32mCREATE VIEW[0m in 0.06s]
[0m12:31:51  
[0m12:31:51  Finished running 15 view models in 0 hours 0 minutes and 1.29 seconds (1.29s).
[0m12:31:51  
[0m12:31:51  [32mCompleted successfully[0m
[0m12:31:51  
[0m12:31:51  Done. PASS=15 WARN=0 ERROR=0 SKIP=0 TOTAL=15
[0m12:31:55  Running with dbt=1.9.0-b2
[0m12:31:55  Registered adapter: postgres=1.8.2
[0m12:31:56  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m12:31:56  
[0m12:31:56  Concurrency: 1 threads (target='dev')
[0m12:31:56  
[0m12:31:56  1 of 8 START snapshot final.dim_author ......................................... [RUN]
[0m12:31:56  1 of 8 OK snapshotted final.dim_author ......................................... [[32mINSERT 0 0[0m in 0.46s]
[0m12:31:56  2 of 8 START snapshot final.dim_book ........................................... [RUN]
[0m12:31:56  2 of 8 OK snapshotted final.dim_book ........................................... [[32mINSERT 0 0[0m in 0.37s]
[0m12:31:56  3 of 8 START snapshot final.dim_customer_address ............................... [RUN]
[0m12:31:57  3 of 8 OK snapshotted final.dim_customer_address ............................... [[32mINSERT 0 0[0m in 0.17s]
[0m12:31:57  4 of 8 START snapshot final.dim_order_status ................................... [RUN]
[0m12:31:57  4 of 8 OK snapshotted final.dim_order_status ................................... [[32mINSERT 0 0[0m in 0.15s]
[0m12:31:57  5 of 8 START snapshot final.dim_shipping_method ................................ [RUN]
[0m12:31:57  5 of 8 OK snapshotted final.dim_shipping_method ................................ [[32mINSERT 0 0[0m in 0.13s]
[0m12:31:57  6 of 8 START snapshot final.fct_book_author_sales .............................. [RUN]
[0m12:31:57  6 of 8 OK snapshotted final.fct_book_author_sales .............................. [[32mINSERT 0 0[0m in 0.53s]
[0m12:31:57  7 of 8 START snapshot final.fct_sales .......................................... [RUN]
[0m12:31:58  7 of 8 OK snapshotted final.fct_sales .......................................... [[32mINSERT 0 0[0m in 0.41s]
[0m12:31:58  8 of 8 START snapshot final.fct_order .......................................... [RUN]
[0m12:32:00  8 of 8 OK snapshotted final.fct_order .......................................... [[32mINSERT 0 26400[0m in 1.80s]
[0m12:32:00  
[0m12:32:00  Finished running 8 snapshots in 0 hours 0 minutes and 4.22 seconds (4.22s).
[0m12:32:00  
[0m12:32:00  [32mCompleted successfully[0m
[0m12:32:00  
[0m12:32:00  Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2024-11-09 19:32:02,129 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-09 19:32:02,129 - INFO - [pid 14882] Worker Worker(salt=9347914090, workers=1, host=Erlina, username=istywhyerlina, pid=14882) done      Transform()
2024-11-09 19:32:02,130 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 19:32:02,130 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-09 19:32:02,131 - DEBUG - Asking scheduler for work...
2024-11-09 19:32:02,131 - DEBUG - Done
2024-11-09 19:32:02,131 - DEBUG - There are no more tasks to run at this time
2024-11-09 19:32:02,131 - INFO - Worker Worker(salt=9347914090, workers=1, host=Erlina, username=istywhyerlina, pid=14882) was stopped. Shutting down Keep-Alive thread
2024-11-09 19:32:02,133 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

/home/istywhyerlina/fp_datastorage/PacbookDWH/run_etl.sh: 11: python: not found
/home/istywhyerlina/fp_datastorage/PacbookDWH/run_etl.sh: 11: python: not found
/home/istywhyerlina/fp_datastorage/PacbookDWH/run_etl.sh: 11: python: not found
/home/istywhyerlina/fp_datastorage/PacbookDWH/run_etl.sh: 11: python: not found
/home/istywhyerlina/fp_datastorage/PacbookDWH/run_etl.sh: 11: python: not found
2024-11-09 20:36:54,411 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 20:36:54,482 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 20:36:54,484 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 20:36:54,495 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 20:36:54,530 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 20:36:54,563 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 20:36:54,565 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 20:36:54,567 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 20:36:54,591 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 20:36:54,595 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 20:36:54,600 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 20:36:54,655 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 20:36:54,701 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 20:36:54,703 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 20:36:54,707 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 20:36:54,708 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 20:36:54,708 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 20:36:54,709 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 20:36:54,709 - INFO - [pid 63963] Worker Worker(salt=7956625501, workers=1, host=Erlina, username=istywhyerlina, pid=63963) done      Extract()
2024-11-09 20:36:54,710 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 20:36:54,710 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 20:36:54,710 - DEBUG - Asking scheduler for work...
2024-11-09 20:36:54,710 - DEBUG - Pending tasks: 2
2024-11-09 20:36:54,710 - INFO - [pid 63963] Worker Worker(salt=7956625501, workers=1, host=Erlina, username=istywhyerlina, pid=63963) running   Load()
2024-11-09 20:36:54,711 - INFO - Read Load Query - SUCCESS
2024-11-09 20:36:54,750 - INFO - Read Extracted Data - SUCCESS
2024-11-09 20:36:54,751 - INFO - Connect to DWH - SUCCESS
2024-11-09 20:36:54,769 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 20:36:54,769 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 20:36:54,776 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 20:36:54,791 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 20:36:54,794 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 20:36:54,848 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 20:36:55,011 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 20:36:55,112 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 20:36:55,117 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 20:36:55,182 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 20:36:55,203 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 20:36:55,225 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 20:36:55,400 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 20:36:55,513 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 20:36:55,516 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 20:36:55,549 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 20:36:55,553 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 20:36:55,553 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 20:36:55,554 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 20:36:55,554 - INFO - [pid 63963] Worker Worker(salt=7956625501, workers=1, host=Erlina, username=istywhyerlina, pid=63963) done      Load()
2024-11-09 20:36:55,554 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 20:36:55,555 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 20:36:55,555 - DEBUG - Asking scheduler for work...
2024-11-09 20:36:55,555 - DEBUG - Pending tasks: 1
2024-11-09 20:36:55,555 - INFO - [pid 63963] Worker Worker(salt=7956625501, workers=1, host=Erlina, username=istywhyerlina, pid=63963) running   Transform()
2024-11-09 20:36:55,555 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m13:36:56  Running with dbt=1.9.0-b2
[0m13:36:57  Installing dbt-labs/dbt_utils
[0m13:36:58  Installed from version 1.1.1
[0m13:36:58  Updated version available: 1.3.0
[0m13:36:58  Installing calogica/dbt_date
[0m13:36:58  Installed from version 0.10.0
[0m13:36:58  Updated version available: 0.10.1
[0m13:36:58  
[0m13:36:58  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m13:37:00  Running with dbt=1.9.0-b2
[0m13:37:00  Registered adapter: postgres=1.8.2
[0m13:37:01  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m13:37:01  
[0m13:37:01  Concurrency: 1 threads (target='dev')
[0m13:37:01  
[0m13:37:01  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m13:38:30  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 89.66s]
[0m13:38:30  
[0m13:38:30  Finished running 1 seed in 0 hours 1 minutes and 29.78 seconds (89.78s).
[0m13:38:30  
[0m13:38:30  [32mCompleted successfully[0m
[0m13:38:30  
[0m13:38:30  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m13:38:33  Running with dbt=1.9.0-b2
[0m13:38:33  Registered adapter: postgres=1.8.2
[0m13:38:34  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m13:38:34  
[0m13:38:34  Concurrency: 1 threads (target='dev')
[0m13:38:34  
[0m13:38:34  1 of 15 START sql view model final.stg_dwh__address ............................ [RUN]
[0m13:38:34  1 of 15 OK created sql view model final.stg_dwh__address ....................... [[32mCREATE VIEW[0m in 0.13s]
[0m13:38:34  2 of 15 START sql view model final.stg_dwh__address_status ..................... [RUN]
[0m13:38:34  2 of 15 OK created sql view model final.stg_dwh__address_status ................ [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  3 of 15 START sql view model final.stg_dwh__author ............................. [RUN]
[0m13:38:34  3 of 15 OK created sql view model final.stg_dwh__author ........................ [[32mCREATE VIEW[0m in 0.05s]
[0m13:38:34  4 of 15 START sql view model final.stg_dwh__book ............................... [RUN]
[0m13:38:34  4 of 15 OK created sql view model final.stg_dwh__book .......................... [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  5 of 15 START sql view model final.stg_dwh__book_author ........................ [RUN]
[0m13:38:34  5 of 15 OK created sql view model final.stg_dwh__book_author ................... [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  6 of 15 START sql view model final.stg_dwh__book_language ...................... [RUN]
[0m13:38:34  6 of 15 OK created sql view model final.stg_dwh__book_language ................. [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  7 of 15 START sql view model final.stg_dwh__country ............................ [RUN]
[0m13:38:34  7 of 15 OK created sql view model final.stg_dwh__country ....................... [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  8 of 15 START sql view model final.stg_dwh__cust_order ......................... [RUN]
[0m13:38:34  8 of 15 OK created sql view model final.stg_dwh__cust_order .................... [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  9 of 15 START sql view model final.stg_dwh__customer ........................... [RUN]
[0m13:38:34  9 of 15 OK created sql view model final.stg_dwh__customer ...................... [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  10 of 15 START sql view model final.stg_dwh__customer_adress ................... [RUN]
[0m13:38:34  10 of 15 OK created sql view model final.stg_dwh__customer_adress .............. [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  11 of 15 START sql view model final.stg_dwh__order_history ..................... [RUN]
[0m13:38:34  11 of 15 OK created sql view model final.stg_dwh__order_history ................ [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  12 of 15 START sql view model final.stg_dwh__order_line ........................ [RUN]
[0m13:38:34  12 of 15 OK created sql view model final.stg_dwh__order_line ................... [[32mCREATE VIEW[0m in 0.09s]
[0m13:38:34  13 of 15 START sql view model final.stg_dwh__order_status ...................... [RUN]
[0m13:38:34  13 of 15 OK created sql view model final.stg_dwh__order_status ................. [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  14 of 15 START sql view model final.stg_dwh__publisher ......................... [RUN]
[0m13:38:34  14 of 15 OK created sql view model final.stg_dwh__publisher .................... [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  15 of 15 START sql view model final.stg_dwh__shipping_method ................... [RUN]
[0m13:38:34  15 of 15 OK created sql view model final.stg_dwh__shipping_method .............. [[32mCREATE VIEW[0m in 0.04s]
[0m13:38:34  
[0m13:38:34  Finished running 15 view models in 0 hours 0 minutes and 0.88 seconds (0.88s).
[0m13:38:34  
[0m13:38:34  [32mCompleted successfully[0m
[0m13:38:34  
[0m13:38:34  Done. PASS=15 WARN=0 ERROR=0 SKIP=0 TOTAL=15
[0m13:38:38  Running with dbt=1.9.0-b2
[0m13:38:38  Registered adapter: postgres=1.8.2
[0m13:38:38  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m13:38:38  
[0m13:38:38  Concurrency: 1 threads (target='dev')
[0m13:38:38  
[0m13:38:38  1 of 8 START snapshot final.dim_author ......................................... [RUN]
[0m13:38:38  1 of 8 OK snapshotted final.dim_author ......................................... [[32mINSERT 0 0[0m in 0.21s]
[0m13:38:38  2 of 8 START snapshot final.dim_book ........................................... [RUN]
[0m13:38:39  2 of 8 OK snapshotted final.dim_book ........................................... [[32mINSERT 0 0[0m in 0.46s]
[0m13:38:39  3 of 8 START snapshot final.dim_customer_address ............................... [RUN]
[0m13:38:39  3 of 8 OK snapshotted final.dim_customer_address ............................... [[32mINSERT 0 0[0m in 0.07s]
[0m13:38:39  4 of 8 START snapshot final.dim_order_status ................................... [RUN]
[0m13:38:39  4 of 8 OK snapshotted final.dim_order_status ................................... [[32mINSERT 0 0[0m in 0.06s]
[0m13:38:39  5 of 8 START snapshot final.dim_shipping_method ................................ [RUN]
[0m13:38:39  5 of 8 OK snapshotted final.dim_shipping_method ................................ [[32mINSERT 0 0[0m in 0.06s]
[0m13:38:39  6 of 8 START snapshot final.fct_book_author_sales .............................. [RUN]
[0m13:38:39  6 of 8 OK snapshotted final.fct_book_author_sales .............................. [[32mINSERT 0 0[0m in 0.28s]
[0m13:38:39  7 of 8 START snapshot final.fct_sales .......................................... [RUN]
[0m13:38:39  7 of 8 OK snapshotted final.fct_sales .......................................... [[32mINSERT 0 0[0m in 0.27s]
[0m13:38:39  8 of 8 START snapshot final.fct_order .......................................... [RUN]
[0m13:38:40  8 of 8 OK snapshotted final.fct_order .......................................... [[32mINSERT 0 15700[0m in 0.98s]
[0m13:38:40  
[0m13:38:40  Finished running 8 snapshots in 0 hours 0 minutes and 2.49 seconds (2.49s).
[0m13:38:40  
[0m13:38:40  [32mCompleted successfully[0m
[0m13:38:40  
[0m13:38:40  Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2024-11-09 20:38:42,374 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-09 20:38:42,374 - INFO - [pid 63963] Worker Worker(salt=7956625501, workers=1, host=Erlina, username=istywhyerlina, pid=63963) done      Transform()
2024-11-09 20:38:42,374 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 20:38:42,375 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-09 20:38:42,375 - DEBUG - Asking scheduler for work...
2024-11-09 20:38:42,375 - DEBUG - Done
2024-11-09 20:38:42,375 - DEBUG - There are no more tasks to run at this time
2024-11-09 20:38:42,375 - INFO - Worker Worker(salt=7956625501, workers=1, host=Erlina, username=istywhyerlina, pid=63963) was stopped. Shutting down Keep-Alive thread
2024-11-09 20:38:42,375 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

/home/istywhyerlina/fp_datastorage/PacbookDWH/run_etl.sh: 11: python: not found
/home/istywhyerlina/fp_datastorage/PacbookDWH/run_etl.sh: 11: python: not found
/home/istywhyerlina/fp_datastorage/PacbookDWH/run_etl.sh: 11: python: not found
/home/istywhyerlina/fp_datastorage/PacbookDWH/run_etl.sh: 11: python: not found
/home/istywhyerlina/fp_datastorage/PacbookDWH/run_etl.sh: 11: python: not found
DEBUG: Checking if Extract() is complete
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
ERROR: Luigi unexpected framework error while scheduling Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f46abf5d930>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f46abf5d930>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f46abf5d930>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed pinging scheduler
INFO: Worker Worker(salt=5529758270, workers=1, host=Erlina, username=istywhyerlina, pid=83703) was stopped. Shutting down Keep-Alive thread
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f46abf5d930>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f46abf5d930>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f46abf5d930>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 97, in <module>
    luigi.build([Extract(),
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 243, in build
    luigi_run_result = _schedule_and_run(tasks, worker_scheduler_factory, override_defaults=env_params)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 175, in _schedule_and_run
    success &= worker.add(t, env_params.parallel_scheduling, env_params.parallel_scheduling_processes)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
DEBUG: Checking if Extract() is complete
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
ERROR: Luigi unexpected framework error while scheduling Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f1cebfe19f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f1cebfe19f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f1cebfe19f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed pinging scheduler
INFO: Worker Worker(salt=6278037631, workers=1, host=Erlina, username=istywhyerlina, pid=104759) was stopped. Shutting down Keep-Alive thread
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f1cebfe19f0>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f1cebfe19f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f1cebfe19f0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 97, in <module>
    luigi.build([Extract(),
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 243, in build
    luigi_run_result = _schedule_and_run(tasks, worker_scheduler_factory, override_defaults=env_params)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 175, in _schedule_and_run
    success &= worker.add(t, env_params.parallel_scheduling, env_params.parallel_scheduling_processes)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
DEBUG: Checking if Extract() is complete
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
ERROR: Luigi unexpected framework error while scheduling Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f458bded990>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f458bded990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f458bded990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed pinging scheduler
INFO: Worker Worker(salt=4056418680, workers=1, host=Erlina, username=istywhyerlina, pid=106258) was stopped. Shutting down Keep-Alive thread
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f458bded990>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f458bded990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f458bded990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 97, in <module>
    luigi.build([Extract(),
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 243, in build
    luigi_run_result = _schedule_and_run(tasks, worker_scheduler_factory, override_defaults=env_params)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 175, in _schedule_and_run
    success &= worker.add(t, env_params.parallel_scheduling, env_params.parallel_scheduling_processes)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
DEBUG: Checking if Extract() is complete
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
DEBUG: Checking if Extract() is complete
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
ERROR: Luigi unexpected framework error while scheduling Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fe3f82d9990>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe3f82d9990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe3f82d9990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed pinging scheduler
INFO: Worker Worker(salt=6107398005, workers=1, host=Erlina, username=istywhyerlina, pid=109244) was stopped. Shutting down Keep-Alive thread
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fe3f82d9990>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe3f82d9990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fe3f82d9990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 97, in <module>
    luigi.build([Extract(),
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 243, in build
    luigi_run_result = _schedule_and_run(tasks, worker_scheduler_factory, override_defaults=env_params)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 175, in _schedule_and_run
    success &= worker.add(t, env_params.parallel_scheduling, env_params.parallel_scheduling_processes)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
ERROR: Luigi unexpected framework error while scheduling Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f45ada69960>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f45ada69960>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f45ada69960>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed pinging scheduler
INFO: Worker Worker(salt=5696998549, workers=1, host=Erlina, username=istywhyerlina, pid=109857) was stopped. Shutting down Keep-Alive thread
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f45ada69960>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f45ada69960>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f45ada69960>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 97, in <module>
    luigi.build([Extract(),
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 243, in build
    luigi_run_result = _schedule_and_run(tasks, worker_scheduler_factory, override_defaults=env_params)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 175, in _schedule_and_run
    success &= worker.add(t, env_params.parallel_scheduling, env_params.parallel_scheduling_processes)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Load() is complete
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Transform() is complete
DEBUG: Checking if Load() is complete
INFO: Informed scheduler that task   Transform__99914b932b   has status   PENDING
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
INFO: Done scheduling tasks
INFO: Running Worker with 1 processes
DEBUG: Asking scheduler for work...
DEBUG: Pending tasks: 3
INFO: [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) running   Extract()
2024-11-09 21:45:02,836 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 21:45:02,878 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 21:45:02,883 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 21:45:02,911 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 21:45:02,993 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 21:45:03,071 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 21:45:03,078 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 21:45:03,084 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 21:45:03,136 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 21:45:03,147 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 21:45:03,159 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 21:45:03,292 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 21:45:03,431 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 21:45:03,439 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 21:45:03,448 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 21:45:03,454 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 21:45:03,454 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 21:45:03,456 - INFO - ==================================ENDING EXTRACT DATA=======================================
INFO: [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) done      Extract()
2024-11-09 21:45:03,456 - INFO - [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) done      Extract()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-09 21:45:03,457 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 21:45:03,464 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-09 21:45:03,464 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 2
2024-11-09 21:45:03,469 - DEBUG - Pending tasks: 2
INFO: [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) running   Load()
2024-11-09 21:45:03,469 - INFO - [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) running   Load()
2024-11-09 21:45:03,470 - INFO - Read Load Query - SUCCESS
2024-11-09 21:45:03,584 - INFO - Read Extracted Data - SUCCESS
2024-11-09 21:45:03,586 - INFO - Connect to DWH - SUCCESS
2024-11-09 21:45:03,671 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 21:45:03,671 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 21:45:03,695 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 21:45:03,732 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 21:45:03,744 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 21:45:03,885 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 21:45:04,375 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 21:45:04,672 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 21:45:04,678 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 21:45:04,823 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 21:45:04,872 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 21:45:04,913 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 21:45:05,286 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 21:45:05,726 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 21:45:05,738 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 21:45:05,781 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 21:45:05,793 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 21:45:05,793 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 21:45:05,795 - INFO - ==================================ENDING LOAD DATA=======================================
INFO: [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) done      Load()
2024-11-09 21:45:05,796 - INFO - [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) done      Load()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-09 21:45:05,797 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 21:45:05,804 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-09 21:45:05,804 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 1
2024-11-09 21:45:05,810 - DEBUG - Pending tasks: 1
INFO: [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) running   Transform()
2024-11-09 21:45:05,810 - INFO - [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) running   Transform()
2024-11-09 21:45:05,811 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-11-09 21:45:05,814 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-11-09 21:45:05,820 - ERROR - Transform Tables - FAILED
ERROR: [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd ./pacbook_transform/ && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 2.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-11-09 21:45:05,820 - ERROR - [pid 113500] Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd ./pacbook_transform/ && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 2.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-09 21:45:05,834 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-09 21:45:05,844 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
DEBUG: Asking scheduler for work...
2024-11-09 21:45:05,845 - DEBUG - Asking scheduler for work...
DEBUG: Done
2024-11-09 21:45:05,849 - DEBUG - Done
DEBUG: There are no more tasks to run at this time
2024-11-09 21:45:05,849 - DEBUG - There are no more tasks to run at this time
DEBUG: There are 1 pending tasks possibly being run by other workers
2024-11-09 21:45:05,849 - DEBUG - There are 1 pending tasks possibly being run by other workers
DEBUG: There are 1 pending tasks unique to this worker
2024-11-09 21:45:05,849 - DEBUG - There are 1 pending tasks unique to this worker
DEBUG: There are 1 pending tasks last scheduled by this worker
2024-11-09 21:45:05,849 - DEBUG - There are 1 pending tasks last scheduled by this worker
INFO: Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) was stopped. Shutting down Keep-Alive thread
2024-11-09 21:45:05,849 - INFO - Worker Worker(salt=1922050133, workers=1, host=Erlina, username=istywhyerlina, pid=113500) was stopped. Shutting down Keep-Alive thread
INFO: 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 21:45:05,853 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 21:50:24,296 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 21:50:24,320 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 21:50:24,324 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 21:50:24,343 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 21:50:24,422 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 21:50:24,493 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 21:50:24,497 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 21:50:24,501 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 21:50:24,559 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 21:50:24,572 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 21:50:24,587 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 21:50:24,698 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 21:50:24,799 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 21:50:24,803 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 21:50:24,810 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 21:50:24,814 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 21:50:24,814 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 21:50:24,815 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 21:50:24,815 - INFO - [pid 117205] Worker Worker(salt=1711335131, workers=1, host=Erlina, username=istywhyerlina, pid=117205) done      Extract()
2024-11-09 21:50:24,816 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 21:50:24,817 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 21:50:24,817 - DEBUG - Asking scheduler for work...
2024-11-09 21:50:24,817 - DEBUG - Pending tasks: 2
2024-11-09 21:50:24,817 - INFO - [pid 117205] Worker Worker(salt=1711335131, workers=1, host=Erlina, username=istywhyerlina, pid=117205) running   Load()
2024-11-09 21:50:24,818 - INFO - Read Load Query - SUCCESS
2024-11-09 21:50:24,942 - INFO - Read Extracted Data - SUCCESS
2024-11-09 21:50:24,942 - INFO - Connect to DWH - SUCCESS
2024-11-09 21:50:25,008 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 21:50:25,009 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 21:50:25,021 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 21:50:25,053 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 21:50:25,061 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 21:50:25,185 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 21:50:25,546 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 21:50:25,764 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 21:50:25,773 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 21:50:25,933 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 21:50:25,976 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 21:50:26,017 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 21:50:26,453 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 21:50:26,688 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 21:50:26,694 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 21:50:26,749 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 21:50:26,754 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 21:50:26,754 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 21:50:26,755 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 21:50:26,756 - INFO - [pid 117205] Worker Worker(salt=1711335131, workers=1, host=Erlina, username=istywhyerlina, pid=117205) done      Load()
2024-11-09 21:50:26,757 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 21:50:26,757 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 21:50:26,757 - DEBUG - Asking scheduler for work...
2024-11-09 21:50:26,757 - DEBUG - Pending tasks: 1
2024-11-09 21:50:26,758 - INFO - [pid 117205] Worker Worker(salt=1711335131, workers=1, host=Erlina, username=istywhyerlina, pid=117205) running   Transform()
2024-11-09 21:50:26,758 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m14:50:28  Running with dbt=1.9.0-b2
[0m14:50:29  Installing dbt-labs/dbt_utils
[0m14:50:29  Installed from version 1.1.1
[0m14:50:29  Updated version available: 1.3.0
[0m14:50:29  Installing calogica/dbt_date
[0m14:50:30  Installed from version 0.10.0
[0m14:50:30  Updated version available: 0.10.1
[0m14:50:30  
[0m14:50:30  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m14:50:33  Running with dbt=1.9.0-b2
[0m14:50:33  Registered adapter: postgres=1.8.2
[0m14:50:34  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m14:50:34  
[0m14:50:34  Concurrency: 1 threads (target='dev')
[0m14:50:34  
[0m14:50:34  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m14:52:59  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 144.72s]
[0m14:52:59  
[0m14:52:59  Finished running 1 seed in 0 hours 2 minutes and 24.87 seconds (144.87s).
[0m14:52:59  
[0m14:52:59  [32mCompleted successfully[0m
[0m14:52:59  
[0m14:52:59  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:53:02  Running with dbt=1.9.0-b2
[0m14:53:03  Registered adapter: postgres=1.8.2
[0m14:53:03  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m14:53:03  
[0m14:53:03  Concurrency: 1 threads (target='dev')
[0m14:53:03  
[0m14:53:03  1 of 15 START sql view model final.stg_dwh__address ............................ [RUN]
[0m14:53:04  1 of 15 OK created sql view model final.stg_dwh__address ....................... [[32mCREATE VIEW[0m in 0.24s]
[0m14:53:04  2 of 15 START sql view model final.stg_dwh__address_status ..................... [RUN]
[0m14:53:04  2 of 15 OK created sql view model final.stg_dwh__address_status ................ [[32mCREATE VIEW[0m in 0.06s]
[0m14:53:04  3 of 15 START sql view model final.stg_dwh__author ............................. [RUN]
[0m14:53:04  3 of 15 OK created sql view model final.stg_dwh__author ........................ [[32mCREATE VIEW[0m in 0.05s]
[0m14:53:04  4 of 15 START sql view model final.stg_dwh__book ............................... [RUN]
[0m14:53:04  4 of 15 OK created sql view model final.stg_dwh__book .......................... [[32mCREATE VIEW[0m in 0.06s]
[0m14:53:04  5 of 15 START sql view model final.stg_dwh__book_author ........................ [RUN]
[0m14:53:04  5 of 15 OK created sql view model final.stg_dwh__book_author ................... [[32mCREATE VIEW[0m in 0.06s]
[0m14:53:04  6 of 15 START sql view model final.stg_dwh__book_language ...................... [RUN]
[0m14:53:04  6 of 15 OK created sql view model final.stg_dwh__book_language ................. [[32mCREATE VIEW[0m in 0.06s]
[0m14:53:04  7 of 15 START sql view model final.stg_dwh__country ............................ [RUN]
[0m14:53:04  7 of 15 OK created sql view model final.stg_dwh__country ....................... [[32mCREATE VIEW[0m in 0.07s]
[0m14:53:04  8 of 15 START sql view model final.stg_dwh__cust_order ......................... [RUN]
[0m14:53:04  8 of 15 OK created sql view model final.stg_dwh__cust_order .................... [[32mCREATE VIEW[0m in 0.06s]
[0m14:53:04  9 of 15 START sql view model final.stg_dwh__customer ........................... [RUN]
[0m14:53:04  9 of 15 OK created sql view model final.stg_dwh__customer ...................... [[32mCREATE VIEW[0m in 0.07s]
[0m14:53:04  10 of 15 START sql view model final.stg_dwh__customer_adress ................... [RUN]
[0m14:53:04  10 of 15 OK created sql view model final.stg_dwh__customer_adress .............. [[32mCREATE VIEW[0m in 0.06s]
[0m14:53:04  11 of 15 START sql view model final.stg_dwh__order_history ..................... [RUN]
[0m14:53:04  11 of 15 OK created sql view model final.stg_dwh__order_history ................ [[32mCREATE VIEW[0m in 0.05s]
[0m14:53:04  12 of 15 START sql view model final.stg_dwh__order_line ........................ [RUN]
[0m14:53:04  12 of 15 OK created sql view model final.stg_dwh__order_line ................... [[32mCREATE VIEW[0m in 0.13s]
[0m14:53:04  13 of 15 START sql view model final.stg_dwh__order_status ...................... [RUN]
[0m14:53:04  13 of 15 OK created sql view model final.stg_dwh__order_status ................. [[32mCREATE VIEW[0m in 0.07s]
[0m14:53:04  14 of 15 START sql view model final.stg_dwh__publisher ......................... [RUN]
[0m14:53:04  14 of 15 OK created sql view model final.stg_dwh__publisher .................... [[32mCREATE VIEW[0m in 0.06s]
[0m14:53:05  15 of 15 START sql view model final.stg_dwh__shipping_method ................... [RUN]
[0m14:53:05  15 of 15 OK created sql view model final.stg_dwh__shipping_method .............. [[32mCREATE VIEW[0m in 0.06s]
[0m14:53:05  
[0m14:53:05  Finished running 15 view models in 0 hours 0 minutes and 1.41 seconds (1.41s).
[0m14:53:05  
[0m14:53:05  [32mCompleted successfully[0m
[0m14:53:05  
[0m14:53:05  Done. PASS=15 WARN=0 ERROR=0 SKIP=0 TOTAL=15
[0m14:53:08  Running with dbt=1.9.0-b2
[0m14:53:08  Registered adapter: postgres=1.8.2
[0m14:53:09  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m14:53:09  
[0m14:53:09  Concurrency: 1 threads (target='dev')
[0m14:53:09  
[0m14:53:09  1 of 8 START snapshot final.dim_author ......................................... [RUN]
[0m14:53:10  1 of 8 OK snapshotted final.dim_author ......................................... [[32mINSERT 0 0[0m in 0.50s]
[0m14:53:10  2 of 8 START snapshot final.dim_book ........................................... [RUN]
[0m14:53:10  2 of 8 OK snapshotted final.dim_book ........................................... [[32mINSERT 0 0[0m in 0.36s]
[0m14:53:10  3 of 8 START snapshot final.dim_customer_address ............................... [RUN]
[0m14:53:10  3 of 8 OK snapshotted final.dim_customer_address ............................... [[32mINSERT 0 0[0m in 0.17s]
[0m14:53:10  4 of 8 START snapshot final.dim_order_status ................................... [RUN]
[0m14:53:10  4 of 8 OK snapshotted final.dim_order_status ................................... [[32mINSERT 0 0[0m in 0.14s]
[0m14:53:10  5 of 8 START snapshot final.dim_shipping_method ................................ [RUN]
[0m14:53:10  5 of 8 OK snapshotted final.dim_shipping_method ................................ [[32mINSERT 0 0[0m in 0.20s]
[0m14:53:10  6 of 8 START snapshot final.fct_book_author_sales .............................. [RUN]
[0m14:53:11  6 of 8 OK snapshotted final.fct_book_author_sales .............................. [[32mINSERT 0 0[0m in 0.57s]
[0m14:53:11  7 of 8 START snapshot final.fct_sales .......................................... [RUN]
[0m14:53:11  7 of 8 OK snapshotted final.fct_sales .......................................... [[32mINSERT 0 0[0m in 0.38s]
[0m14:53:11  8 of 8 START snapshot final.fct_order .......................................... [RUN]
[0m14:53:13  8 of 8 OK snapshotted final.fct_order .......................................... [[32mINSERT 0 4300[0m in 1.68s]
[0m14:53:13  
[0m14:53:13  Finished running 8 snapshots in 0 hours 0 minutes and 4.20 seconds (4.20s).
[0m14:53:13  
[0m14:53:13  [32mCompleted successfully[0m
[0m14:53:13  
[0m14:53:13  Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2024-11-09 21:53:15,486 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-09 21:53:15,486 - INFO - [pid 117205] Worker Worker(salt=1711335131, workers=1, host=Erlina, username=istywhyerlina, pid=117205) done      Transform()
2024-11-09 21:53:15,487 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 21:53:15,487 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-09 21:53:15,488 - DEBUG - Asking scheduler for work...
2024-11-09 21:53:15,488 - DEBUG - Done
2024-11-09 21:53:15,488 - DEBUG - There are no more tasks to run at this time
2024-11-09 21:53:15,488 - INFO - Worker Worker(salt=1711335131, workers=1, host=Erlina, username=istywhyerlina, pid=117205) was stopped. Shutting down Keep-Alive thread
2024-11-09 21:53:15,489 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

DEBUG: Checking if Extract() is complete
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
ERROR: Luigi unexpected framework error while scheduling Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f1756129960>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f1756129960>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f1756129960>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed pinging scheduler
INFO: Worker Worker(salt=5900273607, workers=1, host=Erlina, username=istywhyerlina, pid=123585) was stopped. Shutting down Keep-Alive thread
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f1756129960>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f1756129960>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f1756129960>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 97, in <module>
    luigi.build([Extract(),
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 243, in build
    luigi_run_result = _schedule_and_run(tasks, worker_scheduler_factory, override_defaults=env_params)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 175, in _schedule_and_run
    success &= worker.add(t, env_params.parallel_scheduling, env_params.parallel_scheduling_processes)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Load() is complete
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Transform() is complete
DEBUG: Checking if Load() is complete
INFO: Informed scheduler that task   Transform__99914b932b   has status   PENDING
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
INFO: Done scheduling tasks
INFO: Running Worker with 1 processes
DEBUG: Asking scheduler for work...
DEBUG: Pending tasks: 3
INFO: [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) running   Extract()
2024-11-09 22:04:02,292 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 22:04:02,329 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 22:04:02,334 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 22:04:02,359 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 22:04:02,429 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 22:04:02,510 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 22:04:02,515 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 22:04:02,520 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 22:04:02,565 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 22:04:02,574 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 22:04:02,586 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 22:04:02,703 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 22:04:02,825 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 22:04:02,829 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 22:04:02,839 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 22:04:02,845 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 22:04:02,845 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 22:04:02,846 - INFO - ==================================ENDING EXTRACT DATA=======================================
INFO: [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) done      Extract()
2024-11-09 22:04:02,846 - INFO - [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) done      Extract()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-09 22:04:02,848 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 22:04:02,853 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-09 22:04:02,853 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 2
2024-11-09 22:04:02,857 - DEBUG - Pending tasks: 2
INFO: [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) running   Load()
2024-11-09 22:04:02,858 - INFO - [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) running   Load()
2024-11-09 22:04:02,858 - INFO - Read Load Query - SUCCESS
2024-11-09 22:04:02,949 - INFO - Read Extracted Data - SUCCESS
2024-11-09 22:04:02,950 - INFO - Connect to DWH - SUCCESS
2024-11-09 22:04:03,001 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 22:04:03,001 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 22:04:03,019 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 22:04:03,054 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 22:04:03,062 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 22:04:03,175 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 22:04:03,569 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 22:04:03,806 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 22:04:03,814 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 22:04:03,974 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 22:04:04,030 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 22:04:04,085 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 22:04:04,505 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 22:04:04,829 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 22:04:04,836 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 22:04:04,869 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 22:04:04,876 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 22:04:04,877 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 22:04:04,878 - INFO - ==================================ENDING LOAD DATA=======================================
INFO: [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) done      Load()
2024-11-09 22:04:04,879 - INFO - [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) done      Load()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-09 22:04:04,880 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 22:04:04,884 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-09 22:04:04,884 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 1
2024-11-09 22:04:04,887 - DEBUG - Pending tasks: 1
INFO: [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) running   Transform()
2024-11-09 22:04:04,888 - INFO - [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) running   Transform()
2024-11-09 22:04:04,888 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-11-09 22:04:04,890 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-11-09 22:04:04,892 - ERROR - Transform Tables - FAILED
ERROR: [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd ./pacbook_transform/ && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 2.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-11-09 22:04:04,892 - ERROR - [pid 126309] Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd ./pacbook_transform/ && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 2.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-09 22:04:04,894 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-09 22:04:04,900 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
DEBUG: Asking scheduler for work...
2024-11-09 22:04:04,900 - DEBUG - Asking scheduler for work...
DEBUG: Done
2024-11-09 22:04:04,904 - DEBUG - Done
DEBUG: There are no more tasks to run at this time
2024-11-09 22:04:04,905 - DEBUG - There are no more tasks to run at this time
DEBUG: There are 1 pending tasks possibly being run by other workers
2024-11-09 22:04:04,905 - DEBUG - There are 1 pending tasks possibly being run by other workers
DEBUG: There are 1 pending tasks unique to this worker
2024-11-09 22:04:04,905 - DEBUG - There are 1 pending tasks unique to this worker
DEBUG: There are 1 pending tasks last scheduled by this worker
2024-11-09 22:04:04,906 - DEBUG - There are 1 pending tasks last scheduled by this worker
INFO: Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) was stopped. Shutting down Keep-Alive thread
2024-11-09 22:04:04,907 - INFO - Worker Worker(salt=692936305, workers=1, host=Erlina, username=istywhyerlina, pid=126309) was stopped. Shutting down Keep-Alive thread
INFO: 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 22:04:04,908 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Load() is complete
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Transform() is complete
DEBUG: Checking if Load() is complete
INFO: Informed scheduler that task   Transform__99914b932b   has status   PENDING
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
INFO: Done scheduling tasks
INFO: Running Worker with 1 processes
DEBUG: Asking scheduler for work...
DEBUG: Pending tasks: 3
INFO: [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) running   Extract()
2024-11-09 22:15:02,010 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 22:15:02,041 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 22:15:02,045 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 22:15:02,069 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 22:15:02,143 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 22:15:02,219 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 22:15:02,226 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 22:15:02,232 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 22:15:02,293 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 22:15:02,305 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 22:15:02,317 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 22:15:02,446 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 22:15:02,585 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 22:15:02,591 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 22:15:02,600 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 22:15:02,607 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 22:15:02,607 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 22:15:02,609 - INFO - ==================================ENDING EXTRACT DATA=======================================
INFO: [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) done      Extract()
2024-11-09 22:15:02,609 - INFO - [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) done      Extract()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-09 22:15:02,611 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 22:15:02,616 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-09 22:15:02,616 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 2
2024-11-09 22:15:02,618 - DEBUG - Pending tasks: 2
INFO: [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) running   Load()
2024-11-09 22:15:02,618 - INFO - [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) running   Load()
2024-11-09 22:15:02,619 - INFO - Read Load Query - SUCCESS
2024-11-09 22:15:02,705 - INFO - Read Extracted Data - SUCCESS
2024-11-09 22:15:02,706 - INFO - Connect to DWH - SUCCESS
2024-11-09 22:15:02,763 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 22:15:02,763 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 22:15:02,781 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 22:15:02,817 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 22:15:02,825 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 22:15:02,925 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 22:15:03,327 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 22:15:03,550 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 22:15:03,556 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 22:15:03,708 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 22:15:03,752 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 22:15:03,798 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 22:15:04,226 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 22:15:04,541 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 22:15:04,548 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 22:15:04,580 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 22:15:04,588 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 22:15:04,588 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 22:15:04,590 - INFO - ==================================ENDING LOAD DATA=======================================
INFO: [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) done      Load()
2024-11-09 22:15:04,591 - INFO - [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) done      Load()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-09 22:15:04,592 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 22:15:04,597 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-09 22:15:04,598 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 1
2024-11-09 22:15:04,601 - DEBUG - Pending tasks: 1
INFO: [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) running   Transform()
2024-11-09 22:15:04,602 - INFO - [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) running   Transform()
2024-11-09 22:15:04,602 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-11-09 22:15:04,604 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-11-09 22:15:04,606 - ERROR - Transform Tables - FAILED
ERROR: [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd /home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform/ && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 127.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-11-09 22:15:04,606 - ERROR - [pid 133636] Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd /home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform/ && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 127.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-09 22:15:04,607 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-09 22:15:04,614 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
DEBUG: Asking scheduler for work...
2024-11-09 22:15:04,615 - DEBUG - Asking scheduler for work...
DEBUG: Done
2024-11-09 22:15:04,618 - DEBUG - Done
DEBUG: There are no more tasks to run at this time
2024-11-09 22:15:04,619 - DEBUG - There are no more tasks to run at this time
DEBUG: There are 1 pending tasks possibly being run by other workers
2024-11-09 22:15:04,619 - DEBUG - There are 1 pending tasks possibly being run by other workers
DEBUG: There are 1 pending tasks unique to this worker
2024-11-09 22:15:04,619 - DEBUG - There are 1 pending tasks unique to this worker
DEBUG: There are 1 pending tasks last scheduled by this worker
2024-11-09 22:15:04,620 - DEBUG - There are 1 pending tasks last scheduled by this worker
INFO: Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) was stopped. Shutting down Keep-Alive thread
2024-11-09 22:15:04,620 - INFO - Worker Worker(salt=8856855487, workers=1, host=Erlina, username=istywhyerlina, pid=133636) was stopped. Shutting down Keep-Alive thread
INFO: 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 22:15:04,623 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-09 22:20:27,016 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-09 22:20:27,038 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-09 22:20:27,041 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-09 22:20:27,065 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-09 22:20:27,141 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-09 22:20:27,207 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-09 22:20:27,212 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-09 22:20:27,217 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-09 22:20:27,263 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-09 22:20:27,272 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-09 22:20:27,286 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-09 22:20:27,410 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-09 22:20:27,512 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-09 22:20:27,516 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-09 22:20:27,524 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-09 22:20:27,528 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-09 22:20:27,528 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-09 22:20:27,529 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-09 22:20:27,529 - INFO - [pid 137309] Worker Worker(salt=7589315362, workers=1, host=Erlina, username=istywhyerlina, pid=137309) done      Extract()
2024-11-09 22:20:27,531 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 22:20:27,532 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-09 22:20:27,532 - DEBUG - Asking scheduler for work...
2024-11-09 22:20:27,532 - DEBUG - Pending tasks: 2
2024-11-09 22:20:27,532 - INFO - [pid 137309] Worker Worker(salt=7589315362, workers=1, host=Erlina, username=istywhyerlina, pid=137309) running   Load()
2024-11-09 22:20:27,533 - INFO - Read Load Query - SUCCESS
2024-11-09 22:20:27,615 - INFO - Read Extracted Data - SUCCESS
2024-11-09 22:20:27,616 - INFO - Connect to DWH - SUCCESS
2024-11-09 22:20:27,674 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-09 22:20:27,674 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-09 22:20:27,695 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-09 22:20:27,739 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-09 22:20:27,747 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-09 22:20:27,910 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-09 22:20:28,256 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-09 22:20:28,483 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-09 22:20:28,491 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-09 22:20:28,659 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-09 22:20:28,710 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-09 22:20:28,755 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-09 22:20:29,147 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-09 22:20:29,379 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-09 22:20:29,385 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-09 22:20:29,441 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-09 22:20:29,446 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-09 22:20:29,446 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-09 22:20:29,448 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-09 22:20:29,449 - INFO - [pid 137309] Worker Worker(salt=7589315362, workers=1, host=Erlina, username=istywhyerlina, pid=137309) done      Load()
2024-11-09 22:20:29,449 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 22:20:29,450 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-09 22:20:29,450 - DEBUG - Asking scheduler for work...
2024-11-09 22:20:29,450 - DEBUG - Pending tasks: 1
2024-11-09 22:20:29,450 - INFO - [pid 137309] Worker Worker(salt=7589315362, workers=1, host=Erlina, username=istywhyerlina, pid=137309) running   Transform()
2024-11-09 22:20:29,451 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m15:20:31  Running with dbt=1.9.0-b2
[0m15:20:32  Installing dbt-labs/dbt_utils
[0m15:20:33  Installed from version 1.1.1
[0m15:20:33  Updated version available: 1.3.0
[0m15:20:33  Installing calogica/dbt_date
[0m15:20:34  Installed from version 0.10.0
[0m15:20:34  Updated version available: 0.10.1
[0m15:20:34  
[0m15:20:34  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m15:20:37  Running with dbt=1.9.0-b2
[0m15:20:38  Registered adapter: postgres=1.8.2
[0m15:20:38  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m15:20:38  
[0m15:20:38  Concurrency: 1 threads (target='dev')
[0m15:20:38  
[0m15:20:38  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m15:23:13  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 154.85s]
[0m15:23:13  
[0m15:23:13  Finished running 1 seed in 0 hours 2 minutes and 34.99 seconds (154.99s).
[0m15:23:13  
[0m15:23:13  [32mCompleted successfully[0m
[0m15:23:13  
[0m15:23:13  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m15:23:17  Running with dbt=1.9.0-b2
[0m15:23:17  Registered adapter: postgres=1.8.2
[0m15:23:18  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m15:23:18  
[0m15:23:18  Concurrency: 1 threads (target='dev')
[0m15:23:18  
[0m15:23:18  1 of 15 START sql view model final.stg_dwh__address ............................ [RUN]
[0m15:23:18  1 of 15 OK created sql view model final.stg_dwh__address ....................... [[32mCREATE VIEW[0m in 0.25s]
[0m15:23:18  2 of 15 START sql view model final.stg_dwh__address_status ..................... [RUN]
[0m15:23:18  2 of 15 OK created sql view model final.stg_dwh__address_status ................ [[32mCREATE VIEW[0m in 0.05s]
[0m15:23:18  3 of 15 START sql view model final.stg_dwh__author ............................. [RUN]
[0m15:23:18  3 of 15 OK created sql view model final.stg_dwh__author ........................ [[32mCREATE VIEW[0m in 0.06s]
[0m15:23:18  4 of 15 START sql view model final.stg_dwh__book ............................... [RUN]
[0m15:23:18  4 of 15 OK created sql view model final.stg_dwh__book .......................... [[32mCREATE VIEW[0m in 0.05s]
[0m15:23:18  5 of 15 START sql view model final.stg_dwh__book_author ........................ [RUN]
[0m15:23:18  5 of 15 OK created sql view model final.stg_dwh__book_author ................... [[32mCREATE VIEW[0m in 0.05s]
[0m15:23:18  6 of 15 START sql view model final.stg_dwh__book_language ...................... [RUN]
[0m15:23:18  6 of 15 OK created sql view model final.stg_dwh__book_language ................. [[32mCREATE VIEW[0m in 0.05s]
[0m15:23:18  7 of 15 START sql view model final.stg_dwh__country ............................ [RUN]
[0m15:23:18  7 of 15 OK created sql view model final.stg_dwh__country ....................... [[32mCREATE VIEW[0m in 0.04s]
[0m15:23:18  8 of 15 START sql view model final.stg_dwh__cust_order ......................... [RUN]
[0m15:23:18  8 of 15 OK created sql view model final.stg_dwh__cust_order .................... [[32mCREATE VIEW[0m in 0.04s]
[0m15:23:18  9 of 15 START sql view model final.stg_dwh__customer ........................... [RUN]
[0m15:23:19  9 of 15 OK created sql view model final.stg_dwh__customer ...................... [[32mCREATE VIEW[0m in 0.05s]
[0m15:23:19  10 of 15 START sql view model final.stg_dwh__customer_adress ................... [RUN]
[0m15:23:19  10 of 15 OK created sql view model final.stg_dwh__customer_adress .............. [[32mCREATE VIEW[0m in 0.06s]
[0m15:23:19  11 of 15 START sql view model final.stg_dwh__order_history ..................... [RUN]
[0m15:23:19  11 of 15 OK created sql view model final.stg_dwh__order_history ................ [[32mCREATE VIEW[0m in 0.06s]
[0m15:23:19  12 of 15 START sql view model final.stg_dwh__order_line ........................ [RUN]
[0m15:23:19  12 of 15 OK created sql view model final.stg_dwh__order_line ................... [[32mCREATE VIEW[0m in 0.10s]
[0m15:23:19  13 of 15 START sql view model final.stg_dwh__order_status ...................... [RUN]
[0m15:23:19  13 of 15 OK created sql view model final.stg_dwh__order_status ................. [[32mCREATE VIEW[0m in 0.05s]
[0m15:23:19  14 of 15 START sql view model final.stg_dwh__publisher ......................... [RUN]
[0m15:23:19  14 of 15 OK created sql view model final.stg_dwh__publisher .................... [[32mCREATE VIEW[0m in 0.05s]
[0m15:23:19  15 of 15 START sql view model final.stg_dwh__shipping_method ................... [RUN]
[0m15:23:19  15 of 15 OK created sql view model final.stg_dwh__shipping_method .............. [[32mCREATE VIEW[0m in 0.05s]
[0m15:23:19  
[0m15:23:19  Finished running 15 view models in 0 hours 0 minutes and 1.23 seconds (1.23s).
[0m15:23:19  
[0m15:23:19  [32mCompleted successfully[0m
[0m15:23:19  
[0m15:23:19  Done. PASS=15 WARN=0 ERROR=0 SKIP=0 TOTAL=15
[0m15:23:23  Running with dbt=1.9.0-b2
[0m15:23:23  Registered adapter: postgres=1.8.2
[0m15:23:23  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m15:23:23  
[0m15:23:23  Concurrency: 1 threads (target='dev')
[0m15:23:23  
[0m15:23:24  1 of 8 START snapshot final.dim_author ......................................... [RUN]
[0m15:23:24  1 of 8 OK snapshotted final.dim_author ......................................... [[32mSELECT 9235[0m in 0.26s]
[0m15:23:24  2 of 8 START snapshot final.dim_book ........................................... [RUN]
[0m15:23:24  2 of 8 OK snapshotted final.dim_book ........................................... [[32mSELECT 11127[0m in 0.11s]
[0m15:23:24  3 of 8 START snapshot final.dim_customer_address ............................... [RUN]
[0m15:23:24  3 of 8 OK snapshotted final.dim_customer_address ............................... [[32mSELECT 2950[0m in 0.08s]
[0m15:23:24  4 of 8 START snapshot final.dim_order_status ................................... [RUN]
[0m15:23:24  4 of 8 OK snapshotted final.dim_order_status ................................... [[32mSELECT 6[0m in 0.05s]
[0m15:23:24  5 of 8 START snapshot final.dim_shipping_method ................................ [RUN]
[0m15:23:24  5 of 8 OK snapshotted final.dim_shipping_method ................................ [[32mSELECT 4[0m in 0.05s]
[0m15:23:24  6 of 8 START snapshot final.fct_book_author_sales .............................. [RUN]
[0m15:23:24  6 of 8 OK snapshotted final.fct_book_author_sales .............................. [[32mSELECT 23838[0m in 0.31s]
[0m15:23:24  7 of 8 START snapshot final.fct_sales .......................................... [RUN]
[0m15:23:25  7 of 8 OK snapshotted final.fct_sales .......................................... [[32mSELECT 15400[0m in 0.16s]
[0m15:23:25  8 of 8 START snapshot final.fct_order .......................................... [RUN]
[0m15:23:26  8 of 8 OK snapshotted final.fct_order .......................................... [[32mSELECT 22345[0m in 0.96s]
[0m15:23:26  
[0m15:23:26  Finished running 8 snapshots in 0 hours 0 minutes and 2.16 seconds (2.16s).
[0m15:23:26  
[0m15:23:26  [32mCompleted successfully[0m
[0m15:23:26  
[0m15:23:26  Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2024-11-09 22:23:27,988 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-09 22:23:27,988 - INFO - [pid 137309] Worker Worker(salt=7589315362, workers=1, host=Erlina, username=istywhyerlina, pid=137309) done      Transform()
2024-11-09 22:23:27,988 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-09 22:23:27,989 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-09 22:23:27,989 - DEBUG - Asking scheduler for work...
2024-11-09 22:23:27,989 - DEBUG - Done
2024-11-09 22:23:27,989 - DEBUG - There are no more tasks to run at this time
2024-11-09 22:23:27,989 - INFO - Worker Worker(salt=7589315362, workers=1, host=Erlina, username=istywhyerlina, pid=137309) was stopped. Shutting down Keep-Alive thread
2024-11-09 22:23:27,991 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Load() is complete
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Transform() is complete
DEBUG: Checking if Load() is complete
INFO: Informed scheduler that task   Transform__99914b932b   has status   PENDING
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
INFO: Done scheduling tasks
INFO: Running Worker with 1 processes
DEBUG: Asking scheduler for work...
DEBUG: Pending tasks: 3
INFO: [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) running   Extract()
2024-11-10 05:08:03,551 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-10 05:08:03,645 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-10 05:08:03,649 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-10 05:08:03,676 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-10 05:08:03,749 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-10 05:08:03,812 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-10 05:08:03,815 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-10 05:08:03,819 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-10 05:08:03,871 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-10 05:08:03,882 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-10 05:08:03,894 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-10 05:08:04,010 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-10 05:08:04,179 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-10 05:08:04,185 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-10 05:08:04,192 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-10 05:08:04,196 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-10 05:08:04,196 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-10 05:08:04,197 - INFO - ==================================ENDING EXTRACT DATA=======================================
INFO: [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) done      Extract()
2024-11-10 05:08:04,198 - INFO - [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) done      Extract()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-10 05:08:04,198 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-10 05:08:04,202 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-10 05:08:04,202 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 2
2024-11-10 05:08:04,204 - DEBUG - Pending tasks: 2
INFO: [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) running   Load()
2024-11-10 05:08:04,204 - INFO - [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) running   Load()
2024-11-10 05:08:04,215 - INFO - Read Load Query - SUCCESS
2024-11-10 05:08:04,287 - INFO - Read Extracted Data - SUCCESS
2024-11-10 05:08:04,288 - INFO - Connect to DWH - SUCCESS
2024-11-10 05:08:04,331 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-10 05:08:04,331 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-10 05:08:04,347 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-10 05:08:04,411 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-10 05:08:04,422 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-10 05:08:04,548 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-10 05:08:04,907 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-10 05:08:05,123 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-10 05:08:05,132 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-10 05:08:05,326 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-10 05:08:05,372 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-10 05:08:05,421 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-10 05:08:05,891 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-10 05:08:06,208 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-10 05:08:06,214 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-10 05:08:06,245 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-10 05:08:06,254 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-10 05:08:06,254 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-10 05:08:06,255 - INFO - ==================================ENDING LOAD DATA=======================================
INFO: [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) done      Load()
2024-11-10 05:08:06,256 - INFO - [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) done      Load()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-10 05:08:06,257 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-10 05:08:06,260 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-10 05:08:06,260 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 1
2024-11-10 05:08:06,264 - DEBUG - Pending tasks: 1
INFO: [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) running   Transform()
2024-11-10 05:08:06,264 - INFO - [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) running   Transform()
2024-11-10 05:08:06,265 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-11-10 05:08:06,266 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-11-10 05:08:06,267 - ERROR - Transform Tables - FAILED
ERROR: [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd /home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform/ && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 127.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-11-10 05:08:06,268 - ERROR - [pid 148616] Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd /home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform/ && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 127.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-10 05:08:06,280 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-10 05:08:06,286 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
DEBUG: Asking scheduler for work...
2024-11-10 05:08:06,286 - DEBUG - Asking scheduler for work...
DEBUG: Done
2024-11-10 05:08:06,289 - DEBUG - Done
DEBUG: There are no more tasks to run at this time
2024-11-10 05:08:06,289 - DEBUG - There are no more tasks to run at this time
DEBUG: There are 1 pending tasks possibly being run by other workers
2024-11-10 05:08:06,289 - DEBUG - There are 1 pending tasks possibly being run by other workers
DEBUG: There are 1 pending tasks unique to this worker
2024-11-10 05:08:06,289 - DEBUG - There are 1 pending tasks unique to this worker
DEBUG: There are 1 pending tasks last scheduled by this worker
2024-11-10 05:08:06,289 - DEBUG - There are 1 pending tasks last scheduled by this worker
INFO: Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) was stopped. Shutting down Keep-Alive thread
2024-11-10 05:08:06,290 - INFO - Worker Worker(salt=1459326025, workers=1, host=Erlina, username=istywhyerlina, pid=148616) was stopped. Shutting down Keep-Alive thread
INFO: 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-10 05:08:06,291 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-10 05:21:21,234 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-10 05:21:21,260 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-10 05:21:21,263 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-10 05:21:21,283 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-10 05:21:21,370 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-10 05:21:21,436 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-10 05:21:21,440 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-10 05:21:21,444 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-10 05:21:21,492 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-10 05:21:21,503 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-10 05:21:21,526 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-10 05:21:21,638 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-10 05:21:21,739 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-10 05:21:21,742 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-10 05:21:21,749 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-10 05:21:21,752 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-10 05:21:21,752 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-10 05:21:21,754 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-10 05:21:21,754 - INFO - [pid 157250] Worker Worker(salt=4959484587, workers=1, host=Erlina, username=istywhyerlina, pid=157250) done      Extract()
2024-11-10 05:21:21,755 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 05:21:21,756 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-10 05:21:21,756 - DEBUG - Asking scheduler for work...
2024-11-10 05:21:21,756 - DEBUG - Pending tasks: 2
2024-11-10 05:21:21,757 - INFO - [pid 157250] Worker Worker(salt=4959484587, workers=1, host=Erlina, username=istywhyerlina, pid=157250) running   Load()
2024-11-10 05:21:21,757 - INFO - Read Load Query - SUCCESS
2024-11-10 05:21:21,839 - INFO - Read Extracted Data - SUCCESS
2024-11-10 05:21:21,840 - INFO - Connect to DWH - SUCCESS
2024-11-10 05:21:21,883 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-10 05:21:21,883 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-10 05:21:21,899 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-10 05:21:21,934 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-10 05:21:21,944 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-10 05:21:22,090 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-10 05:21:22,436 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-10 05:21:22,652 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-10 05:21:22,659 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-10 05:21:22,832 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-10 05:21:22,926 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-10 05:21:22,994 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-10 05:21:23,374 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-10 05:21:23,621 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-10 05:21:23,628 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-10 05:21:23,686 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-10 05:21:23,693 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-10 05:21:23,693 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-10 05:21:23,695 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-10 05:21:23,696 - INFO - [pid 157250] Worker Worker(salt=4959484587, workers=1, host=Erlina, username=istywhyerlina, pid=157250) done      Load()
2024-11-10 05:21:23,697 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 05:21:23,697 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-10 05:21:23,698 - DEBUG - Asking scheduler for work...
2024-11-10 05:21:23,698 - DEBUG - Pending tasks: 1
2024-11-10 05:21:23,698 - INFO - [pid 157250] Worker Worker(salt=4959484587, workers=1, host=Erlina, username=istywhyerlina, pid=157250) running   Transform()
2024-11-10 05:21:23,698 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m22:21:26  Running with dbt=1.9.0-b2
[0m22:21:26  Installing dbt-labs/dbt_utils
[0m22:21:27  Installed from version 1.1.1
[0m22:21:27  Updated version available: 1.3.0
[0m22:21:27  Installing calogica/dbt_date
[0m22:21:27  Installed from version 0.10.0
[0m22:21:27  Updated version available: 0.10.1
[0m22:21:27  
[0m22:21:27  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m22:21:31  Running with dbt=1.9.0-b2
[0m22:21:31  Registered adapter: postgres=1.8.2
[0m22:21:32  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m22:21:32  
[0m22:21:32  Concurrency: 1 threads (target='dev')
[0m22:21:32  
[0m22:21:32  1 of 1 START seed file final.dim_date .......................................... [RUN]
[0m22:24:17  1 of 1 OK loaded seed file final.dim_date ...................................... [[32mINSERT 29220[0m in 165.07s]
[0m22:24:17  
[0m22:24:17  Finished running 1 seed in 0 hours 2 minutes and 45.29 seconds (165.29s).
[0m22:24:17  
[0m22:24:17  [32mCompleted successfully[0m
[0m22:24:17  
[0m22:24:17  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:24:20  Running with dbt=1.9.0-b2
[0m22:24:21  Registered adapter: postgres=1.8.2
[0m22:24:21  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m22:24:21  
[0m22:24:21  Concurrency: 1 threads (target='dev')
[0m22:24:21  
[0m22:24:21  1 of 15 START sql view model final.stg_dwh__address ............................ [RUN]
[0m22:24:22  1 of 15 OK created sql view model final.stg_dwh__address ....................... [[32mCREATE VIEW[0m in 0.24s]
[0m22:24:22  2 of 15 START sql view model final.stg_dwh__address_status ..................... [RUN]
[0m22:24:22  2 of 15 OK created sql view model final.stg_dwh__address_status ................ [[32mCREATE VIEW[0m in 0.06s]
[0m22:24:22  3 of 15 START sql view model final.stg_dwh__author ............................. [RUN]
[0m22:24:22  3 of 15 OK created sql view model final.stg_dwh__author ........................ [[32mCREATE VIEW[0m in 0.05s]
[0m22:24:22  4 of 15 START sql view model final.stg_dwh__book ............................... [RUN]
[0m22:24:22  4 of 15 OK created sql view model final.stg_dwh__book .......................... [[32mCREATE VIEW[0m in 0.06s]
[0m22:24:22  5 of 15 START sql view model final.stg_dwh__book_author ........................ [RUN]
[0m22:24:22  5 of 15 OK created sql view model final.stg_dwh__book_author ................... [[32mCREATE VIEW[0m in 0.06s]
[0m22:24:22  6 of 15 START sql view model final.stg_dwh__book_language ...................... [RUN]
[0m22:24:22  6 of 15 OK created sql view model final.stg_dwh__book_language ................. [[32mCREATE VIEW[0m in 0.07s]
[0m22:24:22  7 of 15 START sql view model final.stg_dwh__country ............................ [RUN]
[0m22:24:22  7 of 15 OK created sql view model final.stg_dwh__country ....................... [[32mCREATE VIEW[0m in 0.06s]
[0m22:24:22  8 of 15 START sql view model final.stg_dwh__cust_order ......................... [RUN]
[0m22:24:22  8 of 15 OK created sql view model final.stg_dwh__cust_order .................... [[32mCREATE VIEW[0m in 0.06s]
[0m22:24:22  9 of 15 START sql view model final.stg_dwh__customer ........................... [RUN]
[0m22:24:22  9 of 15 OK created sql view model final.stg_dwh__customer ...................... [[32mCREATE VIEW[0m in 0.06s]
[0m22:24:22  10 of 15 START sql view model final.stg_dwh__customer_adress ................... [RUN]
[0m22:24:22  10 of 15 OK created sql view model final.stg_dwh__customer_adress .............. [[32mCREATE VIEW[0m in 0.05s]
[0m22:24:22  11 of 15 START sql view model final.stg_dwh__order_history ..................... [RUN]
[0m22:24:22  11 of 15 OK created sql view model final.stg_dwh__order_history ................ [[32mCREATE VIEW[0m in 0.06s]
[0m22:24:22  12 of 15 START sql view model final.stg_dwh__order_line ........................ [RUN]
[0m22:24:22  12 of 15 OK created sql view model final.stg_dwh__order_line ................... [[32mCREATE VIEW[0m in 0.10s]
[0m22:24:22  13 of 15 START sql view model final.stg_dwh__order_status ...................... [RUN]
[0m22:24:22  13 of 15 OK created sql view model final.stg_dwh__order_status ................. [[32mCREATE VIEW[0m in 0.05s]
[0m22:24:22  14 of 15 START sql view model final.stg_dwh__publisher ......................... [RUN]
[0m22:24:23  14 of 15 OK created sql view model final.stg_dwh__publisher .................... [[32mCREATE VIEW[0m in 0.06s]
[0m22:24:23  15 of 15 START sql view model final.stg_dwh__shipping_method ................... [RUN]
[0m22:24:23  15 of 15 OK created sql view model final.stg_dwh__shipping_method .............. [[32mCREATE VIEW[0m in 0.05s]
[0m22:24:23  
[0m22:24:23  Finished running 15 view models in 0 hours 0 minutes and 1.32 seconds (1.32s).
[0m22:24:23  
[0m22:24:23  [32mCompleted successfully[0m
[0m22:24:23  
[0m22:24:23  Done. PASS=15 WARN=0 ERROR=0 SKIP=0 TOTAL=15
[0m22:24:26  Running with dbt=1.9.0-b2
[0m22:24:26  Registered adapter: postgres=1.8.2
[0m22:24:27  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m22:24:27  
[0m22:24:27  Concurrency: 1 threads (target='dev')
[0m22:24:27  
[0m22:24:27  1 of 8 START snapshot final.dim_author ......................................... [RUN]
[0m22:24:28  1 of 8 OK snapshotted final.dim_author ......................................... [[32mINSERT 0 0[0m in 0.57s]
[0m22:24:28  2 of 8 START snapshot final.dim_book ........................................... [RUN]
[0m22:24:29  2 of 8 OK snapshotted final.dim_book ........................................... [[32mINSERT 0 0[0m in 1.01s]
[0m22:24:29  3 of 8 START snapshot final.dim_customer_address ............................... [RUN]
[0m22:24:29  3 of 8 OK snapshotted final.dim_customer_address ............................... [[32mINSERT 0 0[0m in 0.17s]
[0m22:24:29  4 of 8 START snapshot final.dim_order_status ................................... [RUN]
[0m22:24:29  4 of 8 OK snapshotted final.dim_order_status ................................... [[32mINSERT 0 0[0m in 0.13s]
[0m22:24:29  5 of 8 START snapshot final.dim_shipping_method ................................ [RUN]
[0m22:24:29  5 of 8 OK snapshotted final.dim_shipping_method ................................ [[32mINSERT 0 0[0m in 0.14s]
[0m22:24:29  6 of 8 START snapshot final.fct_book_author_sales .............................. [RUN]
[0m22:24:30  6 of 8 OK snapshotted final.fct_book_author_sales .............................. [[32mINSERT 0 0[0m in 0.63s]
[0m22:24:30  7 of 8 START snapshot final.fct_sales .......................................... [RUN]
[0m22:24:30  7 of 8 OK snapshotted final.fct_sales .......................................... [[32mINSERT 0 0[0m in 0.43s]
[0m22:24:30  8 of 8 START snapshot final.fct_order .......................................... [RUN]
[0m22:24:32  8 of 8 OK snapshotted final.fct_order .......................................... [[32mINSERT 0 26400[0m in 2.03s]
[0m22:24:32  
[0m22:24:32  Finished running 8 snapshots in 0 hours 0 minutes and 5.37 seconds (5.37s).
[0m22:24:32  
[0m22:24:32  [32mCompleted successfully[0m
[0m22:24:32  
[0m22:24:32  Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2024-11-10 05:24:34,571 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-10 05:24:34,572 - INFO - [pid 157250] Worker Worker(salt=4959484587, workers=1, host=Erlina, username=istywhyerlina, pid=157250) done      Transform()
2024-11-10 05:24:34,572 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 05:24:34,573 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-10 05:24:34,573 - DEBUG - Asking scheduler for work...
2024-11-10 05:24:34,573 - DEBUG - Done
2024-11-10 05:24:34,574 - DEBUG - There are no more tasks to run at this time
2024-11-10 05:24:34,574 - INFO - Worker Worker(salt=4959484587, workers=1, host=Erlina, username=istywhyerlina, pid=157250) was stopped. Shutting down Keep-Alive thread
2024-11-10 05:24:34,575 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

2024-11-10 05:34:49,436 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-10 05:34:49,440 - ERROR - EXTRACT 'address' - FAILED.
2024-11-10 05:34:49,440 - INFO - Extract All Tables From Sources - FAILED
2024-11-10 05:34:49,443 - ERROR - [pid 166135] Worker Worker(salt=7435688574, workers=1, host=Erlina, username=istywhyerlina, pid=166135) failed    Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 68, in run
    df = pd.read_sql_query(extract_query.format(table_name = table_name), src_engine)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 525, in read_sql_query
    with pandasSQL_builder(con) as pandas_sql:
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 906, in pandasSQL_builder
    return SQLDatabase(con, schema, need_transaction)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/pandas/io/sql.py", line 1636, in __init__
    con = self.exit_stack.enter_context(con.connect())
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3278, in connect
    return self._connection_cls(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 148, in __init__
    Connection._handle_dbapi_exception_noconnection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2442, in _handle_dbapi_exception_noconnection
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 146, in __init__
    self._dbapi_connection = engine.raw_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 3302, in raw_connection
    return self.pool.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 449, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 1263, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 712, in checkout
    rec = pool._do_get()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 179, in _do_get
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/impl.py", line 177, in _do_get
    return self._create_connection()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 390, in _create_connection
    return _ConnectionRecord(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 674, in __init__
    self.__connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 900, in __connect
    with util.safe_reraise():
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py", line 146, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/pool/base.py", line 896, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/create.py", line 643, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 621, in connect
    return self.loaded_dbapi.connect(*cargs, **cparams)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "localhost" (127.0.0.1), port 5443 failed: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

(Background on this error at: https://sqlalche.me/e/20/e3q8)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 77, in run
    raise Exception(f"Failed to extract '{table_name}' tables")
Exception: Failed to extract 'address' tables

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/extract.py", line 116, in run
    raise Exception(f"FAILED to execute EXTRACT TASK !!!")
Exception: FAILED to execute EXTRACT TASK !!!
2024-11-10 05:34:49,453 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 05:34:49,456 - INFO - Informed scheduler that task   Extract__99914b932b   has status   FAILED
2024-11-10 05:34:49,456 - DEBUG - Asking scheduler for work...
2024-11-10 05:34:49,457 - DEBUG - Done
2024-11-10 05:34:49,457 - DEBUG - There are no more tasks to run at this time
2024-11-10 05:34:49,457 - DEBUG - There are 3 pending tasks possibly being run by other workers
2024-11-10 05:34:49,458 - DEBUG - There are 3 pending tasks unique to this worker
2024-11-10 05:34:49,458 - DEBUG - There are 3 pending tasks last scheduled by this worker
2024-11-10 05:34:49,459 - INFO - Worker Worker(salt=7435688574, workers=1, host=Erlina, username=istywhyerlina, pid=166135) was stopped. Shutting down Keep-Alive thread
2024-11-10 05:34:49,460 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 1 failed:
    - 1 Extract()
* 2 were left pending, among these:
    * 2 had failed dependencies:
        - 1 Load()
        - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-10 06:32:16,440 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-10 06:32:16,486 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-10 06:32:16,491 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-10 06:32:16,515 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-10 06:32:16,598 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-10 06:32:16,658 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-10 06:32:16,661 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-10 06:32:16,664 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-10 06:32:16,726 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-10 06:32:16,736 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-10 06:32:16,746 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-10 06:32:16,865 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-10 06:32:16,957 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-10 06:32:16,961 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-10 06:32:16,970 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-10 06:32:16,974 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-10 06:32:16,974 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-10 06:32:16,976 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-10 06:32:16,976 - INFO - [pid 21686] Worker Worker(salt=6251108681, workers=1, host=Erlina, username=istywhyerlina, pid=21686) done      Extract()
2024-11-10 06:32:16,977 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 06:32:16,978 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-10 06:32:16,978 - DEBUG - Asking scheduler for work...
2024-11-10 06:32:16,978 - DEBUG - Pending tasks: 2
2024-11-10 06:32:16,978 - INFO - [pid 21686] Worker Worker(salt=6251108681, workers=1, host=Erlina, username=istywhyerlina, pid=21686) running   Load()
2024-11-10 06:32:16,980 - INFO - Read Load Query - SUCCESS
2024-11-10 06:32:17,060 - INFO - Read Extracted Data - SUCCESS
2024-11-10 06:32:17,061 - INFO - Connect to DWH - SUCCESS
2024-11-10 06:32:17,100 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-10 06:32:17,100 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-10 06:32:17,114 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-10 06:32:17,145 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-10 06:32:17,151 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-10 06:32:17,257 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-10 06:32:17,604 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-10 06:32:17,843 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-10 06:32:17,853 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-10 06:32:18,027 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-10 06:32:18,085 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-10 06:32:18,140 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-10 06:32:18,543 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-10 06:32:18,778 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-10 06:32:18,783 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-10 06:32:18,840 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-10 06:32:18,846 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-10 06:32:18,846 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-10 06:32:18,847 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-10 06:32:18,848 - INFO - [pid 21686] Worker Worker(salt=6251108681, workers=1, host=Erlina, username=istywhyerlina, pid=21686) done      Load()
2024-11-10 06:32:18,849 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 06:32:18,849 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-10 06:32:18,849 - DEBUG - Asking scheduler for work...
2024-11-10 06:32:18,850 - DEBUG - Pending tasks: 1
2024-11-10 06:32:18,850 - INFO - [pid 21686] Worker Worker(salt=6251108681, workers=1, host=Erlina, username=istywhyerlina, pid=21686) running   Transform()
2024-11-10 06:32:18,850 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m23:32:21  Running with dbt=1.9.0-b2
[0m23:32:21  Installing dbt-labs/dbt_utils
[0m23:32:22  Installed from version 1.1.1
[0m23:32:22  Updated version available: 1.3.0
[0m23:32:22  Installing calogica/dbt_date
[0m23:32:23  Installed from version 0.10.0
[0m23:32:23  Updated version available: 0.10.1
[0m23:32:23  
[0m23:32:23  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m23:32:25  Running with dbt=1.9.0-b2
[0m23:32:26  Registered adapter: postgres=1.8.2
[0m23:32:26  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m23:32:26  
[0m23:32:26  Concurrency: 1 threads (target='dev')
[0m23:32:26  
[0m23:32:26  
[0m23:32:26  Finished running  in 0 hours 0 minutes and 0.05 seconds (0.05s).
[0m23:32:26  Encountered an error:
Database Error
  connection to server at "localhost" (127.0.0.1), port 5445 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  
2024-11-10 06:32:28,372 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-11-10 06:32:28,374 - ERROR - Transform Tables - FAILED
2024-11-10 06:32:28,374 - ERROR - [pid 21686] Worker Worker(salt=6251108681, workers=1, host=Erlina, username=istywhyerlina, pid=21686) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd /home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform/ && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 2.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-11-10 06:32:28,376 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 06:32:28,380 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-10 06:32:28,381 - DEBUG - Asking scheduler for work...
2024-11-10 06:32:28,381 - DEBUG - Done
2024-11-10 06:32:28,381 - DEBUG - There are no more tasks to run at this time
2024-11-10 06:32:28,381 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-10 06:32:28,381 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-10 06:32:28,381 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-10 06:32:28,382 - INFO - Worker Worker(salt=6251108681, workers=1, host=Erlina, username=istywhyerlina, pid=21686) was stopped. Shutting down Keep-Alive thread
2024-11-10 06:32:28,383 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Load() is complete
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Transform() is complete
DEBUG: Checking if Load() is complete
INFO: Informed scheduler that task   Transform__99914b932b   has status   PENDING
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
INFO: Done scheduling tasks
INFO: Running Worker with 1 processes
DEBUG: Asking scheduler for work...
DEBUG: Pending tasks: 3
INFO: [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) running   Extract()
2024-11-10 06:35:02,549 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-10 06:35:02,576 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-10 06:35:02,581 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-10 06:35:02,607 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-10 06:35:02,691 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-10 06:35:02,748 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-10 06:35:02,752 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-10 06:35:02,756 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-10 06:35:02,805 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-10 06:35:02,815 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-10 06:35:02,826 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-10 06:35:02,943 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-10 06:35:03,069 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-10 06:35:03,073 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-10 06:35:03,081 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-10 06:35:03,087 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-10 06:35:03,087 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-10 06:35:03,089 - INFO - ==================================ENDING EXTRACT DATA=======================================
INFO: [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) done      Extract()
2024-11-10 06:35:03,089 - INFO - [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) done      Extract()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-10 06:35:03,090 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-10 06:35:03,093 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-10 06:35:03,093 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 2
2024-11-10 06:35:03,096 - DEBUG - Pending tasks: 2
INFO: [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) running   Load()
2024-11-10 06:35:03,096 - INFO - [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) running   Load()
2024-11-10 06:35:03,097 - INFO - Read Load Query - SUCCESS
2024-11-10 06:35:03,184 - INFO - Read Extracted Data - SUCCESS
2024-11-10 06:35:03,186 - INFO - Connect to DWH - SUCCESS
2024-11-10 06:35:03,234 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-10 06:35:03,234 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-10 06:35:03,254 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-10 06:35:03,314 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-10 06:35:03,324 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-10 06:35:03,456 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-10 06:35:03,896 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-10 06:35:04,153 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-10 06:35:04,163 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-10 06:35:04,367 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-10 06:35:04,458 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-10 06:35:04,509 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-10 06:35:04,941 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-10 06:35:05,287 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-10 06:35:05,299 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-10 06:35:05,351 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-10 06:35:05,362 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-10 06:35:05,363 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-10 06:35:05,365 - INFO - ==================================ENDING LOAD DATA=======================================
INFO: [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) done      Load()
2024-11-10 06:35:05,366 - INFO - [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) done      Load()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-10 06:35:05,367 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-10 06:35:05,374 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-10 06:35:05,374 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 1
2024-11-10 06:35:05,378 - DEBUG - Pending tasks: 1
INFO: [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) running   Transform()
2024-11-10 06:35:05,378 - INFO - [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) running   Transform()
2024-11-10 06:35:05,378 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-11-10 06:35:05,379 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-11-10 06:35:05,381 - ERROR - Transform Tables - FAILED
ERROR: [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd /home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 127.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-11-10 06:35:05,381 - ERROR - [pid 23375] Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd /home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 127.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-10 06:35:05,382 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-10 06:35:05,389 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
DEBUG: Asking scheduler for work...
2024-11-10 06:35:05,389 - DEBUG - Asking scheduler for work...
DEBUG: Done
2024-11-10 06:35:05,393 - DEBUG - Done
DEBUG: There are no more tasks to run at this time
2024-11-10 06:35:05,393 - DEBUG - There are no more tasks to run at this time
DEBUG: There are 1 pending tasks possibly being run by other workers
2024-11-10 06:35:05,393 - DEBUG - There are 1 pending tasks possibly being run by other workers
DEBUG: There are 1 pending tasks unique to this worker
2024-11-10 06:35:05,394 - DEBUG - There are 1 pending tasks unique to this worker
DEBUG: There are 1 pending tasks last scheduled by this worker
2024-11-10 06:35:05,394 - DEBUG - There are 1 pending tasks last scheduled by this worker
INFO: Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) was stopped. Shutting down Keep-Alive thread
2024-11-10 06:35:05,394 - INFO - Worker Worker(salt=145528310, workers=1, host=Erlina, username=istywhyerlina, pid=23375) was stopped. Shutting down Keep-Alive thread
INFO: 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-10 06:35:05,396 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-10 06:41:17,502 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-10 06:41:17,531 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-10 06:41:17,535 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-10 06:41:17,555 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-10 06:41:17,625 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-10 06:41:17,689 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-10 06:41:17,692 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-10 06:41:17,696 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-10 06:41:17,739 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-10 06:41:17,747 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-10 06:41:17,757 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-10 06:41:17,876 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-10 06:41:17,982 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-10 06:41:17,985 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-10 06:41:17,993 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-10 06:41:17,996 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-10 06:41:17,996 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-10 06:41:17,998 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-10 06:41:17,998 - INFO - [pid 26779] Worker Worker(salt=8596291331, workers=1, host=Erlina, username=istywhyerlina, pid=26779) done      Extract()
2024-11-10 06:41:17,999 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 06:41:18,000 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-10 06:41:18,000 - DEBUG - Asking scheduler for work...
2024-11-10 06:41:18,000 - DEBUG - Pending tasks: 2
2024-11-10 06:41:18,000 - INFO - [pid 26779] Worker Worker(salt=8596291331, workers=1, host=Erlina, username=istywhyerlina, pid=26779) running   Load()
2024-11-10 06:41:18,001 - INFO - Read Load Query - SUCCESS
2024-11-10 06:41:18,084 - INFO - Read Extracted Data - SUCCESS
2024-11-10 06:41:18,084 - INFO - Connect to DWH - SUCCESS
2024-11-10 06:41:18,127 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-10 06:41:18,127 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-10 06:41:18,139 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-10 06:41:18,177 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-10 06:41:18,183 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-10 06:41:18,290 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-10 06:41:18,629 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-10 06:41:18,866 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-10 06:41:18,873 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-10 06:41:19,005 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-10 06:41:19,054 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-10 06:41:19,098 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-10 06:41:19,477 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-10 06:41:19,777 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-10 06:41:19,784 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-10 06:41:19,857 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-10 06:41:19,864 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-10 06:41:19,864 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-10 06:41:19,866 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-10 06:41:19,867 - INFO - [pid 26779] Worker Worker(salt=8596291331, workers=1, host=Erlina, username=istywhyerlina, pid=26779) done      Load()
2024-11-10 06:41:19,867 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 06:41:19,868 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-10 06:41:19,868 - DEBUG - Asking scheduler for work...
2024-11-10 06:41:19,868 - DEBUG - Pending tasks: 1
2024-11-10 06:41:19,868 - INFO - [pid 26779] Worker Worker(salt=8596291331, workers=1, host=Erlina, username=istywhyerlina, pid=26779) running   Transform()
2024-11-10 06:41:19,869 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m23:41:21  Running with dbt=1.9.0-b2
[0m23:41:22  Installing dbt-labs/dbt_utils
[0m23:41:22  Installed from version 1.1.1
[0m23:41:22  Updated version available: 1.3.0
[0m23:41:22  Installing calogica/dbt_date
[0m23:41:23  Installed from version 0.10.0
[0m23:41:23  Updated version available: 0.10.1
[0m23:41:23  
[0m23:41:23  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m23:41:26  Running with dbt=1.9.0-b2
[0m23:41:26  Registered adapter: postgres=1.8.2
[0m23:41:27  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m23:41:27  
[0m23:41:27  Concurrency: 1 threads (target='dev')
[0m23:41:27  
[0m23:41:27  
[0m23:41:27  Finished running  in 0 hours 0 minutes and 0.05 seconds (0.05s).
[0m23:41:27  Encountered an error:
Database Error
  connection to server at "localhost" (127.0.0.1), port 5445 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  
2024-11-10 06:41:28,852 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-11-10 06:41:28,854 - ERROR - Transform Tables - FAILED
2024-11-10 06:41:28,854 - ERROR - [pid 26779] Worker Worker(salt=8596291331, workers=1, host=Erlina, username=istywhyerlina, pid=26779) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd /home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform && dbt deps && dbt seed && dbt run && dbt snapshot' returned non-zero exit status 2.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-11-10 06:41:28,856 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 06:41:28,859 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-10 06:41:28,860 - DEBUG - Asking scheduler for work...
2024-11-10 06:41:28,860 - DEBUG - Done
2024-11-10 06:41:28,860 - DEBUG - There are no more tasks to run at this time
2024-11-10 06:41:28,860 - DEBUG - There are 1 pending tasks possibly being run by other workers
2024-11-10 06:41:28,860 - DEBUG - There are 1 pending tasks unique to this worker
2024-11-10 06:41:28,860 - DEBUG - There are 1 pending tasks last scheduled by this worker
2024-11-10 06:41:28,861 - INFO - Worker Worker(salt=8596291331, workers=1, host=Erlina, username=istywhyerlina, pid=26779) was stopped. Shutting down Keep-Alive thread
2024-11-10 06:41:28,863 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

[0m23:42:03  Running with dbt=1.9.0-b2
[0m23:42:04  Installing dbt-labs/dbt_utils
[0m23:42:06  Installed from version 1.1.1
[0m23:42:06  Updated version available: 1.3.0
[0m23:42:06  Installing calogica/dbt_date
[0m23:42:06  Installed from version 0.10.0
[0m23:42:06  Updated version available: 0.10.1
[0m23:42:06  
[0m23:42:06  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m23:42:09  Running with dbt=1.9.0-b2
[0m23:42:09  Registered adapter: postgres=1.8.2
[0m23:42:10  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m23:42:10  
[0m23:42:10  Concurrency: 1 threads (target='dev')
[0m23:42:10  
[0m23:42:10  
[0m23:42:10  Finished running  in 0 hours 0 minutes and 0.05 seconds (0.05s).
[0m23:42:10  Encountered an error:
Database Error
  connection to server at "localhost" (127.0.0.1), port 5445 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  
[0m23:44:26  Running with dbt=1.9.0-b2
[0m23:44:27  Installing dbt-labs/dbt_utils
[0m23:44:27  Installed from version 1.1.1
[0m23:44:27  Updated version available: 1.3.0
[0m23:44:27  Installing calogica/dbt_date
[0m23:44:28  Installed from version 0.10.0
[0m23:44:28  Updated version available: 0.10.1
[0m23:44:28  
[0m23:44:28  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m23:44:32  Running with dbt=1.9.0-b2
[0m23:44:32  Registered adapter: postgres=1.8.2
[0m23:44:33  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m23:44:33  
[0m23:44:33  Concurrency: 1 threads (target='dev')
[0m23:44:33  
[0m23:44:33  
[0m23:44:33  Finished running  in 0 hours 0 minutes and 0.05 seconds (0.05s).
[0m23:44:33  Encountered an error:
Database Error
  connection to server at "localhost" (127.0.0.1), port 5445 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  
[0m23:45:54  Running with dbt=1.9.0-b2
[0m23:45:54  Installing dbt-labs/dbt_utils
[0m23:45:55  Installed from version 1.1.1
[0m23:45:55  Updated version available: 1.3.0
[0m23:45:55  Installing calogica/dbt_date
[0m23:45:55  Installed from version 0.10.0
[0m23:45:55  Updated version available: 0.10.1
[0m23:45:55  
[0m23:45:55  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m23:45:59  Running with dbt=1.9.0-b2
[0m23:46:00  Registered adapter: postgres=1.8.2
[0m23:46:00  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m23:46:00  
[0m23:46:00  Concurrency: 1 threads (target='dev')
[0m23:46:00  
[0m23:46:00  
[0m23:46:00  Finished running  in 0 hours 0 minutes and 0.05 seconds (0.05s).
[0m23:46:00  Encountered an error:
Database Error
  connection to server at "localhost" (127.0.0.1), port 5445 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  
[0m23:51:25  Running with dbt=1.9.0-b2
[0m23:51:26  Installing dbt-labs/dbt_utils
[0m23:51:26  Installed from version 1.1.1
[0m23:51:26  Updated version available: 1.3.0
[0m23:51:26  Installing calogica/dbt_date
[0m23:51:27  Installed from version 0.10.0
[0m23:51:27  Updated version available: 0.10.1
[0m23:51:27  
[0m23:51:27  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m23:51:30  Running with dbt=1.9.0-b2
[0m23:51:30  Registered adapter: postgres=1.8.2
[0m23:51:30  Found 1 seed, 15 models, 8 snapshots, 15 sources, 673 macros
[0m23:51:30  
[0m23:51:30  Concurrency: 1 threads (target='dev')
[0m23:51:30  
[0m23:51:31  
[0m23:51:31  Finished running  in 0 hours 0 minutes and 0.05 seconds (0.05s).
[0m23:51:31  Encountered an error:
Database Error
  connection to server at "localhost" (127.0.0.1), port 5445 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  
2024-11-10 06:57:01,308 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-10 06:57:01,332 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-10 06:57:01,334 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-10 06:57:01,355 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-10 06:57:01,422 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-10 06:57:01,481 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-10 06:57:01,484 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-10 06:57:01,487 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-10 06:57:01,531 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-10 06:57:01,541 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-10 06:57:01,550 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-10 06:57:01,669 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-10 06:57:01,780 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-10 06:57:01,782 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-10 06:57:01,791 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-10 06:57:01,794 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-10 06:57:01,794 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-10 06:57:01,795 - INFO - ==================================ENDING EXTRACT DATA=======================================
2024-11-10 06:57:01,796 - INFO - [pid 40914] Worker Worker(salt=3247790989, workers=1, host=Erlina, username=istywhyerlina, pid=40914) done      Extract()
2024-11-10 06:57:01,797 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 06:57:01,798 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-10 06:57:01,798 - DEBUG - Asking scheduler for work...
2024-11-10 06:57:01,798 - DEBUG - Pending tasks: 2
2024-11-10 06:57:01,798 - INFO - [pid 40914] Worker Worker(salt=3247790989, workers=1, host=Erlina, username=istywhyerlina, pid=40914) running   Load()
2024-11-10 06:57:01,799 - INFO - Read Load Query - SUCCESS
2024-11-10 06:57:01,867 - INFO - Read Extracted Data - SUCCESS
2024-11-10 06:57:01,868 - INFO - Connect to DWH - SUCCESS
2024-11-10 06:57:01,909 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-10 06:57:01,909 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-10 06:57:01,922 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-10 06:57:01,957 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-10 06:57:01,962 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-10 06:57:02,076 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-10 06:57:02,404 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-10 06:57:02,609 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-10 06:57:02,616 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-10 06:57:02,760 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-10 06:57:02,806 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-10 06:57:02,857 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-10 06:57:03,241 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-10 06:57:03,473 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-10 06:57:03,479 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-10 06:57:03,533 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-10 06:57:03,538 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-10 06:57:03,538 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-10 06:57:03,539 - INFO - ==================================ENDING LOAD DATA=======================================
2024-11-10 06:57:03,540 - INFO - [pid 40914] Worker Worker(salt=3247790989, workers=1, host=Erlina, username=istywhyerlina, pid=40914) done      Load()
2024-11-10 06:57:03,541 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 06:57:03,541 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-10 06:57:03,541 - DEBUG - Asking scheduler for work...
2024-11-10 06:57:03,542 - DEBUG - Pending tasks: 1
2024-11-10 06:57:03,542 - INFO - [pid 40914] Worker Worker(salt=3247790989, workers=1, host=Erlina, username=istywhyerlina, pid=40914) running   Transform()
2024-11-10 06:57:03,542 - INFO - ==================================STARTING TRANSFROM DATA=======================================
[0m23:57:05  Running with dbt=1.9.0-b2
[0m23:57:06  Installing dbt-labs/dbt_utils
[0m23:57:06  Installed from version 1.1.1
[0m23:57:06  Updated version available: 1.3.0
[0m23:57:06  Installing calogica/dbt_date
[0m23:57:07  Installed from version 0.10.0
[0m23:57:07  Updated version available: 0.10.1
[0m23:57:07  
[0m23:57:07  Updates available for packages: ['dbt-labs/dbt_utils', 'calogica/dbt_date']                 
Update your versions in packages.yml, then run dbt deps
[0m23:57:10  Running with dbt=1.9.0-b2
[0m23:57:10  Registered adapter: postgres=1.8.2
[0m23:57:11  Found 15 models, 8 snapshots, 1 seed, 15 sources, 673 macros
[0m23:57:11  
[0m23:57:11  Concurrency: 1 threads (target='dev')
[0m23:57:11  
[0m23:57:11  1 of 24 START sql view model final.stg_dwh__address ............................ [RUN]
[0m23:57:11  1 of 24 OK created sql view model final.stg_dwh__address ....................... [[32mCREATE VIEW[0m in 0.20s]
[0m23:57:11  2 of 24 START sql view model final.stg_dwh__address_status ..................... [RUN]
[0m23:57:11  2 of 24 OK created sql view model final.stg_dwh__address_status ................ [[32mCREATE VIEW[0m in 0.13s]
[0m23:57:11  3 of 24 START sql view model final.stg_dwh__author ............................. [RUN]
[0m23:57:11  3 of 24 OK created sql view model final.stg_dwh__author ........................ [[32mCREATE VIEW[0m in 0.11s]
[0m23:57:12  4 of 24 START sql view model final.stg_dwh__book ............................... [RUN]
[0m23:57:12  4 of 24 OK created sql view model final.stg_dwh__book .......................... [[32mCREATE VIEW[0m in 0.09s]
[0m23:57:12  5 of 24 START sql view model final.stg_dwh__book_author ........................ [RUN]
[0m23:57:12  5 of 24 OK created sql view model final.stg_dwh__book_author ................... [[32mCREATE VIEW[0m in 0.07s]
[0m23:57:12  6 of 24 START sql view model final.stg_dwh__book_language ...................... [RUN]
[0m23:57:12  6 of 24 OK created sql view model final.stg_dwh__book_language ................. [[32mCREATE VIEW[0m in 0.10s]
[0m23:57:12  7 of 24 START sql view model final.stg_dwh__country ............................ [RUN]
[0m23:57:12  7 of 24 OK created sql view model final.stg_dwh__country ....................... [[32mCREATE VIEW[0m in 0.07s]
[0m23:57:12  8 of 24 START sql view model final.stg_dwh__cust_order ......................... [RUN]
[0m23:57:12  8 of 24 OK created sql view model final.stg_dwh__cust_order .................... [[32mCREATE VIEW[0m in 0.08s]
[0m23:57:12  9 of 24 START sql view model final.stg_dwh__customer ........................... [RUN]
[0m23:57:12  9 of 24 OK created sql view model final.stg_dwh__customer ...................... [[32mCREATE VIEW[0m in 0.08s]
[0m23:57:12  10 of 24 START sql view model final.stg_dwh__customer_adress ................... [RUN]
[0m23:57:12  10 of 24 OK created sql view model final.stg_dwh__customer_adress .............. [[32mCREATE VIEW[0m in 0.06s]
[0m23:57:12  11 of 24 START sql view model final.stg_dwh__order_history ..................... [RUN]
[0m23:57:12  11 of 24 OK created sql view model final.stg_dwh__order_history ................ [[32mCREATE VIEW[0m in 0.07s]
[0m23:57:12  12 of 24 START sql view model final.stg_dwh__order_line ........................ [RUN]
[0m23:57:12  12 of 24 OK created sql view model final.stg_dwh__order_line ................... [[32mCREATE VIEW[0m in 0.07s]
[0m23:57:12  13 of 24 START sql view model final.stg_dwh__order_status ...................... [RUN]
[0m23:57:12  13 of 24 OK created sql view model final.stg_dwh__order_status ................. [[32mCREATE VIEW[0m in 0.10s]
[0m23:57:12  14 of 24 START sql view model final.stg_dwh__publisher ......................... [RUN]
[0m23:57:12  14 of 24 OK created sql view model final.stg_dwh__publisher .................... [[32mCREATE VIEW[0m in 0.08s]
[0m23:57:12  15 of 24 START sql view model final.stg_dwh__shipping_method ................... [RUN]
[0m23:57:12  15 of 24 OK created sql view model final.stg_dwh__shipping_method .............. [[32mCREATE VIEW[0m in 0.06s]
[0m23:57:12  16 of 24 START seed file final.dim_date ........................................ [RUN]
[0m23:59:46  16 of 24 OK loaded seed file final.dim_date .................................... [[32mINSERT 29220[0m in 153.31s]
[0m23:59:46  17 of 24 START snapshot final.dim_author ....................................... [RUN]
[0m23:59:46  17 of 24 OK snapshotted final.dim_author ....................................... [[32mSELECT 9235[0m in 0.17s]
[0m23:59:46  18 of 24 START snapshot final.dim_customer_address ............................. [RUN]
[0m23:59:46  18 of 24 OK snapshotted final.dim_customer_address ............................. [[32mSELECT 2950[0m in 0.06s]
[0m23:59:46  19 of 24 START snapshot final.dim_order_status ................................. [RUN]
[0m23:59:46  19 of 24 OK snapshotted final.dim_order_status ................................. [[32mSELECT 6[0m in 0.04s]
[0m23:59:46  20 of 24 START snapshot final.dim_book ......................................... [RUN]
[0m23:59:46  20 of 24 OK snapshotted final.dim_book ......................................... [[32mSELECT 11127[0m in 0.10s]
[0m23:59:46  21 of 24 START snapshot final.dim_shipping_method .............................. [RUN]
[0m23:59:46  21 of 24 OK snapshotted final.dim_shipping_method .............................. [[32mSELECT 4[0m in 0.04s]
[0m23:59:46  22 of 24 START snapshot final.fct_book_author_sales ............................ [RUN]
[0m23:59:47  22 of 24 OK snapshotted final.fct_book_author_sales ............................ [[32mSELECT 23838[0m in 0.24s]
[0m23:59:47  23 of 24 START snapshot final.fct_sales ........................................ [RUN]
[0m23:59:47  23 of 24 OK snapshotted final.fct_sales ........................................ [[32mSELECT 15400[0m in 0.18s]
[0m23:59:47  24 of 24 START snapshot final.fct_order ........................................ [RUN]
[0m23:59:49  24 of 24 OK snapshotted final.fct_order ........................................ [[32mSELECT 22345[0m in 0.97s]
[0m23:59:49  
[0m23:59:49  Finished running 1 seed, 8 snapshots, 15 view models in 0 hours 2 minutes and 38.43 seconds (158.43s).
[0m23:59:49  
[0m23:59:49  [32mCompleted successfully[0m
[0m23:59:49  
[0m23:59:49  Done. PASS=24 WARN=0 ERROR=0 SKIP=0 TOTAL=24
[0m23:59:52  Running with dbt=1.9.0-b2
[0m23:59:52  Registered adapter: postgres=1.8.2
[0m23:59:53  Found 15 models, 8 snapshots, 1 seed, 15 sources, 673 macros
[0m23:59:53  
[0m23:59:53  Concurrency: 1 threads (target='dev')
[0m23:59:53  
[0m23:59:53  1 of 8 START snapshot final.dim_author ......................................... [RUN]
[0m23:59:53  1 of 8 OK snapshotted final.dim_author ......................................... [[32mINSERT 0 0[0m in 0.34s]
[0m23:59:53  2 of 8 START snapshot final.dim_book ........................................... [RUN]
[0m23:59:54  2 of 8 OK snapshotted final.dim_book ........................................... [[32mINSERT 0 0[0m in 0.21s]
[0m23:59:54  3 of 8 START snapshot final.dim_customer_address ............................... [RUN]
[0m23:59:54  3 of 8 OK snapshotted final.dim_customer_address ............................... [[32mINSERT 0 0[0m in 0.16s]
[0m23:59:54  4 of 8 START snapshot final.dim_order_status ................................... [RUN]
[0m23:59:54  4 of 8 OK snapshotted final.dim_order_status ................................... [[32mINSERT 0 0[0m in 0.13s]
[0m23:59:54  5 of 8 START snapshot final.dim_shipping_method ................................ [RUN]
[0m23:59:54  5 of 8 OK snapshotted final.dim_shipping_method ................................ [[32mINSERT 0 0[0m in 0.14s]
[0m23:59:54  6 of 8 START snapshot final.fct_book_author_sales .............................. [RUN]
[0m23:59:54  6 of 8 OK snapshotted final.fct_book_author_sales .............................. [[32mINSERT 0 0[0m in 0.35s]
[0m23:59:54  7 of 8 START snapshot final.fct_sales .......................................... [RUN]
[0m23:59:55  7 of 8 OK snapshotted final.fct_sales .......................................... [[32mINSERT 0 0[0m in 0.31s]
[0m23:59:55  8 of 8 START snapshot final.fct_order .......................................... [RUN]
[0m23:59:57  8 of 8 OK snapshotted final.fct_order .......................................... [[32mINSERT 0 26400[0m in 1.77s]
[0m23:59:57  
[0m23:59:57  Finished running 8 snapshots in 0 hours 0 minutes and 3.67 seconds (3.67s).
[0m23:59:57  
[0m23:59:57  [32mCompleted successfully[0m
[0m23:59:57  
[0m23:59:57  Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2024-11-10 06:59:58,928 - INFO - ==================================ENDING TRANSFROM DATA=======================================
2024-11-10 06:59:58,928 - INFO - [pid 40914] Worker Worker(salt=3247790989, workers=1, host=Erlina, username=istywhyerlina, pid=40914) done      Transform()
2024-11-10 06:59:58,929 - DEBUG - 1 running tasks, waiting for next task to finish
2024-11-10 06:59:58,929 - INFO - Informed scheduler that task   Transform__99914b932b   has status   DONE
2024-11-10 06:59:58,929 - DEBUG - Asking scheduler for work...
2024-11-10 06:59:58,930 - DEBUG - Done
2024-11-10 06:59:58,930 - DEBUG - There are no more tasks to run at this time
2024-11-10 06:59:58,930 - INFO - Worker Worker(salt=3247790989, workers=1, host=Erlina, username=istywhyerlina, pid=40914) was stopped. Shutting down Keep-Alive thread
2024-11-10 06:59:58,931 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 3 ran successfully:
    - 1 Extract()
    - 1 Load()
    - 1 Transform()

This progress looks :) because there were no failed tasks or missing dependencies

===== Luigi Execution Summary =====

DEBUG: Checking if Extract() is complete
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
ERROR: Luigi unexpected framework error while scheduling Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f8683d5d930>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8683d5d930>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8683d5d930>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed pinging scheduler
INFO: Worker Worker(salt=5494598287, workers=1, host=Erlina, username=istywhyerlina, pid=43334) was stopped. Shutting down Keep-Alive thread
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f8683d5d930>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8683d5d930>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8683d5d930>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 97, in <module>
    luigi.build([Extract(),
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 243, in build
    luigi_run_result = _schedule_and_run(tasks, worker_scheduler_factory, override_defaults=env_params)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 175, in _schedule_and_run
    success &= worker.add(t, env_params.parallel_scheduling, env_params.parallel_scheduling_processes)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Load() is complete
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
DEBUG: Checking if Transform() is complete
DEBUG: Checking if Load() is complete
INFO: Informed scheduler that task   Transform__99914b932b   has status   PENDING
DEBUG: Checking if Extract() is complete
INFO: Informed scheduler that task   Load__99914b932b   has status   PENDING
INFO: Informed scheduler that task   Extract__99914b932b   has status   PENDING
INFO: Done scheduling tasks
INFO: Running Worker with 1 processes
DEBUG: Asking scheduler for work...
DEBUG: Pending tasks: 3
INFO: [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) running   Extract()
2024-11-10 07:25:02,910 - INFO - ==================================STARTING EXTRACT DATA=======================================
2024-11-10 07:25:02,943 - INFO - EXTRACT 'address' - SUCCESS.
2024-11-10 07:25:02,949 - INFO - EXTRACT 'address_status' - SUCCESS.
2024-11-10 07:25:03,026 - INFO - EXTRACT 'author' - SUCCESS.
2024-11-10 07:25:03,146 - INFO - EXTRACT 'book' - SUCCESS.
2024-11-10 07:25:03,223 - INFO - EXTRACT 'book_author' - SUCCESS.
2024-11-10 07:25:03,226 - INFO - EXTRACT 'book_language' - SUCCESS.
2024-11-10 07:25:03,230 - INFO - EXTRACT 'country' - SUCCESS.
2024-11-10 07:25:03,280 - INFO - EXTRACT 'cust_order' - SUCCESS.
2024-11-10 07:25:03,291 - INFO - EXTRACT 'customer' - SUCCESS.
2024-11-10 07:25:03,303 - INFO - EXTRACT 'customer_address' - SUCCESS.
2024-11-10 07:25:03,422 - INFO - EXTRACT 'order_history' - SUCCESS.
2024-11-10 07:25:03,544 - INFO - EXTRACT 'order_line' - SUCCESS.
2024-11-10 07:25:03,550 - INFO - EXTRACT 'order_status' - SUCCESS.
2024-11-10 07:25:03,560 - INFO - EXTRACT 'publisher' - SUCCESS.
2024-11-10 07:25:03,566 - INFO - EXTRACT 'shipping_method' - SUCCESS.
2024-11-10 07:25:03,566 - INFO - Extract All Tables From Sources - SUCCESS
2024-11-10 07:25:03,569 - INFO - ==================================ENDING EXTRACT DATA=======================================
INFO: [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) done      Extract()
2024-11-10 07:25:03,569 - INFO - [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) done      Extract()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-10 07:25:03,571 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Extract__99914b932b   has status   DONE
2024-11-10 07:25:03,580 - INFO - Informed scheduler that task   Extract__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-10 07:25:03,581 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 2
2024-11-10 07:25:03,589 - DEBUG - Pending tasks: 2
INFO: [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) running   Load()
2024-11-10 07:25:03,589 - INFO - [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) running   Load()
2024-11-10 07:25:03,591 - INFO - Read Load Query - SUCCESS
2024-11-10 07:25:03,695 - INFO - Read Extracted Data - SUCCESS
2024-11-10 07:25:03,696 - INFO - Connect to DWH - SUCCESS
2024-11-10 07:25:03,731 - INFO - Truncate pacbook Schema in DWH - SUCCESS
2024-11-10 07:25:03,732 - INFO - ==================================STARTING LOAD DATA=======================================
2024-11-10 07:25:03,748 - INFO - LOAD 'pacbook.country' - SUCCESS
2024-11-10 07:25:03,781 - INFO - LOAD 'pacbook.address' - SUCCESS
2024-11-10 07:25:03,788 - INFO - LOAD 'pacbook.address_status' - SUCCESS
2024-11-10 07:25:03,902 - INFO - LOAD 'pacbook.author' - SUCCESS
2024-11-10 07:25:04,307 - INFO - LOAD 'pacbook.book' - SUCCESS
2024-11-10 07:25:04,561 - INFO - LOAD 'pacbook.book_author' - SUCCESS
2024-11-10 07:25:04,569 - INFO - LOAD 'pacbook.book_language' - SUCCESS
2024-11-10 07:25:04,762 - INFO - LOAD 'pacbook.cust_order' - SUCCESS
2024-11-10 07:25:04,811 - INFO - LOAD 'pacbook.customer' - SUCCESS
2024-11-10 07:25:04,873 - INFO - LOAD 'pacbook.customer_address' - SUCCESS
2024-11-10 07:25:05,352 - INFO - LOAD 'pacbook.order_history' - SUCCESS
2024-11-10 07:25:05,725 - INFO - LOAD 'pacbook.order_line' - SUCCESS
2024-11-10 07:25:05,733 - INFO - LOAD 'pacbook.order_status' - SUCCESS
2024-11-10 07:25:05,772 - INFO - LOAD 'pacbook.publisher' - SUCCESS
2024-11-10 07:25:05,780 - INFO - LOAD 'pacbook.shipping_method' - SUCCESS
2024-11-10 07:25:05,780 - INFO - LOAD All Tables To DWH-pacbook - SUCCESS
2024-11-10 07:25:05,782 - INFO - ==================================ENDING LOAD DATA=======================================
INFO: [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) done      Load()
2024-11-10 07:25:05,786 - INFO - [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) done      Load()
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-10 07:25:05,787 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Load__99914b932b   has status   DONE
2024-11-10 07:25:05,792 - INFO - Informed scheduler that task   Load__99914b932b   has status   DONE
DEBUG: Asking scheduler for work...
2024-11-10 07:25:05,792 - DEBUG - Asking scheduler for work...
DEBUG: Pending tasks: 1
2024-11-10 07:25:05,795 - DEBUG - Pending tasks: 1
INFO: [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) running   Transform()
2024-11-10 07:25:05,796 - INFO - [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) running   Transform()
2024-11-10 07:25:05,796 - INFO - ==================================STARTING TRANSFROM DATA=======================================
2024-11-10 07:25:05,799 - ERROR - Transform to All Dimensions and Fact Tables - FAILED
2024-11-10 07:25:05,802 - ERROR - Transform Tables - FAILED
ERROR: [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd /home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform/ && dbt deps && dbt build && dbt snapshot' returned non-zero exit status 127.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
2024-11-10 07:25:05,802 - ERROR - [pid 55247] Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) failed    Transform()
Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 40, in run
    sp.run(
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'cd /home/istywhyerlina/fp_datastorage/PacbookDWH/pacbook_transform/ && dbt deps && dbt build && dbt snapshot' returned non-zero exit status 127.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 210, in run
    new_deps = self._run_get_new_deps()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 138, in _run_get_new_deps
    task_gen = self.task.run()
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 86, in run
    raise Exception('Failed Transforming Tables')
Exception: Failed Transforming Tables
DEBUG: 1 running tasks, waiting for next task to finish
2024-11-10 07:25:05,804 - DEBUG - 1 running tasks, waiting for next task to finish
INFO: Informed scheduler that task   Transform__99914b932b   has status   FAILED
2024-11-10 07:25:05,810 - INFO - Informed scheduler that task   Transform__99914b932b   has status   FAILED
DEBUG: Asking scheduler for work...
2024-11-10 07:25:05,810 - DEBUG - Asking scheduler for work...
DEBUG: Done
2024-11-10 07:25:05,813 - DEBUG - Done
DEBUG: There are no more tasks to run at this time
2024-11-10 07:25:05,813 - DEBUG - There are no more tasks to run at this time
DEBUG: There are 1 pending tasks possibly being run by other workers
2024-11-10 07:25:05,813 - DEBUG - There are 1 pending tasks possibly being run by other workers
DEBUG: There are 1 pending tasks unique to this worker
2024-11-10 07:25:05,813 - DEBUG - There are 1 pending tasks unique to this worker
DEBUG: There are 1 pending tasks last scheduled by this worker
2024-11-10 07:25:05,813 - DEBUG - There are 1 pending tasks last scheduled by this worker
INFO: Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) was stopped. Shutting down Keep-Alive thread
2024-11-10 07:25:05,813 - INFO - Worker Worker(salt=6686893775, workers=1, host=Erlina, username=istywhyerlina, pid=55247) was stopped. Shutting down Keep-Alive thread
INFO: 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

2024-11-10 07:25:05,815 - INFO - 
===== Luigi Execution Summary =====

Scheduled 3 tasks of which:
* 2 ran successfully:
    - 1 Extract()
    - 1 Load()
* 1 failed:
    - 1 Transform()

This progress looks :( because there were failed tasks

===== Luigi Execution Summary =====

DEBUG: Checking if Extract() is complete
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 2 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 3 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
ERROR: Luigi unexpected framework error while scheduling Extract()
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f495e375990>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f495e375990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f495e375990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
WARNING: Failed connecting to remote scheduler 'http://localhost:8082'
NoneType: None
INFO: Retrying attempt 4 of 3 (max)
INFO: Wait for 30 seconds
WARNING: Failed pinging scheduler
INFO: Worker Worker(salt=5816461873, workers=1, host=Erlina, username=istywhyerlina, pid=75360) was stopped. Shutting down Keep-Alive thread
Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 199, in _new_conn
    sock = connection.create_connection(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 789, in urlopen
    response = self._make_request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 495, in _make_request
    conn.request(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 441, in request
    self.endheaders()
  File "/usr/lib/python3.10/http/client.py", line 1278, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/lib/python3.10/http/client.py", line 1038, in _send_output
    self.send(msg)
  File "/usr/lib/python3.10/http/client.py", line 976, in send
    self.connect()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 279, in connect
    self.sock = self._new_conn()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connection.py", line 214, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f495e375990>: Failed to establish a new connection: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 667, in send
    resp = conn.urlopen(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/connectionpool.py", line 843, in urlopen
    retries = retries.increment(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/urllib3/util/retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f495e375990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 185, in _fetch
    response = scheduler_retry(self._fetcher.fetch, full_url, body, self._connect_timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 475, in __call__
    do = self.iter(retry_state=retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check
    raise retry_exc.reraise()
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise
    raise self.last_attempt.result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/tenacity/__init__.py", line 478, in __call__
    result = fn(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 131, in fetch
    resp = self.session.post(full_url, data=body, timeout=timeout)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 637, in post
    return self.request("POST", url, data=data, json=json, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/requests/adapters.py", line 700, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8082): Max retries exceeded with url: /api/add_task (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f495e375990>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/istywhyerlina/fp_datastorage/PacbookDWH/transform.py", line 97, in <module>
    luigi.build([Extract(),
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 243, in build
    luigi_run_result = _schedule_and_run(tasks, worker_scheduler_factory, override_defaults=env_params)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/interface.py", line 175, in _schedule_and_run
    success &= worker.add(t, env_params.parallel_scheduling, env_params.parallel_scheduling_processes)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 806, in add
    for next in self._add(item, is_complete):
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 911, in _add
    self._add_task(
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/worker.py", line 635, in _add_task
    self._scheduler.add_task(*args, **kwargs)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/scheduler.py", line 114, in rpc_func
    return self._request('/api/{}'.format(fn_name), actual_args, **request_args)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 198, in _request
    page = self._fetch(url, body)
  File "/home/istywhyerlina/.local/lib/python3.10/site-packages/luigi/rpc.py", line 187, in _fetch
    raise RPCError(
luigi.rpc.RPCError: Errors (3 attempts) when connecting to remote scheduler 'http://localhost:8082'
